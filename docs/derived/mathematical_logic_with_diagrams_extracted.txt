Mathematical Logic
with Diagrams

Based on the Existential Graphs of Peirce

Frithjof Dau, TU Dresden, Germany

2

Disclaimer: This is (nearly) the ﬁnal version of this treatise. There will
be no more content added. It is only subject of a further proof-reading. For
this reason, if you ﬁnd any misspellings, gaps, ﬂaws, etc., please contact me
(dau@dr-dau.net). Similarly, do not hesitate to contact me if you have any
questions.

Frithjof Dau, September 13, 2006

Come on, my Reader, and let us construct a diagram to illustrate
the general course of thought; I mean a System of diagrammatization by means of which any course of thought can be represented
with exactitude.

Peirce, Prolegomena to an Apology For Pragmaticism, 1906

Contents

Start

1

Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1.1 The Purpose and the Structure of this Treatise . . . . . . . . . . . . . .

2

Short Introduction to Existential Graphs . . . . . . . . . . . . . . . . . .

2.1 Alpha . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .

1

3

7

8

2.2 Beta . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11

2.3 Gamma . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14

3 Theory of Signs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17

3.1 Diagrams . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18

3.2 Icons, Indices, Symbols . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18

3.3 Types and Tokens, Signs and Replicas . . . . . . . . . . . . . . . . . . . . . 23

4 The Role of Existential Graphs in Peirce’s Philosophy . . . . . 25

4.1 Foundations of Knowledge and Reasoning . . . . . . . . . . . . . . . . . . 26

4.2 Existential Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 32

4.3 Conclusion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 37

5 Formalizing Diagrams . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 39

5.1 Problems with Existential Graphs Replicas . . . . . . . . . . . . . . . . . 40

5.2 The First Approach to Diagrams . . . . . . . . . . . . . . . . . . . . . . . . . . 45

5.3 Linear Representations of Logic . . . . . . . . . . . . . . . . . . . . . . . . . . . 48

5.4 The Second Approach to Diagrams . . . . . . . . . . . . . . . . . . . . . . . . 52

6

6

7

8

Contents

Some Remarks to the Books of Zeman, Roberts, and Shin . 55

Alpha

Syntax for Alpha Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 61

Semantics and Calculus for Formal Alpha Graphs . . . . . . . . . 75

8.1 Semantics for Formal Alpha Graphs . . . . . . . . . . . . . . . . . . . . . . . 75

8.2 Some Remarks to the Calculus . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76

8.3 Calculus for Alpha Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 78

8.4 Some Simple Theorems . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 80

9

Soundness and Completeness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83

9.1 Soundness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 83

9.2 Completeness . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 86

10 Translation to Propositional Logic . . . . . . . . . . . . . . . . . . . . . . . . . 91

Beta

11 Getting Closer to Syntax and Semantics of Beta . . . . . . . . . . . 97

11.1 Lines of Identities and Ligatures . . . . . . . . . . . . . . . . . . . . . . . . . . . 98

11.2 Predicates . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 107

11.3 Cuts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 111

11.4 Border cases: LoI touching or crossing on a Cut . . . . . . . . . . . . . 117

12 Syntax for Existential Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123

12.1 Relational Graphs with Cuts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 123

12.2 Existential Graph Instances . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 126

12.3 Further Notations for Existential Graph Instances . . . . . . . . . . . 133

12.4 Formal Existential Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 137

13 Semantics for Existential Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . 141

13.1 Semantics for Existential Graph Instances . . . . . . . . . . . . . . . . . . 141

13.2 Semantics for Existential Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . 145

Contents

7

14 Getting Closer to the Calculus for Beta . . . . . . . . . . . . . . . . . . . . 149

14.1 Erasure and Insertion . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 150

14.2 Iteration and Deiteration . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 152

14.3 Double Cuts . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 159

14.4 Inserting and Deleting a Heavy Dot . . . . . . . . . . . . . . . . . . . . . . . . 161

15 Calculus for Formal Existential Graphs . . . . . . . . . . . . . . . . . . . . 163

16 Improving the Handling of Ligatures . . . . . . . . . . . . . . . . . . . . . . 169

16.1 Derived Rules For Ligatures . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 169

16.2 Improving the Reading of Ligatures . . . . . . . . . . . . . . . . . . . . . . . . 178

17 Soundness of the Calculus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189

18 First Order Logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 197

18.1 Syntax . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 197

18.2 Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 201

18.3 Calculus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 202

19 Syntactical Translations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205

19.1 Deﬁnition of Φ and Ψ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 205

19.2 Semantical Equivalence between Graphs and Formulas . . . . . . . 211

20 Syntactical Equivalence to F O and Completeness . . . . . . . . . . 217

20.1 Ψ Respects ‘ . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 217

20.2 Identity of G and Ψ (Φ(G)) and Completeness of ‘ . . . . . . . . . . . 227

21 Working with Diagrams of Peirce’s Graphs . . . . . . . . . . . . . . . . 229

Extending the System

22 Overview . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 243

23 Adding Constants and Functions . . . . . . . . . . . . . . . . . . . . . . . . . . 245

23.1 General Logical Background . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 247

23.2 Extending the Calculus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 249

8

Contents

23.3 Examples for EGIs with Constants and Functions . . . . . . . . . . . 253

24 Vertices with Constants . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 259

24.1 Syntax and Semantics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 259

24.2 Correspondence between vertex-based EGIs and EGIs . . . . . . . . 262

24.3 Calculus for vertex-based EGIs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 265

24.4 Ligatures in vertex-based EGIs . . . . . . . . . . . . . . . . . . . . . . . . . . . . 274

25 Relation Graphs . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 281

25.1 Semi Relation Graph Instances . . . . . . . . . . . . . . . . . . . . . . . . . . . . 285

25.2 Relation Graph Instances . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 289

26 Peirce’s Reduction Thesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 297

26.1 Introduction . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 297

26.2 Peircean Algebraic Logic . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 298

26.3 Graphs for Peircean Algebraic Logic . . . . . . . . . . . . . . . . . . . . . . . 299

26.4 Peirce’s Reduction Thesis for Relation Graphs . . . . . . . . . . . . . . 309

26.5 The Contributions of Herzberger and Burch . . . . . . . . . . . . . . . . 314

Appendix

Referenced Authors . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 319

Symbols . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 321

Index . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 323

References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 329

Contents

9

Start

1

Introduction

The research ﬁeld of diagrammatic reasoning investigates all forms of human
reasoning and argumentation wherever diagrams are involved. This research
area is constituted from multiple disciplines, including cognitive science and
psychology as well as computer science, artiﬁcial intelligence, logic and mathematics. But it should not be overlooked that there has been until today a
long-standing prejudice against non-symbolic representation in mathematics
and logic. Without doubt diagrams are often used in mathematical reasoning,
but usually only as illustrations or thought aids. Diagrams, many mathematicians say, are not rigorous enough to be used in a proof, or may even mislead
us in a proof. This attitude is captured by the quotation below:

[The diagram] is only a heuristic to prompt certain trains of inference;
... it is dispensable as a proof-theoretic device; indeed ... it has no
proper place in a proof as such. For the proof is a syntactic object
consisting only of sentences arranged in a ﬁnite and inspectable area.

Neil Tennant 1991, quotation adopted from [Bar93]

Nonetheless, there exist some diagrammatic systems which were designed for
mathematical reasoning. Well-known examples are Euler circles and Venn diagrams. More important to us, at the dawn of modern logic, two diagrammatic
systems had been invented in order to formalize logic. The ﬁrst system is
Frege’s Begriﬀsschrift, where Frege attempted to provide a formal universal
language. The other one is the systems of existential graphs (EGs) by Charles
Sanders Peirce, which he used to study and describe logical argumentation.
But none of these systems is used in contemporary mathematical logic. In contrast: For more than a century, linear symbolic representation systems (i.e.,
formal languages which are composed of signs which are a priori meaningless,
and which are therefore manipulated by means of purely formal rules) have
been the exclusive subject for formal logic. There are only a few logicians who

2

1 Introduction

have done research on formal, but non-symbolic logic. The most important
ones are without doubt Barwise and Etchemendy. They say that

there is no principle distinction between inference formalisms that use
text and those that use diagrams. One can have rigorous, logically
sound (and complete) formal systems based on diagrams.

Barwise and Etchemendy 1994, quotation adopted from [Shi02a]

This treatise advocates this view that rigor formal logic can be carried out
by means of manipulating diagrams. In order to do this, the systems of existential graphs is elaborated in a manner which suits the needs and rigor of
contemporary mathematics.

There are good reasons for choosing Peirce’s EGs for the purpose of this
treatise. Peirce had been a philosopher and mathematician who devoted his
life to the investigation of reasoning and the growth of knowledge. He was
particularly interested in the exploration of mathematical reasoning, and EGs
are designed as an instrument for the investigation of such reasoning.

Before he invented EGs at the end of the 19th century, Peirce contributed
much to the development of the symbolic approach to mathematical logic.1
Thus, Peirce was very familiar with both approaches –the diagrammatic and
the symbolic– to logic. As he was interested in an instrument for the investigation of logic (which has to be distinguished from the investigation and
development of logic as such), he discussed the diﬀerences, the advantages
and disadvantages, of these two approaches to a large extent. Particularly, he
elaborated a comprehensive theory of what he already called diagrammatic
reasoning, and he considered his diagrammatic system of EGs to be far more
perfect for the investigation of mathematical reasoning than the symbolic approach he developed as well. His philosophical considerations, his arguments
for his preference of the diagrammatic approach to logic, will give us valuable
insights to how logic with diagrams can be done.

The system of EGs is divided into three parts which are called Alpha, Beta
and Gamma. These parts presuppose and are built upon each other, i.e.
Beta builds upon Alpha, and Gamma builds upon Alpha and Beta. As EGs
are an instrument for the investigation of mathematical reasoning, it is not
surprising that the diﬀerent parts of EGs correspond to speciﬁc fragments of
mathematical logic. It is well accepted that Alpha corresponds to propositional
logic, and Beta corresponds to ﬁrst-order predicate logic.2 The part Gamma

1 For example, he invented, independently from Frege, together with his student
O. H. Mitchell a notation for existential and universal quantiﬁcation. According
to Putnam [Put82], Frege discovered the quantiﬁer four years before Mitchell, but
’Frege did ”discover” the quantiﬁer in the sense of having the rightful claim to
priority; but Peirce and his students discovered it in the eﬀective sense.’

2 Later, it will be discussed in more detail how far the arguments by these authors

can be understood as strict, mathematical proofs.

1.1 The Purpose and the Structure of this Treatise

3

is more complicated: It contains features of higher order and modal logic, the
possibilty to express self-reference, and other features. Due to its complexity, it
was not completed by Peirce. The majority of works which deal with Gamma
deal only with the fragment of Gamma which corresponds to modal logic.

The formal mathematical logic we use nowadays emerged at the beginning
of the 20th century. Russell’s and Whitehead’s
landmark work Principia
Mathematica, probably the most inﬂuential book on modern logic, had been
published in the years 1910–1912. It is obvious that Peirce’s works can by no
means satisfy the needs and criteria of present mathematical logic. His contributions to symbolic logic found their place in the development of modern
formal logic, but his system of EGs received no attention during this process.
Thus, in order to prove mathematically that Alpha and Beta correspond to
propositional and ﬁrst order predicate logic, respectively, the system of EGs
has ﬁrst to be be reworked and reformulated as a precise theory of mathematical logic. Then the correspondence to the symbolic logic we use nowadays
can be mathematically formulated and proven.

Several authors like Zeman, Roberts, Sowa, Burch or Shin have explored the
system of EGs. Most of them work out a correspondence of Alpha and Beta
to propositional and ﬁrst order predicate logic, but it will be discussed later in
detail how far their arguments can be considered to be mathematical proofs.
Moreover, these authors usually fail to implement EGs as a logic system on its
own without a need for translations to other formal, usually symbolic logics,
that is, they fail to provide a dedicated, extensional semantics for the graphs.
The attempt of this treatise is to amend this gap. EGs will be developed
as a formal, but diagrammatic, mathematical logic, including a well-deﬁned
syntax, an extensional semantics, and a sound and complete calculus. Translations from and to symbolic logic are provided as additional elements to work
out the correspondence between diagrammatic and symbolic logic in a mathematical fashion. The methodology of developing a formal, diagrammatic logic
is carried out on EGs, but it can be transferred to the development of diﬀerent
forms of diagrammatic logic as well.

1.1 The Purpose and the Structure of this Treatise

The overall purpose of this treatise has already been explicated: It is to develop a general framework and methodology for a diagrammatic approach to
mathematical logic. In Chpt. 3, a small part of Peirce’s extensively developed
semiotics, i.e., theory of signs, is presented. This part is helpful to elaborate
the speciﬁc diﬀerences between symbolic and diagrammatic representations of
logic. Moreover, it gives us a ﬁrst hint on how diagrams can be mathematically
formalized. This will be more thoroughly discussed in Chpt. 5. In this chapter,
the use of representations in mathematical logic is investigated, and two different, possible approaches for a formalization of diagrams are discussed and

4

1 Introduction

compared. From the results of this discussion, we obtain the methodology for
the formalization of diagrams which is be used in this treatise.

In the frame of this general purpose, Peirce’s EGs serve as a case-study. But
understanding EGs as a ‘mere’ case-study is much too narrow. I have already
argued why it is convenient not to implement an ‘arbitrary’ diagrammatic system, but to consider especially Peirce’s EGs. Although they are not completely
independent from each other, there are two main lines in the elaboration of
Peirce’s EGs.

First of all, this treatise aims to describe Peirce’s deeper understanding of
his systems of EGs (this is similar to Robert’s approach in [Rob73]. See also
Chpt. 6). Due to this aim, in Chpt. 4 it is discussed which role Peirce’s systems
of EGs in his whole philosophy has (this chapter relies on Peirce’s semiotics
which is described in Chpt. 3, but it is a separate chapter in the sense that
the remaining treatise hardly refers to it), and Peirce’s philosophical intention
in the design of the syntax and the transformation rules of EGs is discussed.
For Peirce’s Beta graphs, in Chpt. 11, Peirce’s deeper understanding on the
form and meaning of his graphs is investigated, and in Chpt. 14, the same
is done for Peirce’s transformation rules. These four chapters oﬀer a so-tospeak ’historical reconstruction’ of Peirce’s graphs. Chaps. 11 and 14 are also
needed for the second goal of this treatise: To rework Peirce’s graphs as a
system which fulﬁlls the standards of our contemporary mathematical logic.
This is done ﬁrst for Peirce’s Alpha graphs, then for his Beta graphs.

The Alpha-part of EGs is mathematically elaborated in Chaps. 8–10. The
syntax of these graphs is presented in Chpt. 7, the semantics and calculus
is presented in Chpt. 8. In Chpt. 9, it is directly shown that the calculus
is sound and complete. Propositional logic is encompassed by ﬁrst order order logic; analogously, the system of Alpha graphs is encompassed by the
system of Beta graphs. Thus, from a mathematical point of view, the separate elaboration of Alpha graphs is not needed. But propositional logic and
ﬁrst order logic are the most fundamental kinds of mathematical logic, thus,
in most introductions to mathematical logic, both kinds are separately described. Moreover, this treatise aims to formalize EGs, and Peirce separated
EGs into the systems Alpha, Beta and Gamma as well. For this reason, Alpha
graphs are separately treated in this treatise, too. Moreover, the Alpha part
can be seen as a preparation to the Beta part. Due to this reason, the formalization of Alpha graphs is geared to the formalization of Beta graphs. In fact,
the formalization of Alpha graphs is somewhat a little bit too clumsy and
technical. If one aims to develop solely the Alpha graphs in a mathematical
manner, their formalization could be simpliﬁed, but in the light of understanding Alpha as a preparation for Beta, the herein presented formalization
is more convenient. Finally, in Chpt. 10, translations between Alpha graphs
and formulas of propositional logic are provided. It will be shown that these
translations are meaning-preserving, thus we have indeed a correspondence
between the system of Alpha graphs and propositional logic.

1.1 The Purpose and the Structure of this Treatise

5

First order logic is much more complex than propositional logic, henceforth,
the Beta part of this treatise is much more extensive than the Alpha part.
Moreover, Alpha graphs, more precisely: their diagrammatic representations,
and the transformation rules are somewhat easy to understand and hard to
misinterpret.

Obtaining a precise understanding of the diagrams of Beta graphs, as well
as a precise understanding of the transformation rules, turns out to be much
harder. This is partly due to the fact that Alpha graphs are discrete structures,
whereas Beta graphs (more precisely: the networks of heavily drawn lines in
Beta graphs) are a priori non-discrete structures. For this reason, in Chpt. 11,
the diagrams of Peirce’s Beta graphs are ﬁrst investigated to a large degree,
before their syntax and semantics are formalized in Chaps. 12 and 13. It turns
out that EGs should be formalized as classes of discrete structures. Then, the
transformation rules for Peirce’s Beta graphs are ﬁrst discussed separately in
Chpt. 14, before their formalization is provided in Chpt. 15. The soundness
of these rules can be shown similar to the soundness of their counterparts in
Alpha. This is done in Chpt. 17. Similar to Alpha, I will provide translations
between Beta graphs and formulas of ﬁrst order logic (FO). In Chpt. 18,
the style of FO which is used for this purpose is presented. In Chpt. 19, the
translations between the system of Beta graphs and FO are provided, and it
is shown that these translations are meaning-preserving. It remains to show
that the calculus for Beta graphs is complete (the completeness cannot be
obtained from the facts that the translations are meaning-preserving). Proving
that a logic system with the expressiveness of ﬁrst order logic is somewhat
extensive. For this reason, in contrast to Alpha, the completeness of Beta will
not be shown directly. Instead, the well-known completeness of a calculus for
symbolic ﬁrst order logic will be transferred to Beta graphs. In Chpt. 20, it will
be shown that the translation from formulas to graphs respects the syntactical
derivability-relation as well, from which the completeness of the calculus for
Beta graphs is concluded. Finally in Chpt. 21, the results of the preceeding
chapters are transferred to the diagrammatic representations of EGs. Thus,
this chapter concludes the program of formalizing Peirce’s EGs.

Peirce’s EGs allow to represent propositions about relations. In Chpts. 22–26,
some extensions of EGs which extend their expressiveness are investigated.
First, an overview of them is provided in Chpt. 22. In Chpts. 23 and 24, the
graphs are augmented with constants and functions. In Chpts. 25 and 26, a
new syntactical device which correspond to free variables are added to the
graphs. These resulting graphss evaluate to relations instead of propositions
and are therefore termed relation graphs. In Chpts. 23–Chpts. 25, the syntax,
semantics, and the calculus of the Beta part are appropiately extended to
cover the new elements. Instead of the logic of the extended graphs, Chpt. 26
focuses on operations on relations and on how these operations are reﬂected
by relation graphs. Then a mathematical version of Peirce’s famous reduction
thesis is proven for relation graphs.

6

1 Introduction

The aim and the structure of this treatise should be clear now. In the remainder of this section, some unusual features of treatise are explained.

First of all, this treatise contains a few deﬁnitions, lemmata and theorems
which cannot be considered to be mathematical. For example, this concerns
discussions of the relationship between mathematical structures and their representations. A ‘deﬁnition’ how a mathematical structure is represented ﬁxes
a relation between these mathematical structures and their representations,
but as the representations are non-mathematical entities, this deﬁnition is not
a deﬁnition in a rigid mathematical sense. To distinguish strict mathematical
deﬁnitions for mathematical entities and deﬁnitions where non-mathematical
entities are involved, the latter will be termed Informal Deﬁnition. Examples
can be found in Def. 5.1 or Def. 7.8.

Secondly, there are some parts of the text providing provide further discussions
or expositions which are not needed for the understanding of the text, but
which may be of interest for some readers. These parts can be considered to
be ‘big footnotes’, but, due to their size, they are not provided as footnotes,
but embedded into the continuous text. To indicate them clearly, they start
with the word ‘Comment’ and are printed in footnote size. An example can
be found below.

Finally, the main source of Peirce’s writings are the collected papers [HB35].
The collected papers are -as the name says- a thematically sorted collection
of his writings. They consist of eight books, and in each book, the paragraphs
are indexed by three-digit numbers. I adopt this index without explicitely
mentioning the collected papers. For example, a passage in this treatise like
’in 4.476, Peirce writes [. . .]’ refers to [HB35], book 4, paragraph 476.

Comment: Unfortunately, the collected papers are by no means a complete collection
of Peirce’s manuscripts: More than 100.000 pages, archived in the Houghton Library
at Harvard, remain unpublished. Moreover, due to the attempt of the editors to
provide the writings in a thematically sorted manner, they divided his manuscripts,
placed some parts of them in diﬀerent places of the collected papers, while other
parts are dismissed. Moreover, they failed to indicate which part of the collected
papers is obtained from which source, and sometimes it is even impossible to realize
whether a chapter or section in the collected papers is obtained from exactly one
source or it is assembled from diﬀerent sources. As Mary Keeler writes in [Kee]: ‘The
misnamed Collected Papers [. . .] contains about 150 selections from his unpublished
manuscripts, and only one-ﬁfth of them are complete: parts of some manuscripts
appear in up to three volumes and at least one series of papers has been scattered
throughout seven.’

2

Short Introduction to Existential Graphs

Modern formal logic is presented in a symbolic and linear fashion. That is,
the signs which are used in formal logic are symbols, i.e. signs which are a
priori meaningless and gain their meaning by conventions or interpretations
(in Chpt. 3, the term ‘symbol’ is discussed in detail). The logical propositions,
usually called formulas or sentences, are composed of symbols by writing them
-like text- linearly side by side (in contrast to a spatial arrangement of signs in
diagrams). In fact, nowadays formal logic seems to dismiss any non-symbolic
approach (see the discussion at the beginning of Chpt. 5), thus formal logic
is identiﬁed with symbolic logic.1

In contrast to the situation we have nowadays, the formal logic of the nineteenth century was not limited to symbolic logic only. At the end of that
century, two important diagrammatic systems for mathematical logic have
been developed. One of them is Frege’s Begriﬀsschrift. The ideas behind the
Begriﬀsschrift had an inﬂuence on mathematics which can hardly be underestimated, but the system itself had never been used in practice.2 The other
diagrammatic system are Peirce’s existential graphs, which are the topic of
this treatise. But before Peirce developed his diagrammatic form of logic, he
contributed to the development of symbolic logic to a large extent. He invented the algebraic notation for predicate logic, namely the quantiﬁers (see
for example [Rob73]) for a historical survey of Peirce’s contributions to logic).
Although Peirce invented the algebraic notation, he was not satisﬁed with this
form of logic. As Roberts says in [Rob73]: ‘It is true that Peirce considered
algebraic formulas to be diagrams of a sort; but it is also true that these formulas, unlike other diagrams, are not ‘iconic’ — that is, they do not resemble
the objects or relationships they represent. Peirce took this for a defect.’ Unfortunately, Peirce discovered his system of existential graphs at the very end

1 A much more comprehensive discussion of this topic can be found in [Shi02a].
2 The common explanation for this is that Frege’s diagrams had been to compli-

cated to be printed.

8

2 Short Introduction to Existential Graphs

of the nineteenth century (in a manuscript of 1906, he says that he invented
this system in 1896. see [Rob73]), when symbolic logic already had taken the
vast precedence in formal logic. For this reason, although Peirce was convinced
that EGs are a much better approach to formal logic than any symbolic notation of logic, EGs did not succeed against symbolic logic. It is somewhat
ironic that existential graphs have been ruled out by symbolic formal logic, a
kind of logic which was developed on the basis of Peirce’s algebraic notation
he introduced about 10 years before.

This treatise attempts to show that rigor formal logic can be carried out with
the non-symbolic existential graphs. Before we start with the mathematical
elaboration of existential graphs, in this chapter a ﬁrst, informal introduction
to existential graph is provided.

The system of existential graphs is a highly elegant system of logic which covers propositional logic, ﬁrst order logic and even some aspects of higher-order
logic and modal logic. It is divided into three parts: Alpha, Beta and Gamma.3
These parts presuppose and are built upon each other, i.e. Beta builds upon
Alpha, and Gamma builds upon Alpha and Beta. In this chapter, Alpha and
Beta are introduced, but we will only take a short glance at Gamma.

2.1 Alpha

We start with the description of Alpha. The EGs of Alpha consist only of
two diﬀerent syntactical entities: (atomar) propositions, and so-called cuts
(Peirce often used the term ‘sep’4 instead of ‘cut’, too) which are represented
by ﬁne-drawn, closed, doublepoint-free curves.5 Atomar propositions can be
considered as predicate names of arity 0. Peirce called them medads.

Medads can be written down on an area (the term Peirce uses instead of
‘writing‘ is ‘scribing’ ). The area where the proposition is scribed on is what
Peirce called the sheet of assertion. It may be a sheet of paper, a blackboard, a
computer screen or any other surface. Writing down a proposition is to assert
it (an asserted proposition is called judgement). Thus,

is an EG with the meaning ‘it rains’, i.e. it asserts that it rains.

3 In [Pie04], Pietarinen writes that Peirce mentions in MS 500: 2-3, 1911, that he
even projected a fourth part Delta. However, Pietarinen writes that he found no
further reference to it. And, to the best of my knowledge, no other authors besides
Pietarinen have mentioned or even discussed Delta so far.

4 According to Zeman [Zem64], the term ‘sep’ is inspired from the latin term saepes,
which means ’fence’. Before Fig. 2.3, I provide a passage from Peirce where he
writes that some cut is used to fence oﬀ a proposition from the sheet of assertion.

5 Double-point free means that the line must not cross itself.

it rains2.1 Alpha

9

We can scribe several propositions onto the sheet of assertion, usually side by
side (this operation is called a juxtaposition). This operation asserts the truth
of each proposition, i.e. the juxtaposition corresponds to the conjunction of
the juxtaposed propositions. For example, scribing the propositions ‘it rains’,
‘it is stormy’ and ‘it is cold‘ side by side yields the graph

which means ‘it rains, it is stormy and it is cold’. The propositions do not
have to be scribed or read oﬀ from left to right, thus

is another possibility to arrange the same propositions onto onto the sheet of
assertion, and this graph still has the meaning ‘it rains, it is stormy and it is
cold’.

Encircling a graph by a cut is to negate it. For example, the graph

has the meaning ‘it is not true that it rains’, i.e. ‘it does not rain’. The graph

has the meaning ‘it is not true that it rains and that it is cold’, i.e. ‘it does
not rain or it is not cold’ (the part ‘it is not true’ of this statement refers to
the whole remainder of the statement, that is, the whole proposition ‘it rains
and it is cold’ is denied.)

The space within a cut is called its close or area. Cuts may not overlap,
intersect, or touch6, but they may be nested. The next graph has two nested
cuts.

Its reading starts on the sheet of assertion, then proceeding inwardly. This
way of reading is called endoporeutic method by Peirce. Due to endoporeutic

6 This is not fully correct: Peirce often drew scrolls with one point of intersection
as follows:
. But in 4.474 he informs us that the ‘node [the point of intersection] is of no particular signiﬁcance’, and a scroll may equally well be drawn

as

.

it rains           it is stormy          it is coldit is stormyit is coldit rainsit rainsit rains           it is coldit rains     it is stormyit is cold10

2 Short Introduction to Existential Graphs

reading, this graph has the meaning ‘it is not true that it rains and it is stormy
and that it is not cold’, i.e. ‘if it rains and if its stormy, then it is cold’. It has
three distinct areas: The area of the sheet of assertion contains the outer cut,
the area of the outer cut contains the propositions ‘it rains’ and ’it is stormy’
and the inner cut, and the inner cut contains the proposition ‘it is cold’. An
area is oddly enclosed if it is enclosed by an odd number of cuts, and it is
evenly enclosed if it is enclosed by an even number of cuts. Thus, the sheet of
assertion is evenly enclosed, the area of the outer cut is oddly enclosed, and
the area of the inner cut is evenly enclosed. Moreover, for the items on the
area of a cut (or the area of the sheet of assertion), we will say that these
items are directly enclosed by the cut. Items which are deeper nested are said
to be indirectly enclosed by the cut. For example, the proposition ‘it is cold’
is directly enclosed by the inner cut and indirectly enclosed by the outer cut.

The device of two nested cuts is called a scroll . From the last example we
learn that a scroll can be read as an implication. A scroll with nothing on its
outer area is called double cut. Obviously, it corresponds to a double negation.

As we have the possibility to express conjunction and negation of propositions, we see that Alpha has the expressiveness of propositional logic. Peirce
also provided a calculus for existential graphs (due to philosophical reasons,
Peirce would object against the term ‘calculus’. This will be elaborated in
Chpt. 4). This calculus has a set of ﬁve rules, which are named erasure, insertion, iteration, deiteration, and double cut, and only one axiom, namely the
empty sheet of assertion. Each rule acts on a single graph. For Alpha, these
rules can be formulated as follows:

• Erasure: Any evenly enclosed subgraph7 may be erased.

• Insertion: Any graph may be scribed on any oddly enclosed area.

• Iteration: If a subgraph G occurs on the sheet of assertion or in a cut, then
a copy of the graph may be scribed on the same or any nested area which
does not belong to G.

• Deiteration: Any subgraph whose occurrence could be the result of itera-

tion may be erased.

• Double Cut: Any double cut may be inserted around or removed from any

area.

We will prove in this treatise that this set of rules is sound and complete. In
the following, a simple example of a proof (which is an instantiation of modus
ponens in EGs) is provided. Let us start with the following graph:

7 The technical term ‘subgraph’ will be precisely elaborated in Chpt. 7.

2.2 Beta

11

It has the meaning ‘it rains, and if it rains, then it is cold’. Now we see that
may be considered to be a copy of the
the inner subgraph
. Hence we can erase the inner
outer subgraph subgraph
subgraph using the deiteration-rule. This yields:

This graph contains a double cut, which now may be removed. We get:

Finally we erase the subgraph
get:

with the erasure-rule and

So the graph with the meaning ‘it rains and it is stormy, and if it rains and
it is stormy, then it is cold’ implies the graph with the meaning ‘it is cold’.

2.2 Beta

The step from the Alpha part of EGs to the Beta part corresponds to the
step from propositional logic to ﬁrst order logic. First of all, a new symbol,
the line of identity, is introduced. Lines of identity are used to denote both
the existence of objects and the identity between objects. They are represented as heavily drawn lines. Secondly, instead of only considering medads,
i.e. predicate names of arity 0, now predicate names of arbitrary arity may be
used.

Consider the following graph:

It contains two lines of identity, hence it denotes two (not necessarily diﬀerent)
objects. The ﬁrst line of identity is attached to the unary predicate ‘cat’, hence
the ﬁrst object denotes a cat. Analogously the second line of identity denotes a
mat. Both lines are attached to the dyadic predicate ‘on’, i.e. the ﬁrst object
(the cat) stands in the relation ‘on’ to the second object (the mat). The

it rains     it is stormyit is coldit rains     it is stormyit rains     it is stormyit rains     it is stormyit is coldit rains     it is stormyit rains           it is stormy          it is coldit rains     it is stormyit is coldcatonmat12

2 Short Introduction to Existential Graphs

meaning of the graph is therefore ‘there are a cat and a mat such that the cat
is on the mat’, or in short: A cat is on a mat. Analogously,

means ‘there is a cat between a table and a door’.

Lines of identity may be composed to networks. Such a network of lines of
identity is called ligature. For example, in

we have a ligature composed of three lines of identity, which meet in a socalled branching point. Still this ligature denotes one object: The meaning of
the graph is ‘there is an object which is a cat, young and cute’, or ‘ there is
a cute and young cat’ for short.

Ligatures may cross cuts (it will become clear in Chpt. 11 why I use the term
‘ligature’ in these examples, i.e., why I do not write that lines of identity may
cross cuts). Consider the following graphs:

The meaning of the ﬁrst graph is clear: it is ‘there is a cat’. The second graph
is built from the ﬁrst graph by drawing a cut around it, i.e. the ﬁrst graph is
denied. Hence the meaning of the second graph is ‘it is not true that there is
a cat’, i.e. ‘there is no cat’. In the third graph, the ligature starts on the sheet
of assertion. Hence the existence of the object is asserted and not denied. For
this reason the meaning of the third graph is ‘there is something which is not
a cat’.

A heavily drawn line which traverses a cut denotes the non-identity of the
extremities of that line (again this will be discussed in Chpt. 11). For example,
the graph

has the meaning ‘there is an object o1 which is a cat, there is an object o2
which is a cat, and o1 and o2 are not identical’, that is, there are at least two
cats.

Now we have the possibility to express existential quantiﬁcation, predicates of
arbitrary arities, conjunction and negation. Hence we see that the Beta part
of existential graphs corresponds to ﬁrst order predicate logic (that is ﬁrst

tablebetweendoorcatcutecatyoungcatcatcatcatcat2.2 Beta

13

order logic with identity and predicate names, but without object names and
without function names).

Essentially, the rules for Beta are extensions of the ﬁve rules for Alpha such
that the Beta rules cover the properties of the lines of identity. The Beta rules
are as follows:

• Erasure: Any evenly enclosed subgraph and any evenly enclosed portion

of a line of identity may be erased.

• Insertion: Any graph may be scribed on any oddly enclosed area, and two
portions of two lines of identity which are oddly enclosed on the same area
may be joined.

• Iteration: For a subgraph G on the sheet of assertion or in a cut, a copy
of this subgraph may be scribed on the same or any nested area which
does not belong to G. In this operation, it is allowed to connect any line
of identity of G, which is not scribed on the area of any cut of G, with
its iterated copy. Consequently, it is allowed to add new branches to a
ligature, or to extend any line of identity inwards through cuts.

• Deiteration: Any subgraph whose occurrence could be the result of an

iteration may be erased.

• Double Cut: Any double cut may be inserted around or removed from any
area. This transformation is still allowed if we have ligatures which start
outside the outer cut and pass through the area of the outer cut to the are
of the inner cut.

The precise understanding of these rules will be unfolded in Chpt. 14. In this
chapter, they will be illustrated with an example which is taken from [Sow97a].
This example is a proof of the following syllogism of type Darii:

Every trailer truck has 18 wheels. Some Peterbilt is a trailer truck. Therefore,
some Peterbilt has 18 wheels.

We start with an existential graph which encodes our premises:

We use the rule of iteration to extend the outer line of identity into the cut:

has 18 wheelstrailer truckPeterbilttrailer truck14

2 Short Introduction to Existential Graphs

As the area of this cut is oddly enclosed, the insertion-rule allows us to join
the loose end of the line of identity we have just iterated with the other line
of identity:

Now we can remove the inner instance of ‘is a trailer truck’ with the
deiteration-rule:

Next we are allowed to remove the double cut (the space between the inner
and the outer cut is not empty, but what is written on this area is a ligature
which entirely passes through it, thus the application of the double-cut-rule
is still possible):

Finally we erase the remaining instance of ‘is a trailer truck’ with the erasurerule and obtain:

This is a graph with the meaning ‘some Peterbilt has 18 wheels’, which is the
conclusion of the syllogism.

2.3 Gamma

The Gamma part of EGs shall not be described here: I will only pick out
some peculiar aspects of Gamma. The Gamma system was never completed

has 18 wheelstrailer truckPeterbilttrailer truckhas 18 wheelstrailer truckPeterbilttrailer truckhas 18 wheelstrailer truckPeterbilthas 18 wheelstrailer truckPeterbiltPeterbilthas 18 wheels2.3 Gamma

15

(in 4.576, Peirce comments Gamma as follows: ‘I was as yet able to gain
mere glimpses, suﬃcient only to show me its reality, and to rouse my intense
curiosity, without giving me any real insight into it.’), and it is diﬃcult to be
sure about Peirce’s intention. Roughly speaking, it encompasses higher order
and modal logic and the possibilty to express self-reference. The probably
best-known new device of Gamma is the so-called broken cut. Consider the
following two graphs of 4.516 (the letter ‘g‘ is used by Peirce to denote a
graph):

Fig. 2.1. Figs. 182 and 186 in 4.516

Peirce describes these graphs as follows: ‘Of a certain graph g let us suppose
that I am in such a state of information that it may be true and may be false;
that is I can scribe on the sheet of assertion Figs. 182 and 186.’ We see that
encircling a graph E by a broken cuts is interpreted as ‘it is possibly not the
case that E holds’, thus, the broken cut corresponds to the syntactical device
’3¬’ of modal logic.

Another important aspect of Gamma is the possibility to express meta-level
propositions, i.e. propositions about propositions. As Peirce says: A main idea
of Gamma is that a graph ‘is applicable instead of merely applying it’ (quotation from [Rob73]). In other words: Graphs, which have been used to speak
about objects so far, can now in Gamma be treated like objects themselves
such that other graphs speak about them (this is a kind of abstraction which
Peirce called ‘hypostatic abstraction’). A simple example for this idea can
be found in [Pei92], where Peirce says: ‘When we wish to assert something
about a proposition without asserting the proposition itself, we will enclose
it in a lightly drawn oval, which is supposed to fence it oﬀ from the ﬁeld of
assertions.’ Peirce provides the following graph to illustrate his explanation:

The meaning of this graph is: ‘You are a good girl’ is much to be wished.
Peirce generalized the notation of a cut. The lightly drawn oval is not used to
negate the enclosed graph, it is merely used to ‘fence it oﬀ from the ﬁeld of
assertions’ and to provide a graphical possibility to speak about it.

Peirce extended this approach further. He started to use colors or tinctures to
distinguish diﬀerent kind of contexts. Peirce said himself: ‘The nature of the

ggYou are a good girlis much to be wished16

2 Short Introduction to Existential Graphs

universe or universes of discourse (for several may be referred to in a single
assertion) in the rather unusual cases in which such precision is required,
is denoted either by using modiﬁcations of the heraldic tinctures, marked in
something like the usual manner in pale ink upon the surface, or by scribing
the graphs in colored inks.’ (quotation taken from [Sow]). For example, in the
next graph he used the color red to indicate possibility (which is –due to the
fact that this treatise is printed in black and white– replaced by gray in the
next example).

In this example we have two red (gray) ovals. One is purely red; it says that
the enclosed graph is possible. The other one is a cut which is red inside, hence
it says that the enclosed graph is impossible. As the three lines of identity
start in the area of a scroll, they can be understood as universally quantiﬁed
objects. Hence the meaning of the graph is: For all persons, horses and water,
it is possible for the person to lead the horse to the water, but is impossible
to make the horse drink. Or, for short: You can lead a horse to water, but you
can’t make him drink.

It is important to note that Peirce did not consider the tinctures to be logical
operators, but to be meta-level operators. That is, they are part of a metalanguage which can be used to describe how logic applies to the universe of
discourse.

tois a personis watermakesdrinkis a horseleads3

Theory of Signs

Peirce invented two types of notations for logic: An linear, algebraic notation
and the spatial, graphical notation of EGs. In Peirce’s writings, we ﬁnd lot
of passages where he emphasizes that all mathematical reasoning is based
on diagrams. For example, in [Eis76], 4.314, he writes that ‘all mathematical reasoning is diagrammatic’, or in his Cambridge Lectures, he says that
‘all necessary reasoning is strictly speaking mathematic reasoning, that is to
say, it is performed by observing something equivalent to a mathematical diagram.’ At a ﬁrst glance, these quotations seem to be a motivation for Peirce’s
invention of the diagrammatic notation of EGs. But, Peirce invented a nondiagrammatic notation for logic as well. Moreover, the quotations give no
hint why EGs should be preferred, or even what the main diﬀerence between
the algebraic and the diagrammatic notations for logic are. Moreover, without doubt Peirce would agree that working with the algebraic notation for
logic is mathematical reasoning as well, and as a mathematician he was of
course very aware of the evident fact that a huge amount of mathematics is
carried out with text, formulas, etc, but not with diagrams. In the light of
this consideration, the quotations appear pretty puzzling, and two questions
naturally arise: What qualities distinguish diagrammatic notations from nondiagrammatic notations? And what does Peirce mean when he claims that all
mathematical is diagrammatic?

It is well known that Peirce developed a comprehensive (maybe the most
comprehensive) and notoriously complicated theory of signs, i.e., semiotics (or
‘semeiotics’, as Peirce often called his theory). In this chapter, a few aspects
of this semiotics which are essential for the elaboration of his understanding
of diagrammatic reasoning will be presented. Particularly, these aspects are
helpful to answer the questions above.

18

3 Theory of Signs

3.1 Diagrams

First of all, it has to stressed that Peirce’s conception of the term ‘diagram’ is
much broader than the understanding we have today. In fact, in the starting
passage of this chapter I sticked to the understanding of the term ‘diagram’
we have nowadays, for example, when I wrote about the diﬀerences between
algebraic and diagrammatic notations for logic. There seems to be a contrast
or even conﬂict between these two approaches, but certainly, Peirce would
not agree to that, as for him all mathematical reasoning is diagrammatic.
In 1.418, he says that ‘a diagram has got to be either auditory or visual, the
parts being separated in the one case in time, in the other in space.’ Of course,
in our understanding of diagrams, they are not auditory.1 But even Peirce’s
conception of visual diagrams is much broader than ours. Any collection of
spatially separated signs, i.e., any kind of visual representation system, has to
be considered a diagram in Peirce’s sense. Roughly speaking, nowadays, diagrammatic notations are understood to be graphical notations, thus they are
distinguished from algebraic and symbolic notations like algebraic equations
of formulas in mathematical logic. But for Peirce, these equations and formulas are diagrams as well. For example, in 3.419 he says that ‘algebra is but a
sort of diagram’, and in his Prolegomena to an Apology For Pragmaticism,
he discusses in 4.530 the formula

1
f1

+

1
f2

=

1
f0

stating that ‘this equation is a diagram’, and calls it later on ‘algebraic diagram.’

3.2 Icons, Indices, Symbols

Peirce classiﬁes the signs into several trichotomies, which are often again subdivided into other trichotomies, etc.2 For the purpose of this treatise, it is
helpful and suﬃcient to consider one of Peirce’s trichotomies, namely the division of signs into icons, indices, and symbols, a division of which Peirce says
that this is the most fundamental (see 2.275).

In contrast to the development of existential graphs which were invented not
until 1896 (Peirce was 57 years old), his investigations of signs started decades

1 But I guess, due to the development of computers and presentation programs
with multi-media features, where text, graphics, animations and sounds can be
mixed, it is nowadays easier to follow Peirce’s conception of diagrams.

2 The use of trichotomies is based on Peirce’s three fundamental categories called
ﬁrstness, secondness, and thirdness. But a discussion of these categories goes far
beyond the scope of this treatise.

3.2 Icons, Indices, Symbols

19

earlier. Thus it is no wonder that we ﬁnd a huge amount of deﬁnitions of
the term ‘sign’ (or ‘representamen’, which is synonymous) in his writings. In
[ML], 76 deﬁnitions are collected, ranging from 1865 to 1911 (and the ongoing
deﬁnitions of ‘sign’ can be found in this source). Though these deﬁnitions
diﬀer in details, the overall conception of a sign does not change.

Already in 1873, in a text titled ‘Of logic as a study of signs’, MS 380, he
states that ‘a sign is something which stands for another thing to a mind.’ 30
years later, we ﬁnd a very similar deﬁnition in his Lowell Lectures (see 1.346),
where he says: ‘Now a sign is something, A, which denotes some fact or object,
B, to some interpretant thought, C.’ Thus, an entity is established as a sign
when it is interpreted by a mind to represent another object. Thus we have
three things to deal with: First of all, we have the sign, secondly, we have the
object which is represented by the sign, and thirdly, we have a mind in which
the representation causes a subjective idea of the represented object. This
subjective idea is what Peirce calls ‘interpretant thought’, or, in many places,
simply ‘interpretant’. This conception of signs leads to the so-called meaning
triangle which is constituted by the sign, its object and the interpretant (=
subjective idea). According to Peirce, the sign is ‘mediating between an object
and an interpreting thought’ (1.480). For him, the interpreting thought is
essential: 1902 he writes in MS 599 that ‘a Sign does not function as a sign
unless it be understood as a sign.’

A sign can represent its object in three diﬀerent ways, which leads to the division of signs into icons, indices, and symbols. These diﬀerent types of signs
are perceived in diﬀerent ways, that is, the interpretant thought emerges differently. For this reason this division is interesting for the investigation of
diagrams, and in fact, in Peirce’s writings on existential graphs, we ﬁnd discussions on icons, indices and symbols in several places. In the following, these
types will be deﬁned and discussed. But before I do so, I have to stress that a
sign rarely belongs to one of these classes exclusively. Often, a sign possesses
iconical, indexical and symbolic qualities. Thus, the deﬁnitions which will be
given should be understood in a prototypic manner.

A symbol is a sign which gains its meaning by mere convention. The best
example for symbols are words. In 4.447 Peirce’s writes: ‘Take, for example,
the word ”man.” These three letters are not in the least like a man; nor is
the sound with which they are associated’ (we will come back to this example
in the next section). There is no necessary reason whatsoever that the word
‘man’ is interpreted as it is. A symbol is a sign if ‘is constituted a sign merely
or mainly by the fact that it is used and understood as such’, Peirce says in
2.307. The meaning of a symbol is based on laws, habits or conventions in
a community. In order to understand the meaning of a symbol, we have to
learn what the symbol denotes. Of course, there are other examples of symbols
which are no words. For example, ﬂags are symbols for countries, or colors are
often used as symbols (for example, in Europe, the color black is a symbol for
mourning, in China it is the color white).

20

3 Theory of Signs

In contrast to symbols, indices and icons have a direct connection to the
represented objects. Roughly speaking, for indices it is a physical causality,
for icons it is resemblance. In 2.448, Peirce writes that an ‘An Index is a sign
which refers to the object that it denotes by virtue of being really aﬀected by
that object’, or, more explicit in 2.299: ‘The index is physically connected with
its object; they make an organic pair, but the interpreting mind has nothing
to do with this connection, except remarking it, after it is established.’ This
induces an important diﬀerence to symbols: Symbols may refer to ideas, or
abstract concepts (like ‘man’, which refers not to a speciﬁc man, but to the
concept of man), but an index always refers to an individual, singular entity.
An example Peirce gives is that smoke is an index of ﬁre, more precisely, of
the ﬁre which causes the smoke. Other examples of Peirce are weathercocks
which indicate the direction of the wind or low barometers which indicate
moist air and coming rain; a pointing ﬁnger is an index, too (all examples
can be found in 2.286). Due to the direct connection between an index and
the represented object, an index does not necessarily need an interpretant to
be a sign, but it need the physical existence of the denoted object. Peirce
explicates this point in 2.304 with a somewhat drastic example as follows: ‘An
index is a sign which would, at once, lose the character which makes it a sign
if its object were removed, but would not lose that character if there were no
interpretant. Such, for instance, is a piece of mould with a bullet-hole in it as
sign of a shot; for without the shot there would have been no hole; but there is
a hole there, whether anybody has the sense to attribute it to a shot or not.’

The most important type for diagrams is the class of icons. The essential
feature of an icon is a similarity between the sign and the denoted object,
i.e. that the ‘relation between the sign and its object [. . .] consists in a mere
resemblance between them’ (3.362). A simple example is a painting, let’s say,
of the Eiﬀel tower. A person who knows the Eiﬀel tower and sees the painting
will immediately know that the painting refers to the Eiﬀel tower in Paris. No
convention is needed for this, thus, the painting is not a symbol. Moreover,
there is no direct, physical connection between the tower and its painting3,
thus, the painting is not an index. This becomes even more evident if we
considered the painting of an object which does not exist, for example, an
unicorn. Other, popular examples for icons can be found in public buildings,
like signs for restrooms, busses, trains, elevators etc in an international airport.

Iconic representations are much easier to comprehend than symbolic representations. Iconicity is an essential feature which occurs in diagrams. Peirce
says in 4.333 that diagrams ‘ought to be as iconic as possible.’ Let us consider
an example in mathematics, where diagrams are used. A well-known type of
diagrams are are the spatial representations of graphs, a slightly more sophis-

3 This would be diﬀerent if we considered a photograph of the Eiﬀel tower. In fact,

photographs are for Peirce a mixture of indices and icons.

3.2 Icons, Indices, Symbols

21

ticated example are Hasse-diagrams which are used to represent ordered sets.4
Let us consider the following ordered set:

({a, b, c, d, e}, {(a, a), (b, b), (c, c), (d, d), (e, e), (a, c), (b, c), (a, d), (b, d), (c, d)})

The following is a representation of this ordered set as a Hasse-diagram:
t
d

t
c
@@
(cid:0)(cid:0)

(cid:0)
t
a

@
t
b

t
e

An element of the ordered set is above another element, if and only if there is a
path from the dot representing the ﬁrst element upwards to the dot representing the second element. In this sense, the order ≤ is represented iconically.
Without doubt, the order is easier to comprehend from the Hasse-diagram
than from the symbolic notation given before. Moreover, in the Hasse-diagram,
more facts about the represented order can immediately be read oﬀ. For example, we easily see that a, b and e are the minimal elements of the order.
This advantage of iconic representation is described by Peirce in 2.279, where
her writes that ‘a great distinguishing property of the icon is that by the direct observation of it other truths concerning its object can be discovered than
those which suﬃce to determine its construction.’ 5

It is crucial to note that a diagram has iconic features, but usually, it is not an
icon. Peirce writes in 2.282 that ‘many diagrams resemble their objects not at
all in looks; it is only in respect to the relations of their parts that their likeness consists.’ For Peirce, even algebraical equations are not purely symbolic,
but they have some iconic qualities. In 2.281, he writes that ‘every algebraical
equation is an icon, in so far as it exhibits, by means of the algebraical signs
(which are not themselves icons), the relations of the quantities concerned.’
For this reason, Peirce considered even algebraical equations to be diagrams.
But without doubt, other diagrams bear much more iconicity than algebraic
equations. Diagrams are representations, representing some facts, and they
‘ought to be as iconic as possible.’ In 4.418 he states more precisely that ‘A
diagram is a representamen [sign] which is predominantly an icon of relations
and is aided to be so by conventions.’ Nonetheless, there is no sharp distinction between diagrammatic and non-diagrammatic representations, but the
discussion so far gives rise to a possible ﬁxation of the term ‘diagram’, which,
I suspect, is close to Peirce’s understanding of diagrams, and which might
serve as a deﬁnition which suits contemporary needs as well:

4 A graph is a pair (V, E) with E ⊆ V × V . The elements of V and E are called
vertices and edges, respectively. An ordered set (X, ≤) is a set X with a relation
≤ ⊆ X × X such that ≤ is reﬂexive, anti-symmetric and transitive, i.e. for all
x, y, z ∈ X we have x ≤ x, x ≤ y ≤ x ⇒ x = y and x ≤ y ≤ z ⇒ x ≤ z.

5 In the modern research ﬁeld of diagrammatic reasoning, Shimojima coined the

term free ride for this property of diagrams.

22

3 Theory of Signs

Diagram: Given a representation of some facts, the higher the
amount of iconically represented facts is (among all represented facts),
the more the representation is a diagram.

(This is closely related to Hammer’s characterization of ‘good diagrams’. In
Chpt. 1 of his book citeHa95, where he states that ‘the resemblance between
diagrams and what they represent is more a feature of good diagrams than of
diagrams generally. ’.)

Concerning our example, the representation of the order ≤ is partly iconic,
but it is partly symbolic as well. For example, it is a convention that not all
pairs (x, y) ∈ ≤ are represented with a line; this is only done if x and y are
neighbors, i.e., there is no third element z with x ≤ z ≤ y. A student who gets
for the ﬁrst time in contact with Hasse-diagrams has to learn this convention.
Thus she has to learn which facts of the structure are represented in the
diagram, and how this is done. Vice versa, she has to learn which properties
in the diagram are indeed representing facts. It is sometimes puzzling for
novices that the positions of the dots may vary to some extent, and that the
length of a line is of no signiﬁcance. For example, the next (badly designed)
Hasse-diagram represents the same order, although it looks quite diﬀerent:

t
d
(cid:0)(cid:0)
(cid:0)
t
c
@@
t
a

t
b

t
e

The example does not only show in Hasse-diagrams are partly symbolic, moreover, it shows that it is of great importance to make clear which graphical
properties in a diagram are of signiﬁcance, i.e. they represent some facts, and
which not. We have already seen that an advantage of diagrams is that some
new facts are easily read oﬀ the diagram. But if it is not clear which graphical
properties represent facts, there may be accidental, non-representing properties which seem to represent something, while they do not. Thus they may
mislead a reader to draw wrong conclusion from the diagram. Shin investigates in [Shi02a] the use of icons in diagrams to a large extent, and one result
of her scrutiny is the following statement: ‘Now we may reach the following
general conclusion about the representation of icons: When we adopt an icon
to represent something in general (as a symbol does), it is important to classify
the observable properties of the particular icon into two diﬀerent categories;
properties that are representing facts and properties that are not.[. . .] The existence of accidental properties is directly related to the traditional complaint
against the use of diagrams in a proof.’

3.3 Types and Tokens, Signs and Replicas

3.3 Types and Tokens, Signs and Replicas

23

In the last section, Peirce was quoted where he exempliﬁes his deﬁnition of a
symbol with the word ”man”. The whole passage is:

Take, for example, the word ”man.” These three letters are not in
the least like a man; nor is the sound with which they are associated.
Neither is the word existentially connected with any man as an index.
It cannot be so, since the word is not an existence at all. The word does
not consist of three ﬁlms of ink. If the word ”man” occurs hundreds
of times in a book of which myriads of copies are printed, all those
millions of triplets of patches of ink are embodiments of one and the
same word. I call each of those embodiments a replica of the symbol.

(a similar consideration with this example can be found in 2.292). This is
a consideration which does only apply to symbols. For example, if we have
smoke which acts as an index for a ﬁre, then the physical object smoke is
the sign. The sign is physically determined by the object. For symbols, the
relation between object and sign is established by the interpreting mind, and
the symbol is not a concrete physical object. But of course there are physical
objects which represent the symbol: For the word ”man”, that are the three
ﬁlms of ink Peirce spoke about. Each of these physical occurrences are replicas
of the abstract symbol ”man”. To put it short: ‘Symbols act through replicas,’
as Peirce says. This will turn out to be important in Chpt. 5, where it is
discussed how EGs can be formalized.

Although the type-token issue, as it is known from philosophy, is far from being
settled, the distinction between graphs and graph replicas is obviously very
similar to the distinction between types (graphs) and tokens (graph replicas).
In fact, in his Prolegomena to an Apology For Pragmaticism, Peirce elaborates
the meaning of the terms ‘token‘ and ‘type’ exactly like the meaning of the
term ‘symbol’ and ‘replica’. But unfortunately, in other passages uses the term
‘token’ as a synonym for the term ‘symbol’, thus one has to be careful about
Peirce use of the term ‘token’.

4

The Role of Existential Graphs in Peirce’s
Philosophy

Diagrammatic reasoning is the only really fertile reasoning. If logicians would only embrace this method, we should no longer see
attempts to base their science on the fragile foundations of metaphysics or a psychology not based on logical theory; and there
would soon be such an advance in logic that every science would
feel the beneﬁt of it.

Peirce, Prolegomena to an Apology For Pragmaticism, 1906

Among philosophers, Peirce is in the ﬁrst place recognized as the founder of
‘pragmatism’ (or ‘pragmaticism’, as Peirce later called his theory), and as
a scientist who has elaborated the probably most extensive theory of signs,
i.e., semiotics. But the system of existential graphs is neither in philosophy,
nor in mathematics or logic, very much acknowledged or even appreciated.
Interestingly, in contrast to the contemporary estimation of his work, Peirce
himself considered his development of existential graphs as his ‘luckiest ﬁnd
of my career’, and he called them his ‘chef d’oeuvre’. In a letter to William
James, he says that EGs are the ‘logic of future’. In fact, after he started
working with EGs, he spent the remainder of his life with the elaboration of
this system. Mary Keeler writes in [Kee] that ‘he produces his most intensive
theoretical work, which includes the Existential Graphs, during the last 10
years of his life (40.000 pages, or nearly half of the whole collection [100.000
unpublished pages which are achieved in the Houghton Library at Harvard]).’

This chapter attempts to explain why Peirce places his existential graphs into
the center of his philosophy, and from this elaboration we will moreover obtain
good reasons why Peirce designed the existential graphs the way he did.

26

4 The Role of Existential Graphs in Peirce’s Philosophy

4.1 Foundations of Knowledge and Reasoning

The overall goal of Peirce’s philosophy are the foundations of reasoning and
knowledge. Hookway, who has worked extensively with Peirce’s manuscripts,
writes in [Hoo85]: ‘Inspired by Kant, he devoted his live to providing foundations for knowledge and, in the course of doing so, he brought together a
number of diﬀerent philosophical doctrines’, and Mary Keeler says in [Kee]
that ‘generally, his life’s work can be seen as a struggle to build the philosophical perspective needed to examine how intellectual growth occurs.’

Peirce’s semiotics and his theory of pragmaticism can be seen as two important facets of his theory of reasoning. Pragmaticism is not addressed by
this chapter, thus I let other authors describe the relationship between pragmatism and reasoning. The editors of the collected papers summarize in the
introduction of Volume 5 (Pragmatism and Pragmaticism) this relationship
as follows: ‘Pragmatism is conceived to be a method in logic rather than a
principle of metaphysics. It provides a maxim which determines the admissibility of explanatory hypotheses.’ Similarly, Dipert writes in [Dip04] that ‘the
penultimate goal of thought is to have correct representations of the world, and
these are ultimately grounded for the pragmatist in the goal of eﬀective action
in the world.’ I.e., as Dipert writes, pragmaticism answers the question why
to think logically.

More important to us is the relationship between semiotics and reasoning. For
Peirce, semiotics is not a mere metatheory of linguistics, he is interested in
what sense signs are involved in reasoning. Already in 1868, in a publication
titled ‘Questions concerning certain Faculties Claimed for Man’, he addresses
the question whether reasoning which does not use signs is possible, and he
comes to the conclusion that ‘all thought, therefore, must necessarily be in
signs’ (whole article: 5.213-5.263, quotation: 5.2521). Particularly, the main
types of signs, i.e. icons, indices, and symbols (see [Dau04c, Shi02a] for a discussion), are needed in reasoning. In 5.243, Peirce claims that these ‘three kinds
of signs [. . .] are all indispensable in all reasoning.’ It is not only reasoning
which has to be in signs. Pape summarizes the following fundamental principle which underlies Peirce understanding of semiotics:2 ‘All intellectual or
sensory experience – no matter of which pre-linguistic or pre-conscious level
it is – can be generalized in a way that it can be interpreted in a universal
representation.’

In his speculative grammar (2.105–2.444), Peirce’s elaborates that the growth
of knowledge is condensed in the change and growth of the meaning of signs.

1 I adopt the usual convention to refer to the collected papers [HB35]. I.e., 5.213-

5.263 refers to the ﬁfth book of [HB35], paragraphs 213–263.

2 The original German quotation is: ‘Alle intellektuelle und sinnliche Erfahrung –
gleich welcher vorsprachlichen oder vorbewußten Stufe – kann so verallgemeinert
werden, daß sie in einer universalen Darstellung interpretierbar ist.’

4.1 Foundations of Knowledge and Reasoning

27

In 2.222, he writes: ‘For every symbol is a living thing, in a very strict sense
that is no mere ﬁgure of speech. The body of the symbol changes slowly, but its
meaning inevitably grows, incorporates new elements and throws oﬀ old ones.’
In this understanding, semiotics is more than a formal theory of signs: It is
a theory of meaning as well. Moreover, to investigate the laws of reasoning is
to investigate the relationships between the signs reasoning is based on. Thus
a theory of reasoning and the emergence of knowledge has to be a theory of
signs. In 1.444, Peirce summarizes the relationship between logic, reasoning
and semiotic as follows: ‘The term ”logic” [. . .] in its broader sense, it is
the science of the necessary laws of thought, or, still better (thought always
taking place by means of signs), it is general semeiotic, treating not merely
of truth, but also of the general conditions of signs being signs [. . .], also
of the laws of the evolution of thought.’ Due to this broad understanding
of semiotics and logic, these two research ﬁelds investigate reasoning from
diﬀerent perspectives, but they are essentially the same. So Peirce starts the
second chapter of his speculative grammar with the conclusion that ‘logic, in
its general sense, is, as I believe I have shown, only another name for semiotic’
(2.227).

In the following, we will investigate Peirce’s theory of logic and reasoning. I
start this scrutiny with two quotations from Peirce, both taken from ’Book II:
Existential graphs’ of the collected papers, in which he elaborates his understanding of logic and so-called necessary reasoning. In 4.431, Peirce writes:

But what are our assertions to be about? The answer must be that
they are to be about an arbitrarily hypothetical universe, a creation
of a mind. For it is necessary reasoning alone that we intend to study;
and the necessity of such reasoning consists in this, that not only does
the conclusion happen to be true of a pre-determinate universe, but
will be true, so long as the premises are true, howsoever the universe
may subsequently turn out to be determined. Physical necessity consists in the fact that whatever may happen will conform to a law
of nature; and logical necessity, which is what we have here to deal
with, consists of something being determinately true of a universe not
entirely determinate as to what is true, and thus not existent.

In 4.477, we ﬁnd:

The purpose of logic is attained by any single passage from a premiss
to a conclusion, as long as it does not at once happen that the premiss
is true while the conclusion is false. But reasoning proceeds upon a
rule, and an inference is not necessary, unless the rule be such that
in every case the fact stated in the premiss and the fact stated in the
conclusion are so related that either the premiss will be false or the
conclusion will be true. (Or both, of course. ”Either A or B” does not
properly exclude ”both A and B.”) Even then, the reasoning may not

28

4 The Role of Existential Graphs in Peirce’s Philosophy

be logical, because the rule may involve matter of fact, so that the
reasoner cannot have suﬃcient ground to be absolutely certain that it
will not sometimes fail. The inference is only logical if the reasoner can
be mathematically certain of the excellence of his rule of reasoning;
and in the case of necessary reasoning he must be mathematically
certain that in every state of things whatsoever, whether now or a
million years hence, whether here or in the farthest ﬁxed star, such a
premiss and such a conclusion will never be, the former true and the
latter false.

The main point in both quotations is that Peirce’s emphasizes to investigate necessary reasoning, and he elaborates his understanding of necessity
in reasoning. First of all, we see that a necessary implication is an implication which can never lead from a true premise to a false conclusion. This
can be expressed by diﬀerent logical connectives: In the second quotation,
he explicates a necessary inference like a truth-table (to adopt a term from
contemporary propositional logic) with the operators ‘not’ and ’or’. In another place, he writes: ‘A leading principle of inference which can lead from
a true premiss to a false conclusion is insofar bad; but insofar as it can only
lead either from a false premiss or to a true conclusion, it is satisfactory; and
whether it leads from false to false, from true to true, or from false to true, it
is equally satisfactory’; thus in this quotation he provides the truth-table for
the syntactical expression a → b. A necessary implication corresponds to the
material implication as it is understood in classical propositional logic, that
is, as an implication which can be expressed in the following diﬀerent ways:

a → b ∼ ¬(a ∧ ¬b) ∼ ¬a ∨ b

The truth of a necessary implication does not depend on the actual facts expressed in its premise and conclusion, but only on its form. An implication
can be a ‘physical necessity’ if it is true due to physical laws, but here are
still facts involved: Only if an implication is true in an ‘arbitrarily hypothetical
universe, a creation of a mind’, i.e. it is true in ‘every state of things whatsoever’, then it is a necessary implication. Moreover, considering hypothetical
universes ﬁts very well into the contemporary tarski-style approach to logic
and model-theory, where the diﬀerent states of things, the diﬀerent universes
of discourses are mathematically captured by (usually relational) models, and
an implication is true (a better word in mathematical logic would be ‘valid’)
if it holds in every model.

Peirce had been a mathematician on its own, having a deep respect for mathematics and their kind of reasoning (in 4.235, he appraises the mathematicians
as follows: ‘Mathematicians alone reason with great subtlety and great precision.’ It is important to understand the role mathematics plays among the
sciences in Peirce’s philosophy. In 4.232, he explains his view what the ‘true
essence of mathematics’ is: ‘For all modern mathematicians agree with Plato

4.1 Foundations of Knowledge and Reasoning

29

and Aristotle that mathematics deals exclusively with hypothetical states of
things, and asserts no matter of fact whatever; and further, that it is thus
alone that the necessity of its conclusions is to be explained.’ Dealing not with
actual facts, but exclusively with hypothetical states of things is the essence
of mathematics, not shared with any other science. In his Cambridge lectures
([Pei92]), lecture one, Peirce provides a classiﬁcation of science which is based
on their level of abstraction: A science is placed above a second one if the
second science adopts the principles of the ﬁrst science, but not vice versa.
Mathematics is the science at the top of this classiﬁcation ‘for this irrefutable
reason, that it is the only of the sciences which does not concern itself to
inquiry what the actual facts are, but studies hypotheses exclusively.’ In this
sense, even philosophy is more concrete than mathematics, as it is ‘a search
for the real truth’ and as ‘it consequently draws upon experience for premises
and not merely, like mathematics, for suggestions.’ As mathematics is the
only science which does not deal with facts, but with hypothetical universes,
it is clear why Peirce identiﬁes necessary and mathematical reasoning. He
explicates this very clearly in his lectures when he says that ‘all necessary
reasoning is strictly speaking mathematical reasoning.’

In 4.425–4.429, Peirce makes clear that mathematical reasoning is by no means
a mere application of some static inference rules. He starts his observations
with an examination of the syllogisms of Aristotle from which he says that
the ‘ordinary treatises on logic [. . .] pretend that ordinary syllogism explains
the reasoning of mathematics. But if this statement is examined, it will be
found that it represents transformations of statements to be made that are not
reduced to strict syllogistic form; and on examination it will be found that it
is precisely in these transformations that the whole gist of the reasoning lies.’
When Peirce wrote these sentences, after an absolute dominance of syllogism
which lasted for more than two thousand years, new approaches to a formal
theory of logic and necessary reasoning emerged. Peirce, as a researcher in
this ﬁeld, was of course aware of these approaches. In these paragraphs, he
mentions Schr¨oder, Dedekind, and his own systems. In other places, he discusses (and extends) Boole’s approach to a large extend. But none of these
approaches are comprehensive enough or even suﬃcient to capture the whole
realm of reasoning, that is ‘that the soul of the reasoning has even here not
been caught in the logical net’ (4.426). And even more explicit, in the beginning
of the 4.425, he writes:

But hitherto nobody has succeeded in giving a thoroughly satisfactory logical analysis of the reasoning of mathematics.[. . .] yet nobody
has drawn up a complete list of such rules covering all mathematical
inferences. It is true that mathematics has its calculus which solves
problems by rules which are fully proved; but,[. . .] every considerable
step in mathematics is performed in other ways.

30

4 The Role of Existential Graphs in Peirce’s Philosophy

We see that there is no comprehensive theory of mathematical reasoning.
Moreover, Peirce is aware that mathematician are human beings which may
make mistakes in their reasoning. In [Pei92], lecture 4, he writes: ‘Theoretically, I grant you, there is no possibility of error in necessary reasoning. But
to speak thus ‘theoretically’, it is to use language in a Pickwickian sense. In
practice and in fact, mathematics is not exempt from the liability to error
that aﬀects everything that man does’ (emphasis by Peirce). In the light of
these observations, the question arises why Peirce had so much trust in the
reliability and certainty of mathematical reasoning.

The clue is ‘this marvellous self-correcting property of Reason’, as Peirce says
in [Pei92]. Reasoning is a conscious process which in turn can be subject
of inspection, criticism, or reasoning itself. This ability of self-criticism3 is
crucial to call any inference-process ‘reasoning’; it distinguishes reasoning from
a mere, mechanical application of inference rules to obtain conclusions from
to premises. In 1.606 (a work titled ‘ideals of conduct’), Peirce expresses this
point: ‘For reasoning is essentially thought that is under self-control. [. . .] You
will nevertheless remark, without diﬃculty, that a person who draws a rational
conclusion, not only thinks it to be true, but thinks that similar reasoning
would be just in every analogous case. If he fails to think this, the inference
is not to be called reasoning.’ The ability of self-control includes the ability of
self-criticism: ‘But in the case of reasoning an inference which self-criticism
disapproves is always instantly annulled, because there is no diﬃculty in doing
this’ (1.609).

The ability of self-criticism implies an important consequence. The conclusions
of some train of reasoning are not simply granted for true: They are observed
and veriﬁed. The veriﬁcation of the truth of the conclusion may fail. In this
case, the reasoning has to be corrected. The correction not only concerns the
result of the reasoning: The assumptions the reasoning started with, even
if they had been taken for true so far, may be corrected, too. In [Pei92],
Peirce’s writes: ‘I can think of, namely, that reasoning tends to correct itself,
and the more so the more wisely its plan is laid. Nay, it not only corrects its
conclusions, it even corrects its premises.’

Peirce distinguishes between three modes of reasoning. Induction concludes
its conclusion from a suﬃcient large amount of facts; that is, the conclusion is
an approximate proposition which generalizes and explains these facts. This
is the mode of inquiry which occurs as main mode of reasoning in sciences
which are based on experiments. Induction leads to truth in the long run of
experience.

3 Self-reference and self-criticism are based on a speciﬁc kind of abstraction, a
shift of the observing level from the use of (linguistic) items to their observation.
It should be noted that it is this shift of levels which underlies Peirce’s already
mentioned conception of hypostatic abstraction, where a former collection of items
is considered to be a new, singular item of its own.

4.1 Foundations of Knowledge and Reasoning

31

Deduction concludes its conclusion not from the content of the premises, but
from the form of the argumentation. It may happen that the conclusion does
not necessarily follow from the premises: It can only be concluded to a certain
probability. In contrast to probable deduction, necessary deduction always
leads from true premises to true conclusions. Thus, necessary deduction corresponds to necessary reasoning. It is worth to note that, according to Peirce,
even deductive inquiry is based on experiments too, namely on mental experiments. Roughly speaking, induction is based on many experiments in the real
world, and deduction is based on one experiment in the mind.4

Finally, besides induction and deduction, abduction is a creative generation
of a new hypothesis and its provisional adoption. For a hypothesis which is
obtained by abduction, its consequences are capable of experimental veriﬁcation, and if further, new experiments contradict the hypothesis, it will be
ruled out.

In induction and abduction, the conclusions are hypothetical, thus it is clear
that these modes of reasoning tend to correct themselves. But this applies
to deduction as well. Already at the beginning of lecture 4 in [Pei92], Peirce
says that ‘deductive inquiry, then, has its errors; and it corrects them, too’,
and two pages later he concludes ‘that inquiry of every type, fully carried out,
has the vital power of self-correction and of growth.’ Now we see why Peirce
was convinced that mathematical reasoning is such reliable: ‘The certainity of
mathematical reasoning, however, lies in this, that once an error is suspected,
the whole world is speedily in accord about it.’

The last quotation sheds a new light to another important aspect in Peirce’s
theory of reasoning and knowledge, namely the importance of a rational community (the ‘whole world’ [of mathematicians] in the quotation above). In
Peirce’s understanding, knowledge is a collective achievement. It grows by
means of communication between human beings, where the results of reasoning are critically observed and discussed. In any moment, the community possesses certain information, obtained from previous experiences, whose
results are analyzed by means of reasoning, i.e. deduction, induction, and
abduction. Informations are conscious cognitions, and Peirce speaks of ‘the
cognitions which thus reach us by this inﬁnite series of inductions and hypotheses’ (5.311). This process leads from speciﬁc information to more general information, and to the recognition of the reality and truth in the long
run. In fact, there is no other way than just described to reach a knowledge
of reality: In 5.312, Peirce continues: ‘Thus, the very origin of the conception of reality shows that this conception essentially involves the notation of

4 Mathematical reasoning and diagrammatic reasoning are synonymous for Peirce.
In [Eis76], we ﬁnd an often quoted passage where the use of experiments in
diagrammatic reasoning is explained as follows: ‘By diagrammatic reasoning, I
mean reasoning which constructs a diagram according to a precept expressed in
general terms, performs experiments upon this diagram, notes their results, [. . .]
and expresses this in general terms.’

32

4 The Role of Existential Graphs in Peirce’s Philosophy

a COMMUNITY , without deﬁnite limits, and capable of a deﬁnite increase
of knowledge’ (emphasis by Peirce). We see that knowledge growths by use
of rational communication in a community. It is worth to note that even reasoning carried out by a single person can be understood to be a special kind
of rational communication as well. In 5.421, ‘What Pragmaticism Is‘, 1905,
Peirce says: ‘A person is not absolutely an individual. His thoughts are what
‘he is saying to himself ’, that is, is saying to that other self that is just coming into life in the ﬂow of time’, or in 7.103 he explains: ‘In reasoning, one is
obliged to think to oneself. In order to recognize what is needful for doing this
it is necessary to recognize, ﬁrst of all, what ”oneself” is. One is not twice
in precisely the same mental state. One is virtually [. . .] a somewhat diﬀerent
person, to whom one’s present thought has to be communicated.’

4.2 Existential Graphs

The discussion so far show up some essential aspects of reasoning: It is selfcontrolled and self-critical, and it takes places in a community by means of
rational communication. For this reason, we need an instrument which allows
to explicate and investigate the course of reasoning as best as possible. This
is the purpose of EGs, as it is clearly stated by Peirce in 4.248–4.429:

Now a thorough understanding of mathematical reasoning must be a
long stride toward enabling us to ﬁnd a method of reasoning about
this subject as well, very likely, as about other subjects that are not
even recognized to be mathematical.

This, then, is the purpose for which my logical algebras were designed
but which, in my opinion, they do not suﬃciently fulﬁll. The present
system of existential graphs is far more perfect in that respect, and
has already taught me much about mathematical reasoning. [. . .]

Our purpose, then, is to study the workings of necessary inference.

This has already been realized by Roberts: He writes in [Rob73] that ‘The
aim [of EGs] was not to facilitate reasoning, but to facilitate the study of
reasoning.’ In the beginning of this chapter, it has already been said that
Peirce’s life-long aim was the investigation of reasoning and knowledge. For
him, his EGs turned out to be the right instrument for making necessary
reasoning explicit (much better than language), thus the investigation of EGs
is the investigation of necessary reasoning. From this point of view, the central
place of EGs in Peirce’s philosophy becomes plausible. Moreover, due to the
discussion so far, the design of EGs can be explained as well.

The quotation I have just provided continues as follows: ‘What we want, in
order to do this, is a method of representing diagrammatically any possible set

4.2 Existential Graphs

33

of premises, this diagram to be such that we can observe the transformation
of these premises into the conclusion by a series of steps each of the utmost
possible simplicity.’ We have already seen that deductive inquiries are for
Peirce mental experiments. In these experiments, we are starting with some
facts, and rearrange these facts to obtain new knowledge. First of all, diﬀerent pieces of information are brought together, that is, they are colligated.
Then, sometimes, informations are duplicated (or vice versa: redundant information is removed), or some other information which is not needed anymore
is erased. These are for Peirce the general ﬁgures of reasoning: ‘Precisely those
three things are all that enter in the Experiment of any Deduction — Colligation, Iteration, Erasure. The rest of the process consists of observing the
result.’ [Pei92]. It is this understanding of reasoning which underlies Peirce’s
permission rules, i.e. erasure and insertion, iteration and deiteration, and double cut. These rules are the patterns reasoning is composed of.5

The purpose of the rules is to explicate a reasoning process a posteriori, to
explain and allow to make mental experiments on diagrams which explicate
the premises of the reasoning process, but not to aid the drawing of inferences.
In 4.373, he writes:

The ﬁrst requisite to understanding this matter is to recognize the
purpose of a system of logical symbols. That purpose and end is simply and solely the investigation of the theory of logic, and not at all
the construction of a calculus to aid the drawing of inferences. These
two purposes are incompatible, for the reason that the system devised for the investigation of logic should be as analytical as possible,
breaking up inferences into the greatest possible number of steps, and
exhibiting them under the most general categories possible; while a
calculus would aim, on the contrary, to reduce the number of processes
as much as possible, and to specialize the symbols so as to adapt them
to special kinds of inference.

Peirce has a very precise understanding of the term ‘calculus’ (probably based
on Leibniz’ idea of a ‘calculus ratiocinator’). A calculus is not simply a set of
(formal) rules acting on a system of symbols. For him, the purpose is essential,
and the purpose gives a set of rules its shape. The purpose of a calculus is
to support drawing inferences. Thus, the derivations in a calculus are rather
short, and the inference steps are rather complicated, because it is the goal
to reach the conclusion as fast as possible. A calculus is a synthetical tool. In
contrast to that, the goal of Peirce’s rules is to exhibit the steps of a reasoning
process. Thus, the rules are rather simple and correspond the general patterns
of reasoning, and the derivations ‘dissect the operations of inference into as
many distinct steps as possible’ (4.424). Peirce’s rules are an analytical tool.

5 In [Shi02a], Shin argues that Peirce’s transformation rules are not fully developed
in an iconic manner, and she poses the question why Peirce himself did not fully
exploit the iconic features of EGs. This might be an answer to her.

34

4 The Role of Existential Graphs in Peirce’s Philosophy

They allow to discuss and critizise any reasoning best. For this reason, Peirce
emphasizes that his system ‘is not intended as a calculus, or apparatus by
which conclusions can be reached and problems solved with greater facility
than by more familiar systems of expression’ (4.424).

Comment: Ironically, compared to the rules of contemporary calculi for ﬁrst order
logic (like natural deduction), the rules for Peirce’s EGs turn out to be rather complex. Moreover, nowadays it is often said that a main advantage of Peirce’s rules is
that they allow to draw very short inferences. An heuristic argument for this claum
is given by Sowa in his commentary on Peirce’s MS 514. Sowa provides an proof
for Leibniz’s Praeclarum Theorema (splendid theorem) with Peirce’s rules, which
needs 7 steps, and writes later on: ‘In the Principia Mathematica, which Whitehead
and Russell (1910) published 13 years after Peirce discovered his rules, the proof of
the Praeclarum Theorema required a total of 43 steps, starting from ﬁve non-obvious
axioms. One of those axioms was redundant, but the proof of its redundancy was not
discovered by the authors or by any of their readers for another 16 years. All that
work could have been saved if Whitehead and Russell had read Peirce’s writings on
existential graphs.’

In [Dau06c], a mathematical proof that Peirce’s rules allow fairly short proofs is provided. In this work, proofs for Statman’s formulas are investigated. It is known that
size of their proofs in (cut-free) sequent calculi increases exponentially. In contrast
to that, in [Dau06c], it has been shown that for Statman’s formulas, there exists
proofs with with Peirce’s rules (without using the erasure-rule) whose size increases
polynomially. In Peirce’s calculus, the erasure rule is the only rule which, similarly
to the cut-rule in sequent calculi, does not satisfy the so-called ﬁnite choice property.
That is, roughly speaking, Peirce’s rules (without the erasure rule) are as nice as the
rules of cut-free sequent calculi and as fast as sequent calculi including the cut-rule.

As we have just discussed the purpose and the design of the rules, we will now
explore the form and appearance of EGs. I have already quoted 4.431, where
Peirce states that necessary reasoning is about assertions in an ‘arbitrarily
hypothetical universe, a creation of a mind.’ Reasoning can be understood as a
rational discourse, and such a discourse takes always place in a speciﬁc context,
the universe of discourse. It is essential for the participants of a discourse to
agree on this universe. This is explicated by by Peirce in Logical Tracts. No. 2.
‘On Existential Graphs, Euler’s Diagrams, and Logical Algebra’, MS 492,
where he writes: ‘The logical universe is that object with which the utterer
and the interpreter of any proposition must be well-aquainted and mutually
understand each other to be well acquainted, and must understand that all
their discourse refers to it.’ EGs are an instrument to make reasoning explicit.
The universe of discourse is represented the system of EGs by the sheet of
assertion. This function of the sheet of assertion is described in in 4.396 by
Peirce as follows: ‘It is agreed that a certain sheet, or blackboard, shall, under
the name of The Sheet of Assertion, be considered as representing the universe
of discourse [. . .].’

Using a sheet of assertion for representing the universe of discourse is no
accident, but a consequence of Peirce’s purpose –making reasoning explicit–
of EGs. This is explained by Peirce in 4.430 as follows:

4.2 Existential Graphs

35

What we have to do, therefore, is to form a perfectly consistent method
of expressing any assertion diagrammatically. The diagram must then
evidently be something that we can see and contemplate. Now what
we see appears spread out as upon a sheet. Consequently our diagram
must be drawn upon a sheet. We must appropriate a sheet to the
purpose, and the diagram drawn or written on the sheet is to express
an assertion. We can, then, approximately call this sheet our sheet of
assertion.

An empty sheet of assertion represents the very beginning of a discourse, when
no assertions so far are made. A diagram represents a proposition, and writing
the diagram on the sheet of assertion is to assert it (that is, the corresponding
proposition). Peirce had a very broad understanding of the term ‘diagram’ (see
for example [Dau04c, Shi02a]), so the question arises how the diagrams should
look like. As diagrams have to be contemplated, the underlying goal is that ‘a
diagram ought to be as iconic as possible; that is, it should represent relations
by visible relations analogous to them ’ (4.433). This goal induces some design
decisions Peirce has made in the development of existential graphs.

Peirce continues in 4.433 with an example where two propositions can be taken
for true, that is, each of them may be scribed on the sheet of assertion. Let us
denote them by P1 and P2. Now it is a self-suggesting idea that both P1 and P2
may be written on diﬀerent parts of the sheet of assertion. We then see that P1
and P2 are written on the sheet of assertion, and it is very natural to interpret
this as the assertion of both P1 and P2. Writing two graphs on the sheet of
assertion is called juxtaposing these graphs, and we have just seen that the
juxtaposition of graphs is a highly iconical representation of their conjunction
(to be very precisely: the conjunction of the propositions which are represented
by the graphs).6 Note that the juxtaposition of graphs is a commutative and
associative operation, thus the commutativity and associativity of conjunction
is iconically captured by its representation and has –in contrast to linear forms
of logic– not to be covered by rules.

There are several places where Peirce discusses the iconicity of the line of
identity. Assume that each of the letters A and B stands for a unary predicate,
i.e. we have to complete each of them by an object to obtain a proposition
which is false or true (mathematically spoken: A and B are the names of

6 Before Peirce’s invention of existential graphs, he worked shortly on a system
called entitative graphs. In this system, the juxtaposition of two graphs is interpreted as the disjunction of the graphs. Peirce realized that this interpretation
is counter-intuitive, so he switched to to interpreting the juxtaposition as a conjunction. See [Rob73] for a thorough discussion.

36

4 The Role of Existential Graphs in Peirce’s Philosophy

relations with arity 1). Assume we know that both A and B can be completed
by the same object in order to get a true proposition? In 4.385, Peirce answers
as follows:

A very iconoidal way of representing that there is one quasi-instant
[the object] at which both A and B are true will be to connect them
with a heavy line drawn in any shape, thus:

or

If this line be broken, thus

, the identity ceases to be asserted.7

(A very similar argumentation can be found in 4.442.) In 4.448, he argues that
a line of identity is a mixture of a symbol, an index and an icon. Nonetheless,
although Peirce does not think that lines of identity are purely iconic, he concludes 4.448 with the following statement: ‘The line of identity is, moreover,
in the highest degree iconic.’

In necessary reasoning, Peirce focuses on implications. In the system of existential graphs, a device of two nested cuts, a scroll, can be read as an implication. For example,

is read ’A implies B’. Reading a scroll as implication is usually obtained from
the knowledge that cuts represent negation, i.e., the graph is literally read ‘it
is not true that A holds and B does not hold’, which is equivalent to ’A implies
B’. In 4.376–4.379, Peirce discusses how implications have to be handled in
any logical system, and he draws the conclusion that syntactical devices are
needed which allows to separate the premise from the sheet of assertion resp.
the conclusion from the the premise, and he argues that this syntactical device
negates the part of the implication which is separated by it. Separating a part
of a graph which is written on the sheet of assertion is represented on a sheet
by a closed line. For this reason, he added the cut as a syntactical devise to
graphs, and due to the argument he has provided before, he concludes that
the cut negates the enclosed subgraph.

We see that the design, the appearance of EGs is, similarly to the design of the
rules, driven by Peirce’s purpose to provide an instrument for investigating
reasoning.

7 The two lines of identity may denote distinct objects, but this is not necessary,

i.e., they are still allowed to denote the same objects as well.

ABABABBA4.3 Conclusion

4.3 Conclusion

37

To conclude this chapter, it shall be remarked that Peirce himself stresses in
4.424 that his purpose for EGs has not to be confused with other purposes. We
have already seen that EGs are not intended as a calculus. Moreover, Peirce
stresses that ‘this system is not intended to serve as a universal language for
mathematicians or other reasoners.’ A universal language is intended to describe only one, i.e., ‘the’, universe. In a universal language, the signs have a
ﬁxed, deﬁnite meaning. i.e. there are no diﬀerent interpretations of a sign.8
But EGs are about arbitrarily hypothetical universes, and they have to be
interpreted in a given universe of discourse (Peirce describes the handling
of EGs by means of a communication between a so-called graphist, who asserts facts by scribing and manipulating appropriate graphs on the sheet of
assertion, and a so-called grapheus or interpreter9, who interprets the graphs
scribed by the grapheus and checks their validity in the universe of discourse).
Thus it is clear that EGs cannot serve as a universal language.

Moreover, although EGs are intended to provide an instrument for the investigation of reasoning, it is important for Peirce that the psychological aspects of
reasoning are not taken into account.10 Finally, Peirce writes that ‘although
there is a certain fascination about these graphs, and the way they work is
pretty enough, yet the system is not intended for a plaything, as logical algebra has sometimes been made.’ After we have elaborated in this chapter why
Peirce placed his EGs into the very center of his philosophy, this assessment
is by no means surprising.

8 This was Frege’s intention when he invented his Begriﬀsschrift.
9 Due to Peirce’s understanding that reasoning is established by communication,
the graphist and grapheus may be diﬀerent mental states of the same person.
10 Susan Haack distinguishes in her book ‘philosophy of logics’ ([Haa78]) three approaches to logic: strong psychologism, where ‘logic is descriptive of mental processes’, weak psychologism, where ‘logic is prescriptive of mental processes (it
prescribes how we should think’, and anti-psychologism, where ‘logic has nothing
to do with mental processes’, and names Kant Peirce and Frege as examples for
these three approaches, respectively.

5

Formalizing Diagrams

There are some authors who explored EGs, e.g. Roberts, Shin, Sowa, or Zeman. In all elaborations of EGs, it is claimed that the Alpha part corresponds
to propositional calculus, and the Beta part corresponds to ﬁrst order predicate logic, that is, ﬁrst order logic with predicates and identity, but without
object names and function names. Propositional calculus and ﬁrst order predicate logic are comprehensively elaborated mathematical theories, thus this
claim has to be understood in a mathematical manner. In other words: The
system of EGs has to be formalized in a fashion which suits the needs and
rigor of contemporary mathematics, and the correspondence between EGs and
mathematical logic has to be elaborated and proven mathematically.

Peirce distinguished between graphs and their graphical representations,
termed graph-replicas. Not all authors employ this distinction in their elaborations, i.e., they treat graphs like they are the graphical representations.
This approach leads to diﬃculties in the formalization of EGs. In Sect. 5.1,
some of the problems which occur in this handling of EGs are analyzed. In
order to do this, the approach of Shin (see [Shi02a]) will be used. Besides
the missing distinction between EGs and their graphical representations, it
will turn out that Shin’s deﬁnition of EGs are, from a mathematical point of
view, informal, which leads to problems as well. In fact, due to this problems,
Shin’s (and some authors as well) elaboration of EGs is from a mathematicians point of view insuﬃcient and cannot serve as diagrammatic approach to
mathematical logic. I will argue that a separation between EGs as abstract,
mathematical structures and their graphical representations is appropriate. A
question which then arises immediately is how the graphical representations,
i.e. the graph replicas, should be deﬁned and handled.

One might suspect that the graph replicas should be mathematically deﬁned
as well, but in Secs. 5.2 it will be shown that a mathematical formalization of
the graphical representations may cause a new class of problems. In Sect. 5.3
we will discuss why the symbolic approach to mathematical logic does not have

40

5 Formalizing Diagrams

to cope with problems which arise in diagrammatic systems. It will turn out
that the preciseness of mathematical logic is possible although the separation
between formulas and their representations is usually not discussed. From
this result we draw the conclusion that a mathematical formalization of the
diagrammatic representations of EGs is not needed: It is suﬃcient to provide
conventions how the abstract structures are represented. This result and the
outcomes of the discussion in the preceding sections are brought together in
Sect. 5.4 in order to describe a second approach for a mathematical foundation
of diagrams, which will be used in this treatise.

5.1 Problems with Existential Graphs Replicas

To illustrate some of the problems which may occur in the handling of diagrams, we focus on the EGs as they are described in the book of Shin
([Shi02a]). We start the discussion with Shin’s deﬁnitions for alpha and beta
graphs.

Informal Deﬁnition 5.1 (Alpha Graphs) The set of alpha graphs, Gα, is
the smallest set satisfying the following:

1. An empty space is in Gα.
2. An sentence symbol is in Gα.
3. Juxtaposition closure

If G1 is in Gα, . . ., and Gn is in Gα, then the
juxtaposition of these n graphs, i.e. G1, . . . , Gn, (we write ’G1 . . . Gn’ for
juxtaposition) is also in Gα.

4. Cut closure

If G is Gα, then a single cut of G (we write ’[G]’ following

Peirce’s linear notation) is also in Gα.

Informal Deﬁnition 5.2 (Beta Graphs) The set of beta graphs, Gβ, is the
smallest set satisfying the following:

1. An empty space is in Gβ.
2. A line of identity is in Gβ.
3. Juxtaposition closure

If G1 is in Gβ, . . ., and Gn is in Gβ, then the
juxtaposition of these n graphs, i.e. G1, . . . , Gn, (we write ’G1 . . . Gn’ for
juxtaposition) is also in Gβ.

4. Predicate closure

If G is in Gβ, then a graph with an n-ary predicate

symbol written at the joint of n loose ends in G is also in Gβ.

5. Cut closure

If G is in Gβ, then a graph in which a single cut is drawn

in any subpart of G without crossing a predicate symbol is also in Gβ.

5.1 Problems with Existential Graphs Replicas

41

6. Branch closure If G is in Gβ, then a graph in which a line of identity in

G branches is also in Gβ.

There are two points remarkable in this deﬁnition:

1. Although some mathematical terms are used, the deﬁnitions are formulated more or less in common spoken language and cannot be seen as
mathematical deﬁnitions.

2. EGs are considered to be graphical entities (this can particularly seen in

the cut closure rule for Beta graphs).1

This approach, particularly the two points mentioned above, yields diﬀerent
kinds of problems which shall be elaborated in this section. We start with
problems caused by the use of common language.

First of all, many important technical terms are deﬁned either in an insuﬃcient
way or not at all. For example, the terms sentence symbol, juxtaposition or
single cut (this holds already for Shin’s deﬁnition of Alpha graphs) as well as
the terms lines of identity, loose ends or branching of LoIs are not deﬁned.
Even if we have some pre-knowledge on terms like ‘single cut’ (e.g. we know
that a single cut is a closed, double-point-free curve on the plane) or LoIs,
these deﬁnitions leave some issues open. E.g., is it not clear whether two cuts
may touch, cross, intersect, or partly overlap, or whether a LoI may terminate
on a cut. For example, we might ask which of the following diagrams are welldeﬁned diagrams of Beta graphs:

Examining the ﬁrst three examples, in Shin’s book we do not ﬁnd any example
of an Beta graph where a LoI terminates on a cut. But, in contrast, this case is
explicitly investigated in Peirce’s manuscripts or in the book of Roberts. The
fourth example is not explicitly excluded by Shin, but it is implicitly excluded
based on the background a reader should have of EGs.

Considering the ﬁfth example, Peirce used to draw to nested cuts, i.e., scrolls,
as follows:
. So it seems that a touching of cuts is allowed. But we can raise
the question whether scrolls should be handled as own syntactical devices, or
whether Peirce’s drawing is a sloppy version of two nested cuts which do not
touch, i.e. of
. So we have to make a decision whether cuts may touch or
not (see the footnote on page 9). Answering these question is not only about
deciding whether a diagram is an EG or not. It is even more important to
have rigor deﬁnitions for all technical terms when transformation rules, e.g.

1 In [HMST02], she revised her approach to diagrammatic reasoning and stresses
that a distinction between abstract structures and graphical representations is
needed.

PPQPQ42

5 Formalizing Diagrams

the rules of a calculus, are applied to EGs. An important example for this
is the in most publications undeﬁned term subgraph. A rule in the calculus
allows us to scribe a copy of a subgraph in the same cut (this is a special case
of the iteration-rule), which occurs in the treatises of Peirce, Shin, Roberts,
and later on in this treatise.

To get an impression of the problems, we raise some simple questions on
subgraphs. Consider the following Alpha graph:

Gα :=

In order to know how the iteration-rule can be applied, it must be possible

to answer the following questions: Is

a subgraph of Gα? Is

a subgraph of Gα? Do we have one or two subgraphs

of Gα
(this is a question which corresponds to the distinction between subformulas
and subformula instances in FO)?

For Beta, it is important to know how LoIs are handled in subgraphs. Consider
the following Beta graph:

Gβ :=

We might ask which of the following diagrams are subgraphs of Gβ:

Shin (and most other authors) does not oﬀer a deﬁnition for subgraphs: The
answer of the questions above is left to the intuition of the reader. From the
discussion above, we draw a ﬁrst conclusion:

Thesis 1: The deﬁnitions of Shin (and some other authors) are insufﬁcient for a precise understanding and handling of existential graphs.

If EGs are considered as graphical entities, i.e., if no distinction between graphs
and graph-replicas in employed, a new class of diﬃculties has to be coped
with. Consider again Gα. Remember that the iteration-rule should allow us
to draw a copy of the subgraph
into the outer cut. But if we want to
understand EGs and subgraphs as (graphical) diagrams, then this is obviously
not possible, because in the outer cut, there is simply not enough space left
. But, of course, this is not intended by the rule, and
for another copy of

everybody who is familiar with EGs will agree that

is a

result of a valid application of the iteration-rule. Why that? The idea behind

AABBAAAQPRQPRQPRQPRAAAAAB5.1 Problems with Existential Graphs Replicas

43

is that we may change the shape of LoIs or cuts to a ’certain degree’ without
changing the meaning of an EG. For this reason it is evident that any attempt
which tries to deﬁne EGs as purely graphical entities runs into problems.

For a discussion of the term ’certain degree’, consider the three Alpha graphs
in Fig. 5.1. From the left to the right, we decrease the size of the outer cut.

Fig. 5.1. Diagrams of Alpha graphs

There are obviously visual diﬀerences between these three diagrams. The question is whether the diﬀerences between the ﬁrst two diagrams are comparable
to the diﬀerences between the last two diagrams. We have already seen that
the shape of a cut is – in some sense – of no relevance. The only facts we have
to know is which other items of the graph are enclosed by the cut and which
are not. Thus we see that the ﬁrst two diagrams are (in some sense) the same
graph, particularly they have the same meaning. In contrast to that the third
diagram has a diﬀerent meaning and has therefore to be treated diﬀerently.

If we – due to the visual diﬀerences – treat the ﬁrst two diagrams to be syntactically diﬀerent, we would get a syntax which is much too ﬁne-grained.
Any kind of equivalence between graphs would be postponed to the semantical level. Furthermore, we would need transformation rules which allow to
transform the ﬁrst graph into the second graph (and vice versa). This syntax
would become very complicated and nearly unusable. Thus we see that any
appropriate syntax should not distinguish between the ﬁrst two diagrams.

Now the question arises which properties of the ﬁrst two diagrams cause us
to identify them. Should we syntactically identify graphs when they have the
same meaning? This would inappropriately mix up syntax and semantics. For
example, the empty sheet of assertion and the graph
have the same
meaning, but they should obviously be syntactically distinguished.

In deﬁning a reasonable syntax for the graphs, we see that we have to dismiss
certain graphical properties of the diagrams (e.g. the form of a cut), while
other properties are important (e.g. the number of cuts and other items, or
whether an item of the diagram is enclosed by a cut or not). Particularly, in
any formalization, EGs should not be understood as graphical entities at all.
Instead of this, we have, according to Peirce’s distinction between graph and
graph-replicas, to distinguish between graphs as abstract structures and the
diagrams which represent the graphs.

When we employ a distinction between EGs and their replicas, we have to
investigate which graphical properties in a diagram represent facts of the

AABAABAAB44

5 Formalizing Diagrams

represented structure, and which not (this has already been discussed at the
end of Sect. 3.2). In other words: When are two diagrams replicas of the same
EG? Peirce explicitly said that arbitrary features of the diagrams may vary,
as long as they represent the same EG. At the beginning of [Pei35] he says:

Convention No. Zero. Any feature of these diagrams that is not expressly or by previous conventions of languages required by the conventions to have a given character may be varied at will. This ”convention” is numbered zero, because it is understood in all agreements.

A similar explication is his ‘Rule of Deformation’ in 4.507, where he says that
‘all parts of the graph may be deformed in any way, the connexions of parts
remaining unaltered; and the extension of a line of identity outside a sep2 to an
otherwise vacant point on that sep is not to be considered to be a connexion.’.
For LoIs, he says even more explicit in [Pei35] that ‘its shape and length are
matters of indiﬀerence’, and ﬁnally, in 4.500 we ﬁnd that ‘Lines of Identity
are replicas of the linear graph of identity’. Particularly the last quotation is
illuminating, as it makes very clear that a deformation of a line of identity is
indeed only a change in the representation, but not a change in the represented
graph. From this we can conclude that the other mentioned deformations (for
example, changing the shape of a cut) are mere changes in the representation
of a ﬁxed, represented EG. Due to this understanding, the ﬁrst two diagrams
in Fig. 5.1 are not diﬀerent graphs with the same meaning, but diﬀerent
representations, i.e., diagrams, of the same graph, and the third diagram is a
representation of a diﬀerent graph. Similarly, the following diagrams are all
replicas of the same beta graph.

Please note that the line of identity in the right diagram terminates on a
cut. Even in this case, the diagram is still a replica of the same EG, as ‘the
extension of a line of identity outside a sep to an otherwise vacant point on
that sep is not to be considered to be a connexion’. But those diagrams can
easily be transformed such that LoIs terminating on a cut do not occur, while
they still represent the same EG. We will come back to LoI terminating on a
cut in Chpt. 11.

The important distinction between graphs graph replicas is summarized in
the next conclusion:

Thesis 2: EGs should not be deﬁned as graphical entities. Instead
of that, we need a deﬁnition of EGs which copes exactly the crucial

2 Recall that ‘sep’ is another word Peirce used for cut.

RPQPQRQRP5.2 The First Approach to Diagrams

45

features of EGs, and the diagrams should be understood as (mere)
representations of an underlying EG.

As the distinction between graphs and graph-replicas corresponds to the distinction between types and tokens, roughly sketched, we now have the following situation:

corresponds to
-
(cid:27)

Type
6
represents

corresponds to
-
(cid:27)

Token

| {z }
Semiotics

Ex. Graph
6
represents

Ex. Graph Replica

|

{z
Peirce

}

corresponds to
-
(cid:27)

corresponds to
-
(cid:27)

Math. Structure

6
represents

Diag. Represent.

|

{z
This Treatise

}

5.2 The First Approach to Diagrams

One of the most important features of mathematics is its preciseness. The
preciseness of mathematics is based on a very strict understanding of mathematical deﬁnitions and proofs. We have seen that the informal deﬁnitions
of EGs lead to problems in their understanding and handling. Moreover, the
claim that the Alpha and Beta part of EGs correspond to propositional calculus ﬁrst order predicate logic, resp., lead to the conclusion that EGs should be
deﬁned as mathematical structures, and the diagrams are representations for
these structures. This approach raises the question whether the graph replicas, i.e., the diagrams of EGs, should be deﬁned mathematically as well. This
approach shall be discussed in this section.

Let us assume in this section that we want to deﬁne the graphical representations of Alpha or Beta graphs mathematically. Then we would have two
diﬀerent kinds of objects: Mathematical structures which model EGs, and
mathematical structures which model the representations of EGs, i.e., the
diagrams. Let us call the ﬁrst structures type-structures and the second structures token-structures. In ﬁnding a deﬁnition for the token-structures, we have
two fundamental issues to cope with: First to ﬁnd a deﬁnition for the tokenstructures which encodes the informally given diagrams as best as possible.
Secondly, we have to show how the type-structures are represented by the
token-structures. It should be possible to show that each token-structure represents uniquely a type-structure, and that each type-structure is represented
by at least one token-structure. Let us call these two principal problems representation problem.

An obvious approach is to model the lines of an EG (i.e., the cuts and the
LoIs) as families of curves in the Euclidean plane R2. For example, we can

46

5 Formalizing Diagrams

model each LoI by a smooth, double-point-free curve and each cut by a by a
smooth, double-point-free and closed curve.3 Consider the ﬁst two graphs of
Fig. 5.1. They are two diﬀerent tokens of the same type. Diagrams like these
shall be called type-equivalent (this term is adopted from [HMST02]).

If we deﬁne type-equivalence, we have to refer to the relationship between
types and tokens. But the diagrams can be compared directly as well. If we
consider again the ﬁrst two graphs of Figure 5.1, we see that we have mappings
from the cuts resp. the occurrences of propositional variables from the ﬁrst
graph to the second which fulﬁll certain conditions. For example, the mappings
are bijective and the preserve some entailment-relations (e.g. if an occurrence
of a propositional variable or a cut is enclosed by a cut, then this holds for the
images as well). In some sense, we can say that the ﬁrst graph can be topologically transformed into the second graph. Graphs like this shall be called
diagrammatically equivalent (again, this term is adopted from [HMST02]). If
we have found adequate deﬁnitions for the type- and token-structures as well
as for the relation ‘a token-structure represents a type-structure’, it should be
mathematically provable that being type-equivalent and being diagrammatically equivalent means the same.

In any description of the diagrams, particularly if we provide a mathematical
deﬁnition for them, we have to decide some of the border cases we have discussed in Sect. 5.1. For example, we have to decide whether (and how often)
LoIs may touch cuts, or whether cuts may touch or even intersect each other.
But in no (reasonable) mathematical deﬁnition, we can encode all graphical
properties of a diagram directly (e.g. by curves). This is easiest to see for letters or words, i.e. the occurrences of propositional variables in Alpha graphs
or for the relation names in Beta graphs. Of course the location of the occurrence of a propositional variable in an Alpha graph is important, but neither
the size or the font of the propositional variable will be of relevance. Similar
considerations hold for relation names in Beta graphs. As the shape of propositional variables or relation names should not be captured by the deﬁnition
of the diagrams, it is reasonable to handle these items in a diﬀerent way. The
question arises how much of the properties of these items has to captured by a
deﬁnition of the diagrams. For example, the occurrences of propositional variables in an Alpha graph could be modeled by points or spots of the Euclidean
plane to which we assign the variables. We see that even in a mathematical
deﬁnition for the diagrams, we have to prescind certain graphical features.

On the other hand: If we try to capture graphical properties of diagrams,
some of the items of a diagram will probably be overspeciﬁed. For example,

3 It should be noted that Peirce’s understanding of EGs depends on his understanding of the continuum, and this understanding is very diﬀerent from the set
R. Nevertheless a mathematization of the diagrams as a structure of lines and
curves in R2 is convenient as R2 is the standard mathematization of the Euclidean
plane in contemporary mathematics.

5.2 The First Approach to Diagrams

47

how should a simple line of identity – i.e.,
– be modeled mathematically? We already said that LoI could be modeled by a curve in the Euclidean
plane. But when a diagram is given, it is usually drawn without providing a
coordinate system. Thus, which length should this curve have? Where in the
Euclidean plane is it located? Again we see that we cannot capture a diagram
exactly by a mathematical deﬁnition.

Finally, it is worth to note that we have a couple of (unconscious) heuristics
in drawing diagrams for EGs. A simple example is that pending edges should
be drawn ‘far away enough’ from any relation-signs. To see this, consider the
following diagrams:

The leftmost diagram should be understood as ‘There is thing which is P
which is in relation Q to another thing’, The rightmost diagram should be
understood as ‘There is thing which is P and there is thing which is Q’. But
the readings, thus the meanings, of the diagrams in the middles are not clear.
Thus one will avoid drawing diagrams like these.

Similar considerations have to be taken into account if we think about how the
diagrams are handled further. For example, we have to be careful in the deﬁnition of the relation ‘being diagrammatically equivalent’. To see this, consider
the following simple example which consists of two triples of diagrams:

,

,

and

,

,

.

Peirce treated point on a cut to be placed outside a cut. Thus the ﬁrst three
diagrams are in Peirce’s understanding diﬀerent representations of the same
graph, while the last three diagrams are pairwise not type-equivalent. Hence
an appropriate deﬁnition for EGs should yield that the ﬁrst three graphs are
diagrammatically equivalent, but the last three graphs are not.

Another heuristic is to draw a diagram as simple as possible. Furthermore,
although we have seen that neither the size or the font of the propositional
variable or a relation name will be of relevance, it is clear that the choice of
a font and its size is not arbitrary if a diagram is drawn in a convenient way.
This should became clear with the following three diagrams:

Although all diagrams are representations of the same graph (with the meaning ‘there exists something which is blue, but not small), it is clear that the

PQQPQQPPsmallbluesmallbluebluesmall48

5 Formalizing Diagrams

left-most diagram is the best representation of these three diagrams. Conventions like these cannot by captured by any mathematical deﬁnition.

Moreover, we have to think how any operations with graphs (i.e., with the
type-structures) are reﬂected by their representations. Examples for operations are the juxtaposition of graphs or all transformation rules of a calculus.
Shall these operations be deﬁned on the type- or on the token-level? The discussion in Sect. 5.1 (see the discussion of Fig. 5.1) shows that a deﬁnition
on the type-level is more convenient. Nonetheless, then the question remains
how a operation on the type-level is represented on the token-level. For the
herein investigated system of existential graphs, such a scrutiny is carried out
in Chpt. 21.

Remember that the reason for ﬁnding mathematical deﬁnitions for diagrams
was to solve the representation problem. We wanted to grasp the distinction
between non well-formed and well-formed diagrams, as well as the relationship
between graphs and their diagrams, as best as possible. We have already seen
that we cannot capture all graphical features of a diagram by a mathematical
deﬁnition (the more graphical properties are encompassed by a deﬁnition, the
more technical overhead has to be expected). Now the ﬁnal question is how a
mathematically deﬁned diagram is related to a concrete drawing of a diagram
on a sheet of paper. This is a crucial last step from mathematical objects to
objects of the real world. Thus, even if we provide mathematical deﬁnitions
for the diagrams, we still have a representation problem. The initial representation problem between mathematically deﬁned graphs and mathematically
deﬁned diagrams has shifted to a representation problem between mathematically deﬁned diagrams and diagrams – i.e., drawings – in the real world. A
mathematical deﬁnition for diagrams can clarify a lot of ambiguities, but it
cannot solve the representation problem ﬁnally.

5.3 Linear Representations of Logic

In the last section we have raised some questions concerning the representation
problem, and we have seen that mathematics alone is not enough to solve these
problems. It is likely the often unclear relationship between diagrams and
represented structures which causes mathematicians to believe that diagrams
cannot have a proper place in mathematical argumentation, esp. proofs. It
is argued that only a symbolic system for logic can provide the preciseness
which is needed in mathematical proofs (for a broader discussion of this see
[Shi02a]). It seems that the problems we have discussed in the last section
simply do not occur in mathematics, esp. mathematical logic. In this section

5.3 Linear Representations of Logic

49

we will have a closer look on this. We start with a deﬁnition of the well-formed
formulas of FO.4

Deﬁnition 5.3. The alphabet for ﬁrst order logic consists of the following
signs:

• Variables: x1, x2, x3, . . . (countably many)
• Relation symbols: R1, R2, R3, . . . (countably many). To each predicate sym-

bol Ri we assign an arity ar(Ri) ∈ N.5

• Connectives: ∧, ¬, ∃

• Auxiliary Symbols: ., ,, ( ,).

Deﬁnition 5.4. The formulas of FO are inductively deﬁned as follows:

1. Each variable and each constant name is a term.

2. If R is a predicate symbol with arity n and if t1, . . . , tn are terms, then

f := R(t1, . . . , tn) is a formula.

3. If f 0 is a formula, then f := ¬f 0 is a formula.

4. If f1 and f2 are formulas, then f := (f1 ∧ f2) is a formula.
5. If f 0 is a formula and α is a variable, then := ∃α.f 0 is a formula.

It is easy to capture the idea behind this deﬁnitions: First, we ﬁx a set of
signs, and a formula is a sequence of these signs which has been composed
according to certain rules.

Let us consider the following two strings (the relation name R1 has arity 2):

∃x1.∃x2.R1(x1, x2)
∃x1. ∃x2. R1(x1, x2)

Although these two strings are written in diﬀerent places and although they
look slightly diﬀerent, they clearly represent the same formula. For our considerations, it is worth to raise the question which steps a reader has to pass
from the perception of a string to the identiﬁcation of a formula which is
represented by the string. Roughly speaking, if a reader reads the two strings
above, she passes the following steps:

1. The region on the paper must be identiﬁed where the representation of
the formula is written on. In the example above, this is possible because
we have written the two diﬀerent strings into two diﬀerent lines.

4 The following deﬁnitions are only needed to discuss the type-token-issue for symbolic logic. In Chpt. 18, a more thorough introduction into the notations of symbolic ﬁrst order logic is provided.

5 We set N := {1, 2, 3, . . .} and N0 := N ∪ {0}.

50

5 Formalizing Diagrams

2. In this region, we must be able to identify representations of the signs
which may occur in a formula (e.g. the sign ‘∃’, which appears twice, or
the sign ‘R1’, which appears only once). Nothing else may occur.

3. The representations of the signs must be assembled in a way such that
we are able to identify their ordering on the region. That is: We must be
able to identify the sequence. For our examples, we identify the ordering
of the instances of signs by reading them from left to right.

4. Finally, after we have reconstructed the sequence of signs (internally), we
can check whether this sequence is a well-deﬁned formula, i.e., whether it
is composed with the rules of Deﬁnition 5.4.

In the following, we will use the label (∗) to refer to these four steps. The
process (∗) yields the same result for the two strings above: In both cases,
the lines represent the same sequence of signs, which is in fact a well-formed
formula. Thus every mathematician would (hopefully) agree that these two
strings represent the same (well-deﬁned) formula.

We want to stress that the process of perceiving a representation of a formula
is not ‘deterministic’: It is not clear without ambiguity for each string whether
it represents a formula or not. To see this, consider the following strings (the
‘type-setting problems’ are intended). The question is: Which of these strings
represents a well-deﬁned formula?

∃x1∃.x2.R1(x1,x2)

)

x2
.
∃

,x2

R1(
.
x1
:

∃
x1
∃x1.∃♥.R1(x1, x2)
), ∃..R1x1∃x1(x2x2
∃x1 .∃x2 .R1(x1, x2)

∃x1.∃x2.R1(x1,x2)
∃x1.∃x2.R1(x1, x2)
∃x2 .R1(
∃x1.

x1, x2)

∃

x1.

∃x2.R1(

x1, x2)

(5.1)
(5.2)

(5.3)
(5.4)
(5.5)
(5.6)
(5.7)
(5.8)
(5.9)

In line 5.1, we are neither able to identify the signs, nor to identify their
ordering. That is we cannot pass the steps (2) and (3) of (∗), thus this line
does not represent a formula. In line 5.2, we are able to identify the signs, but
we are not able to identify their ordering. That is we cannot pass the step (3)
of (∗), thus this line does not represent a formula as well. Moreover, it may
be doubted whether step 1 of (∗) can be passed without problems. In line 5.3,
we are able to identify the signs, but one of these signs does obviously not
belong to our alphabet of ﬁrst order logic, thus this line does not represent a
formula. In line 5.4, we are able to identify the signs, all of them belong to

5.3 Linear Representations of Logic

51

to our alphabet of ﬁrst order logic, and we are able to identify their ordering,
that is we reconstruct a sequence of signs of our alphabet. But we see that
this sequence is not build according to our rules (we cannot pass the step
(4) of (∗). ). Thus this line does not represent a formula. In the remaining
lines, it is not uniquely determined whether the lines represent a formula
or not. In line 5.5, the font for the variables has changed. In mathematical
texts, diﬀerent fonts are often used to denote mathematical entities of diﬀerent
kinds, but this is not a general rule. So it depends on the context whether
lines 5.5 or 5.6 are accepted to represent formulas. Using diﬀerent sizes of
a font is usually driven by a speciﬁc purpose. The same holds for the use
of signiﬁcantly diﬀerent distances between signs. It is hardly conceivable to
ﬁnd a purpose for using diﬀerent font sizes or signiﬁcantly diﬀerent distances
in formulas. Thus it is possible, but not sure, that the lines 5.7–5.9 are not
accepted by a mathematician to represent a formula.

In standard books on logic, usually only the last step of (∗) is discussed.
The main reason for this is the following: The linear notation of formulas
corresponds to the way ordinary text is written: Text is assembled of letters
which are written side by side and which are read from left to right. As we are
used to read texts, we are trained as well to read strings which shall represent
formulas. Thus the ﬁrst three steps of (∗) are unconsciously executed when
we perceive a representation of a formula.

But as soon we perceive an unfamiliar representation (like in the strings 5.15.9), we become aware of the whole process described by (∗). We realize that
mathematical structures need representations, and in mathematics we have
a clear separation between structures and their representations. The representations rely on conventions, either implicit or explicit, based on common
cultural background as well as on mathematical socialization, and they are
not fully explicated. Nonetheless, this usually poses no problems: Although
these conventions can never be fully explicated, as long as we provide representations of mathematical structures in accordance to these conventions,
they are strong enough to provide a secure transformation from the external
representation of a structure (e.g. on a sheet of paper or on a blackboard)
into an internal representation of any mathematician, i.e., they refer to the
represented structures in a clear and and non-ambiguous way (as Barwise says
in a broader discussion of representations: ’Every representation indicates a
genuine possibility’ [Bar93]). This yields the next thesis:

Thesis 3: In a mathematical theory, the mathematical structures
need representations. A rigor mathematical theory can be developed
without providing mathematical deﬁnitions for the representations.
Instead of that, it is suﬃcient if we have conventions – either implicit
or explicit — which describe the representations, as well as the relationship between structures and their representations, in a clear and
non-ambiguous way.

52

5 Formalizing Diagrams

5.4 The Second Approach to Diagrams

In Sect. 5.1, we have argued that in literature, EGs are described in an informal
and insuﬃcient way (Thesis 1). Furthermore, we should not mix up graphs
and their representations. Particularly, EGs should be deﬁned as abstract,
mathematical structures and not as graphical entities (Thesis 2). Nonetheless,
we haven’t already solved the question whether the representations should be
deﬁned mathematically as well.

In Sect. 5.2, we presented some diﬃculties when we try to deﬁne the diagrams
mathematically. The arguments of Sect. 5.2 are not strong enough to claim
that a mathematical deﬁnition of diagrams will always run into problems.
In contrast: Finding a appropriate mathematical deﬁnition for the diagrams
should clarify the points mentioned in Sect. 5.1. That is, a mathematical
deﬁnition would make clear without ambiguities which diagrams should be
considered to be well-formed diagrams of EGs, and which not. Furthermore,
the relation between graphs and their representations can be elaborated mathematically as well. But providing mathematical deﬁnitions for the diagrams
may result in a technical overhead or overspeciﬁcation of the formalization
of EGs and their representations, and none mathematical deﬁnition can solve
the representation problem ﬁnally.

In contrast to the attempt to capture the representations by mathematical
deﬁnitions, we have seen in Sect. 5.3 that logic is a rigor mathematical theory,
although the representations of the types in logic, i.e., formulas, are not fully
explicated, but they rely on diﬀerent conventions. This works because these
conventions are mainly based on a common and solid cultural background,
namely the form how text is presented.

We now have two approaches to a representation of EGs. We can adopt the
approach of thesis 3, that is, the way how EGs are graphically represented is
explicated informally in common language. Or, on the other hand, the diagrams are deﬁned mathematically, which is the approach discussed in Sect. 5.2.
Of course, the mathematical deﬁnition should capture as best as possible the
informally provided conventions of the ﬁrst approach. The advantage of a
mathematical deﬁnition is its preciseness, but we gain this preciseness for the
cost of a technical overspeciﬁcation of the diagrams.

Moreover, the discussion in Sect. 5.2 showed that even if a mathematical
deﬁnition of the diagrams is provided, we need (informal) conventions for
drawing diagrams. In both approaches, we have to provide a set of conventions
on how diagrams are written. Roughly speaking: A mathematical deﬁnition
alone cannot capture exactly the diagrams we intend to use. Mathematical
deﬁnitions cannot solve the representation problem.

As already said above, arguments like these are not strong enough to generally discard mathematical deﬁnitions for the token-structures. It has to be
estimated whether a mathematical deﬁnition is really needed, or whether the

5.4 The Second Approach to Diagrams

53

conventions for drawing diagrams and for the relationship between representing diagrams and represented structures can be captured suﬃciently by descriptions in common language. If the latter is possible, we are able to gain
the rigorousness and preciseness of a mathematical theory without a technical
overspeciﬁcation of the diagrams. Thus, for doing logic with diagrams, I claim
that the approach of thesis 3 should be preferred. The program of this treatise
can now be summarized as follows:

We have to deﬁne EGs as abstract, mathematical structures. Particularly, we distinguish between EGs, which are abstract mathematical
structures, and their graphical representations (diagrams). We have
to provide a set of conventions for drawing a diagram of an EG, and
we have to describe the relationship between EGs and their diagrams.
Due to these conventions and descriptions, we will show that each diagram uniquely determines an represented EG, and that each EG can
be represented by a diagram.

6

Some Remarks to the Books of Zeman,
Roberts, and Shin

As already mentioned before, there is some amount of secondary literature
about Peirce’s graphs, including several publications in journals and some
books, written by researchers from diﬀerent scientiﬁc disciplines. In my view,
the main treatises are the books of Zeman ([Zem64], 1967), Roberts ([Rob73],
1973), and Shin ([Shi02a]), 2002). Each of this books focuses on diﬀerent
aspects of existential graphs. This holds for this treatise as well: It cannot cover
all aspects of existential graphs, but focuses on a mathematical elaboration
of existential graphs as a diagrammatic approach to mathematical logic.

In this chapter, the scientiﬁc orientations of the treatises of Roberts, Shin and
Zeman are set out. On the one hand, it will be explicated which aspects of
existential graphs are better described in these treatises than in this one. On
the hand, I discuss from a mathematical point of view some lacks in these
books.

Probably the most prominent book on existential graphs is D. Robert’s ‘The
Existential Graphs of Charles S. Peirce’. This book oﬀers the most comprehensive description of the whole system of existential graphs and its genesis.
Particularly, the gamma part of existential graphs is described to a large
degree. Peirce describes far more features of gamma graphs than than the
broken cuts, which are the main focus of most papers or books which deal
with gamma. Moreover, the predecessor of existential graphs, the entitative
graphs, are described as well. Obviously, Roberts worked through many, many
manuscripts of Peirce, and he justiﬁes his elaboration with a lot of quotations.
Robert’s treatise is deﬁnitely an outstanding work.

From a mathematical point of view, compared to the treatises of Shin and
Zeman, this book is the most insuﬃcient one. Roberts does not provide any
(technical or mathematical) deﬁnitions for existential graphs, neither their
syntax, semantic, nor inference rules, and he relies solely on the graphical
representations of graphs. In the appendix, Roberts provides proofs for the
sound- and completeness of Alpha and Beta in which the rules of the calculus

56

6 Some Remarks to the Books of Zeman, Roberts, and Shin

of Church for propositional logic are translated to derivations in Alpha, and
the rules of the calculus of Quine for ﬁrst order logic are translated to derivations in Beta. But as neither the existential graphs, nor the translations are
deﬁned mathematically, these proofs cannot be understood as strict mathematical proofs. Finally, similar to the treatises of Shin and Zeman, Roberts
does not provide a mathematical, extensional semantics for Peirce’s graphs.

In contrast to Roberts, J. J. Zeman book ‘The Graphical Logic of C. S. Peirce’
is, from a mathematical point of view, the best of the books which are here discussed. Zeman provides a mathematical elaboration of Peirce’s alpha-graphs,
Peirce’s beta-graphs, and the part of Peirce’s gamma-graphs which extend the
beta-part by adding the broken cut.

Zeman does not explicitely discuss the distinction between graphs and graph
replicas. Nonetheless, he deﬁnes existential graphs inductively as abstract
structures. For example, he deﬁnes and explains encircling a given graph X
by a cut as follows:

...

1.1ii Where X is an alpha graph, S(X) is an alpha graph.
...
1.1v The sequence of signs consisting of ’S(’ followed by the name
of the graph X followed by ’)’ names a graph; speciﬁcally, it
names the graph formed by enclosing X by an alpha cut.

We see that Zeman deﬁnes existential graph as sequences of signs which are
graphically depicted.

Like in the other treatises, Zeman does not provide a mathematical, extensional semantics for Peirce’s graphs. Instead of that, he deﬁnes mappings
between the systems Alpha, Beta, Gamma and appropriate systems of propositional, ﬁrst order, and modal logic. These translations from graphs to symbolic are correct, but in my eyes a little bit clumsy (you can ﬁnd a discussion of
this in Shin’s book as well). Zeman’s book is the most formal book among the
books discussed in this chapter. It does not contain a readable introduction
into existential graphs and presupposes some knowledge of them. On the other
hand, it is the most precise elaboration and the only one which explicates the
mathematical relationship between Gamma and modal logic.

Sun Joo Shin treats in her book ’The Iconic Logic of Peirce’s Graphs’ only the
Alpha and Beta part of existential graphs. Her interest in existential graphs is
philosophically driven, and she uses existential graphs as a case study for her
goal to provide a formal approach to diagrammatic reasoning. As the title of
her book suggest, she focuses on the diagrammatic aspects, particularly the
iconicity, of existential graphs. In order to do this, she provides an overview
into the research ﬁeld of diagrammatic reasoning and into the semiotics of
Peirce. Her main critics to the handling of EGs in secondary literature so far
is as follows: ‘Despite the fact that EG is known to be a graphical system, the

6 Some Remarks to the Books of Zeman, Roberts, and Shin

57

iconic features of EG have not been fully implemented either in any existing
reading algorithm [translations from graphs to symbolic logic] or in how the
transformation rules are stated.’ Her goal is to amend this ﬂaw. She compares
symbolic and diagrammatic approaches to mathematical logic and works out
that the ‘long-standing prejudice against non-symbolic representation in logic,
mathematics, and computer science’are due to the fact that diagrammatic
systems are evaluated in terms of symbolic systems. Then, based on her arguments, she reconsiders Alpha and Beta from iconic aspects and rewrite the
reading algorithms, that is, the translations from graphs to symbolic logic, and
the transformation rules in order to improve their iconicity and naturalness.

Unfortunately, as already discussed in Sect. 5.1, her approach lacks mathematical preciseness. First of all, a distinction of graphs and graph replicas
is missing (which is in my eyes very surprising, as Shin elaborates carefully
the semiotic aspects of existential graphs). Secondly, as argued in Sect. 5.1,
the deﬁnitions (and later on, theorems and proofs) she provides cannot be
considered to be mathematical deﬁnitions. In fact, this leads to a mistake in
her reading algorithm, and some of her newly implemented transformation
rules are not sound. The ﬂaw in her her reading algorithm and a possible way,
based on the results of this treatise, to ﬁx it is presented in [Dau06a], and
in the comment below. As done for her reading algorithm in [Dau06a], Shin’s
ﬂaws can be ﬁxed, but they clearly show the lack of mathematical preciseness
in her elaboration. Finally, Shin does not provide an extensional semantics
for Peirce’s graphs: Her reading algorithms are translations to symbolic logic,
thus translations from one formal system to another.

Comment: To make the ﬂaws more precise: On page 128, Shin translates the graph

Gz :=

to FO as follows: ∃x.(P x ∧ ∀y.(x = y ∨ ¬Qy) ∧ Rx) . This formula can be converted
to a s slightly better readable formula as follows, which is denoted by fs:

fs := ∃x.(P x ∧ Rx ∧ ∀y.(Qy → x = y))

In contrast to that, the correct approach of Zeman yields a translation which is
equivalent to

fz := ∃x.∃z.(P x ∧ Rz ∧ ∀y.(Qy → (x = y ∧ y = z)))

It is easy to see that these two translation are not semantically equivalent; we have
fs |= fz., but fz 6|= fs. The mistake in Shin’s reading algorithm can be found in her
rule 2(b). I discussed this with her in personal communication, and Shin reformulates
in a letter her rule as follows:

2(b) If a branch of an LI network crosses an odd number of cuts entirely (i.e.
an odd number of cuts clip an LI into more than one part), then

RPQ58

6 Some Remarks to the Books of Zeman, Roberts, and Shin

(i) assign a diﬀerent type of a variable to the outermost part of each

branch of the LI which joins in the cut, and

(ii) (ii) at the joint of branches (inside the innermost cut of these odd
number of cuts), write vi = vj, where vi and vj are assigned to each
branch (in the above process).

In her transformation rules, the rule NR3(b)(iii), which allows to extend a LoI outwards through an even number of cuts, and the corresponding dual rule NR4(b)(iii)
are not sound. The rule NR3(b)(iii) allows the following, non-valid derivation:

‘

The rule NR5(b), which allows to join two loose ends of identity lines ‘if the subgraphs to be connected are tokens of the same time’, and the corresponding dual
rule NR6(a) are not sound. Although it is not totally clear what exactly is meant
by ‘the subgraphs to be connected are tokens of the same time’, the transformation
rule NR5(b) the following, non-valid derivation:

6|=

Shin wants to provide a diagrammatic system of logic which is precise and
in which the advantages of diagrammatic systems are implemented as best
as possible. Due to the lack of mathematical preciseness and the mistakes in
her reading algorithm and transformation rules, Shin’s book unfortunately
cannot be understood to be a formally precise, diagrammatic approach to
mathematical logic. Nonetheless, her book is an excellent introduction into
the philosophical aspects of diagrammatic reasoning and existential graphs,
and her arguments for the development of diagrammatic systems, for unfolding their speciﬁc advantages, particularly their iconic features, and for an
evaluation to diagrammatic systems which is not based on criteria adopted
from symbolic systems remain true. Particularly, her book is turns out to be
very good help and guide for the implementation of any diagrammatic logic
system.

RRRRPPPP6 Some Remarks to the Books of Zeman, Roberts, and Shin

59

Alpha

7

Syntax for Alpha Graphs

In this chapter, Alpha graphs and some elementary technical terms for them
(like subgraph) are formally deﬁned as abstract, mathematical structures. Due
to the discussion in the last chapters, it is moreover explained how these
structures can be graphically represented.

Alpha graphs are built up from two syntactical devices: sentence symbols and
cuts. We ﬁrst ﬁx the sentence symbols, which we call propositional variables.

Deﬁnition 7.1 (Propositional Variables). Let P := {P1, P2, P3, . . .} be a
countably inﬁnite set of propositional variables .

Alpha graphs are built up from propositional variables and cuts, e.g., by the
rules described in Deﬁnition 5.1. We can try to transform this inductive deﬁnition into a inductive mathematical deﬁnition. This is possible, but here we
deﬁne alpha graphs in one step. Let us brieﬂy discuss what we have to capture
in the mathematical deﬁnition. Consider ﬁrst the two diagrams depicted in
Fig. 7.1.

and

Fig. 7.1. Two Diagrams of the same Alpha graph

According to the discussion in Sec.5.4, these two diagrams represent the same
Alpha graph. We have the same occurrences of propositional variables and
cuts, although the propositional variables are placed in diﬀerent locations
and although the cuts are drawn diﬀerently. Remember that we have said in
the discussion of Fig. 5.1 that the shape of a cut has no relevance. The same

4P4P3P2P3PP1P12P3P2P4P4P3P2PP1P162

7 Syntax for Alpha Graphs

holds in some respect for the location of the occurrence of a propositional
variable. Given a cut, the only fact we have to know which other items of a
graph (cuts or occurrences of propositional variables) are enclosed by this cut
and which are not. For example, in both diagrams of Fig. 7.1 the outermost
cut encloses exactly all other cuts, one occurrence of the propositional variable
P2 and all occurrences of the propositional variables P3 and P4. We will say
more speciﬁcally that the occurrence of the propositional variable P2 and
the two cuts are enclosed directly, while all other enclosed items are enclosed
indirectly, and we will say that the items which are directly enclosed by a cut
are placed in the area of this cut. It is convenient to say that the outermost
items (the outermost cut, the two occurrences of P1 and one occurrence of P2
are placed on the area of the sheet of assertion. This enclosing-relation is the
main structural relation between cuts and the other items of a graph. For this
reason, the two diagrams represent the same alpha graph: We have one-toone-correspondences between the occurrences of the propositional variables
in the left diagram to the propositional variables in the right diagram and
between the cuts in the left diagram to the cuts in the right diagram such
that the enclosing-relation is respected.

Let us consider two further diagrams.

and

Fig. 7.2. Two Diagrams of diﬀerent Alpha graphs

The diagrams in Fig. 7.2 represent two alpha graphs which are distinct from
the graph of Figure 7.1. In the left diagram, we have diﬀerent sets of cuts and
occurrences of propositional variables (compared to the diagrams of Fig. 7.1).
In the right diagram, we have the same sets of cuts and occurrences of propositional variables like in Figure 7.1), but we have a diﬀerent enclosing-relation.

A mathematical deﬁnition of Alpha graphs must therefore capture

1. a set of occurrences of propositional variables,

2. a set of cuts, and

3. the above-mentioned enclosing-relation.

To distinguish between propositional variables and occurrences of propositional variables, we will introduce vertices which are labeled with propositional variables. This yields the possibility that a propositional variable may
occur several times in a graph, even in the same cut. The cuts are introduced
as elements of a set Cut. It is reasonable to introduce the sheet of assertion

2P4P4P3P3P2PP12P4P4P3PP12PP13P7 Syntax for Alpha Graphs

63

as own syntactical device. The enclosing-relation will be captured by a mapping area, which assigns to the to the sheet of assertion and to each cut the
set of all other elements of the graph which are directly enclosed by the cut.
We know that we have some restrictions for cuts, e.g. cuts must not overlap.
These restrictions are captured mathematically by conditions for the mapping area. In order to distinguish the mathematically deﬁned alpha graphs
from the Peircean Alpha graphs, they are termed formal alpha graphs. Formal
Alpha graphs are now deﬁned as follows:

Deﬁnition 7.2 (Formal Alpha Graph). A formal Alpha graph is a
5-tuple (V, >, Cut, area, κ) with

• V and Cut are disjoint, ﬁnite sets whose elements are called vertices

and cuts, respectively,

• > is a single element with > /∈ V ∪ Cut, called the sheet of assertion,

• area : Cut ∪ {>} → P(V ∪ Cut) is a mapping such that

a) c1 6= c2 ⇒ area(c1) ∩ area(c2) = ∅ ,
b) V ∪ Cut = S
c) c /∈ arean(c) for each c ∈ Cut ∪ {>} and n ∈ N (with area0(c) := {c}

d∈Cut∪{>} area(d),

and arean+1(c) := S{area(d) | d ∈ arean(c)}), and

• κ : V → P is a mapping.

The elements of Cut ∪ {>} are called contexts. As we have for every x ∈
V ∪ Cut exactly one context c with x ∈ area(c), we can write c = area−1(x)
for every x ∈ area(c), or even more simple and suggestive: c = ctx(x).

In this deﬁnition,1 we have already captured some important technical terms.
Mainly we have deﬁned the sheet of assertion and the cuts of formal Alpha
graphs, and we have introduced the so-far informally described mapping area.
In the following, we will often speak more simply of ‘graphs’ instead of ‘formal
Alpha graphs’.

There is a crucial diﬀerence between formal Alpha graphs and most other
languages of logic: Formal Alpha graphs are deﬁned in one step. In contrast
to that, the well-formed formulas of a language for logic are usually built up
inductively. This is mainly done for the following reason: In a linear representations of logic, an inductive deﬁnition of formulas is much more easier
to provide – often an inductive deﬁnition is the canonical deﬁnition – than a
deﬁnition in one step. Moreover, usually the formulas in a linear representations of logic have an unique derivational history, from which a methodology

1 For Alpha, there are more simple deﬁnitions possible. But it will turn out that
an extension of this deﬁnition is a convenient formalization of Beta graphs. For
this reason, this formal deﬁnition of Alpha graphs is provided here.

64

7 Syntax for Alpha Graphs

for proofs on formulas is obtained: The proofs are carried out by a principle called recursion on the construction of formulas or induction principle for
short.

This reason do not necessarily hold for the deﬁnition of existential graphs.
Especially for Beta, a inductive deﬁnition for Beta graphs is not straight
forward (e.g., there are essential diﬀerences in the inductive deﬁnitions of
Zeman and Shin for Beta graphs), and a inductive deﬁnition is not necessarily
shorter or even easier than a deﬁnition in one step.

More importantly, even if an inductive deﬁnition for existential graphs is provided, it is likely that this deﬁnition does not lead to a unique derivational
history of graphs. Then, for any further deﬁnition on the graphs which is
carried out along their inductive construction, it has to be shown that it is
well-deﬁned. For example, if the semantics is deﬁned inductively, it has to be
shown that diﬀerent derivational histories of a given graph G lead nonenetheless to the same semantics of G (in the part ’extending the system’, a speciﬁc
class of graphs – so-called PAL-graphs, is deﬁned inductively, and on page 309,
we will shortly come back to this discussion). Thus the main advantage of inductive deﬁnitions gets lost for existential graphs. For this reason, although it
is possible to provide inductive deﬁnitions for Alpha and Beta, in this treatise
the decision is taken to deﬁne the graphs in a non-inductive manner.

As just mentioned, in an inductively deﬁned language, the well-formed formulas bear a structure which is obtained from their (normally uniquely determined) inductive construction. Of course, Alpha graphs bear a structure
as well: A cut of the graph may contain other cuts, but cuts may not intersect. Thus, for two (diﬀerent) cuts, we have three possibilities: The ﬁrst cut
encloses the second one, the second cut encloses the ﬁrst one, or the two cuts
are incomparable. If we incorporate the sheet of assertion into this consideration, it has to be expected that this idea induces an order ≤ on the contexts
(the naive deﬁnition of ≤ is to deﬁne c < d iﬀ c is ‘deeper nested’ than d)
which should be a tree, having the sheet of assertion > as greatest element.
The next deﬁnition is the mathematical implementation of this naive idea.

As we mathematize informal given entities – here: (diagrams of) Alpha graphs,
we cannot prove (mathematically) that the mathematization, e.g. the deﬁnition of formal Alpha graphs, is ’correct’. But as we have a mathematical
deﬁnition of Alpha graphs and as the order ≤ will be mathematically deﬁned
as well, we must be able to prove the proposition that ≤ is a tree with the
sheet of assertion as greatest element. The attempt to prove this proposition
can be understood as a test on our mathematical ’re-engineering’ of Alpha
graphs. If we cannot prove this proposition, our mathematization of Alpha
graphs does not capture crucial features of Alpha graphs, thus we should rework the deﬁnition. If we can prove this proposition, this is a good argument
that our deﬁnition is ‘right’. In fact, this proposition will turn out to be the

7 Syntax for Alpha Graphs

65

main instrument to argue that each formal alpha graph can be represented
graphically.

In the next deﬁnition, we deﬁne the ordering on the vertices and contexts
which will capture the enclosing-relation.

Deﬁnition 7.3 (Ordering on the Contexts, Enclosing Relation). Let
G := (V, >, Cut, area, κ) be a formal alpha graph. Now we deﬁne a mapping
β : V ∪ Cut ∪ {>} → Cut ∪ {>} by

(cid:26)

β(x) :=

x for x ∈ Cut ∪ {>}

ctx(x) for x ∈ V

,

and set x ≤ y :⇐⇒ ∃n ∈ N0.β(x) ∈ arean(β(y)) for x, y ∈ V ∪ Cut ∪ {>}.
To avoid misunderstandings, let

x < y :⇐⇒ x ≤ y ∧ y 6≤ x

and

x (cid:12) y :⇐⇒ x ≤ y ∧ y 6= x

. For a context c ∈ Cut ∪ {>}, we set furthermore

≤[c] := {x ∈ V ∪Cut∪{>} | x ≤ c} and (cid:12)[c] := {x ∈ V ∪Cut∪{>} | x (cid:12) c}.

Every element x of S
n∈N arean(c) is said to be enclosed by c, and vice
versa: c is said to enclose x. For every element of area(c), we say more
speciﬁcally that it is directly enclosed by c.

The relation ≤ is implemented to ease the mathematical treatment of the
enclosing-relation. First of all, let us show that the enclosing-relation can be
described with the relation ≤.

Lemma 7.4 (Order Ideals Generated by Contexts). Let a formal alpha
graph (V, >, Cut, area, κ) be given and let c ∈ Cut ∪ {>}. Then:

[

≤[c] =

{arean(c) | n ∈ N0}

, and (cid:12)[c] =

[

{arean(c) | n ∈ N} .

For c1, c2 ∈ Cut ∪ {>} we have the following implication:

c1 ∈ (cid:12)[c2] =⇒ ≤[c1] ⊆ (cid:12)[c2].

Proof: If d is context, we have

d ∈ ≤[c] ⇐⇒ ∃n ∈ N0.d = β(d) ∈ arean(c)} ⇐⇒ d ∈

arean(c)

[

n∈N0

Analogously, if v is a vertex, we have

v ∈ ≤[c] ⇐⇒ ∃n ∈ N0.ctx(v) = β(v) ∈ arean(c)} ⇐⇒ d ∈

arean(c)

[

n∈N

66

7 Syntax for Alpha Graphs

As moreover area0(c) = {c} does not contain any vertices, we are done. 2

If we have two cut-lines in the graphical representations of an alpha graph,
either one of the cut-lines is enclosed by the other one, or (as cut-lines must
not intersect) there is no element in the diagram which is enclosed by both
cut-lines. Of course, this statement has to hold for formal alpha graphs as
well, which is the proposition of the next lemma.

Lemma 7.5 (Relations between Order Ideals). For a formal alpha graph
(V, >, Cut, area, κ) and two contexts c1 6= c2, exactly one of the following
conditions holds:

i) ≤[c1] ⊆ (cid:12)[c2]

ii) ≤[c2] ⊆ (cid:12)[c1]

iii) ≤[c1] ∩ ≤[c2] = ∅

Proof: It is quite evident that neither i) and iii) nor ii) and iii) can hold
simultaneously. Suppose that i) and ii) hold. We get ≤[c1] ⊆ (cid:12)[c2] ⊆ (cid:12)[c1],
hence c1 ∈ (cid:12)[c1], in contradiction to c) for area in Def. 7.2 and to Lem. 7.4.
Now it is suﬃcient to prove the following: If iii) is not satisﬁed, then i) or ii)
holds. So we assume that iii) does not hold. Then we have

∅6=≤[c1] ∩ ≤[c2]
=({c1} ∪ (cid:12)[c1]) ∩ ({c2} ∪ (cid:12)[c2])
=({c1}∩{c2}) ∪ ({c1}∩(cid:12)[c2]) ∪ ({c2}∩(cid:12)[c1]) ∪ ((cid:12)[c1]∩(cid:12)[c2])

From c1 6= c2 we conclude {c1} ∩ {c2} = ∅. If {c1} ∩ (cid:12)[c2] 6= ∅ holds, i.e.
c1 ∈ (cid:12)[c2], Lem. 7.4 yields i). Analogously follows ii) from {c2} ∩ (cid:12)[c1] 6= ∅.
So it remains to consider the case (cid:12)[c1] ∩ (cid:12)[c2] 6= ∅. For this case, we choose
x ∈ aream(c1) ∩ arean(c2) such that n + m is minimal. We distinguish the
following four cases:

• m = 1 = n: This yields x ∈ area(c1) ∩ area(c2) in contradiction to c1 6= c2

and condition a) of Def. 7.2.

• m = 1, n > 1: Let c2

0 ∈ arean−1(c2) such that x ∈ area(c2

of Def. 7.2 and x ∈ area(c1) ∩ area(c2
c1 ∈ arean−1(c2) holds, and we get c1 ∪ (cid:12)[c1] ⊆ (cid:12)[c2], i.e., condition i).

0) we conclude c1 = c2

0). From a)
0. Hence

• m > 1, n = 1: From this, we conclude ii) analogously to the last case.

• m > 1, n > 1: Let c1

0 ∈ arean−1(c2) such that x ∈ area(c2

c2
hence c1
tion to the minimality of m + n.

0 ∈ aream−1(c1) such that x ∈ area(c1

0), and let
0) 6= ∅,
0. This yields aream−1(c1) ∩ arean−1(c2) 6= ∅, in contradic2

0). We get area(c1

0)∩area(c2

0 = c2

Now we get the following lemma:

7 Syntax for Alpha Graphs

67

Lemma 7.6 (≤ is a Tree on Cut ∪ {>}). Let G := (V, >, Cut, area, κ)
be a formal alpha graph. Then ≤ is an quasiorder on V ∪ Cut ∪ {>}, and the
restriction of ≤ to Cut ∪ {>} is an order on Cut ∪ {>} which is a tree with
the sheet of assertion > as greatest element.

Proof: We have x ≤ y ⇐⇒ β(x) ≤ β(y) ⇐⇒ ≤[β(x)] ⊆ ≤[β(y)]. Hence ≤ is a
quasiorder. Now Lem. 7.5 yields that the restriction of ≤ to Cut ∪ {>} is an
order which is furthermore a tree.

As Cut ∪ {>} is ﬁnite, is contains a maximal element c. Assume that c 6= >.
Then condition b) for area in Def. 7.2 yields a d with c ∈ area(d). From this
we conclude c < d, a contradiction to the maximality of c. Hence > is the
2
only maximal element of Cut ∪ {>}, i.e., > is the greatest element.

To provide an example of a formal Alpha graph, we consider the right diagram
of Fig. 7.1. Additionally, we have labeled the vertices and cuts with names for
pairwise distinct elements. Below the diagram, the formal Alpha graph which
is represented by the diagram is provided.

G := ({v1, v2, v3, v4, v5, v6, v7, v8}, >, {c1, c2, c3, c4, c5, c6}, (cid:9) V, >, Cut

{(>, {v1, v2, v3, c1}), (c1, {v4, c2, c3, c4}), (c2, ∅),

(c3, {v5}), (c4, {v6, c5, c6}), (c5, {v7}), (c6, {v8})},

{(v1, P1), (v2, P1), (v3, P2), (v4, P3),

(v5, P2), (v6, P3), (v7, P4), (v8, P4)})

(cid:27)

area

(cid:27)

κ

Next we show the mapping ctx, and the quasiorder ≤ is presented by its
Hasse-diagram.

x v1 v2 v3 v4 v5 v6 v7 v8 c1 c2 c3 c4 c5 c6
ctx(x) > > > c1 c3 c4 c5 c6 > c1 c1 c1 c4 c4

>, v1, v2, v3

c1, v4
@@

c3, v5

(cid:0)(cid:0)

(cid:0)

c2

@

c4, v6
@@

(cid:0)(cid:0)

(cid:0)
c5, v7

@

c6, v8

Note that we did not further specify the objects v1, . . . , v8, >, and c1, , . . . , c6.
It is quite obvious that a diagram of an EG cannot determine the mathematical objects for vertices or cuts, it only determines the relationships between

3P2P4P4P3P2PP1P1c1c2c3v1v4v3v2v5c4v6c5v7c6v868

7 Syntax for Alpha Graphs

these objects. In fact we can choose arbitrary sets for these mathematical objects (we only have to take into account that {v1, v2, v3, v4, v5, v6, v7, v8}, {>},
{c1, c2, c3, c4, c5, c6} must be pairwise disjoint). In other words: The diagram
of a graph determines the graph only up to isomorphism. The isomorphismrelation is canonically deﬁned as follows:

Deﬁnition 7.7 (Isomorphism). Let Gi := (Vi, >i, Cuti, areai, κi) with i =
.
∪ fCut is called isomorphism,
1, 2 be two formal alpha graphs. Then f = fV
if fV : V1 → V2 and fCut : Cut1∪{>1} → Cut2∪{>2} are bijective and satisfy
fCut(>1) = >2 such that f [area1(c)] = area2(f (c)) for each c ∈ Cut1 ∪ {>1}
(we write f [X] for {f (x) | x ∈ X}), and κ1(v) = κ2(fV (v)) for all v ∈ V1.

From now on, isomorphic formal alpha graphs are implicitely identiﬁed.
We have seen that a diagram of an Alpha graph is a diagram which is
built up from two diﬀerent kinds of items, namely of closed, double-point-free
and smooth curves which represent cuts (we will call them cut-lines), and signs
which denote the propositional variables Pi, such that two diﬀerent items of
the diagram neither overlap nor intersect.

So far, we have not discussed why the relationship between formal alpha
graphs and their graphical representations. This is needed to argue that formal
alpha graphs capture exactly the essential features of the diagrams of alpha
graphs. We have to answer the following two questions:

1. Can each formal alpha graph be represented by a diagram?

2. Does each diagram represent an alpha graph? How can this graph be

reconstructed from the diagram?

In order to answer these questions, a further clariﬁcation of the term ’diagram’
of an alpha graph is needed.

Informal Deﬁnition 7.8 (Diagram of Alpha Graphs) A diagram of
an alpha graph is a diagram which is built up from two diﬀerent kinds
of items, namely of

1. closed, doublepoint-free and smooth curves which are named cut-lines,

and

2. signs which denote the propositional variables Pi,

such that the following conditions hold:

1. Nothing else may occur (i.e. there are no other graphical items but cut-

lines or signs denoting a propositional variable), and

2. two diﬀerent items the diagram must neither overlap nor intersect.

7 Syntax for Alpha Graphs

69

Obviously, a cut-line separates the plane into two distinct regions: What is
outside the cut-line and what is inside the cut-line. Of course we say that
another item of the diagram is enclosed by this cut-line if and only if it is
placed in the inner region of this cut-line. Furthermore, we agree that each
item is placed on the sheet of assertion, thus it is convinient to say that
each item is enclosed by the sheet of assertion. As no items, of the diagram,
particulary no cut-lines, may neither overlap nor intersect, we can decide for
two items whether one of them enclosed the other one or not. Now we say that
an item x is directly enclosed by a cut-line cl (resp. by the sheet of assertion)
if and only if it is enclosed by cl (resp. by the sheet of assertion) and there
is no other cut-line cl0 which is enlosed by cl (resp. by the sheet of assertion)
and which encloses x.

Now let a diagram of an alpha graph be given. It is easy to ﬁnd (up to
isomorphism) the corresponding formal Alpha graph (V, >, Cut, area, κ): We
choose sets V and Cut of which its elements shall stand for the occurences of
propositional variables resp. the cut-lines in the diagram, and the mapping κ
is deﬁned accordingly. Then, the mapping area area is now deﬁned as follows:
Let c ∈ Cut be a cut. So we have a uniquely given cut-line cl in our diagram
.
which corresponds to c. Now let area(c) be the set of all x ∈ V
∪ Cut such that
x corresponds to an item of the diagram (an occurence of a PV or a cut-line)
which is directly enclosed by the cut-line cl. Furthermore, let area(>) be the
.
set of all x ∈ V
∪ Cut such that x corresponds to an item which is not enclosed
by any cut-line. So we obtain a formal Alpha graph which is represented by the
diagram, i.e., we have an one-to-one correspondence between the occurences
of the signs which denote the propositional variables in the diagram and V ,
and a an one-to-one correspondence between the cut-lines of the diagram and
Cut, such that the following holds:

1. If we have an occurence of a sign which denotes a propositional variable
Pi in the diagram and which is mapped to a vertex v, then κ(v) = Pi.
2. Let an arbitrary item of the diagram be given, which is mapped to an
.
∪ Cut, and let an arbitrary cut-line be given (resp. the sheet of
x ∈ V
assertion), which is mapped to a cut c ∈ Cut (resp. to >). Then the item
is directly enclosed by the cut-line (resp. by the sheet of assertion) if and
only if x ∈ area(c) (resp. x ∈ area(>)).

Now let on the other hand be a formal alpha graph G := (V, >, Cut, area, κ) be
given. Using Lem. 7.6, inductively over the tree (Cut ∪ {>}, ≤), we can assign
to each context c ∈ Cut ∪ {>} a diagram Diag(c). So let c ∈ Cut ∪ {>} be a
context such that we have already constructed Diag(d) for each d ∈ area(c).
Then Diag(c) is constructed by writing side by side (without overlapping) the
following items:

1. For each v ∈ area(c)∩V , we write an sign which denotes the propositional

variables κ(v), and

70

7 Syntax for Alpha Graphs

2. For each d ∈ area(c) ∩ Cut, we write the diagram Diag(d) and a further
cut-line which encloses Diag(d) (that is, it encloses excatly all items of
Diag(d)).

It is easy to see that Diag(>) is a diagram of an alpha graph which represents
G.

To summarize: We provided an (informal) deﬁnition of diagrams of alpha
graphs, as well as a mathematical (formal) deﬁnition of formal alpha graphs.
We explicated when a diagram is a representation of a formal alpha graph.
We have argued that each diagram of an alpha graph is a representation of
a formal alpha graph, and, vice versa, that each formal alpha graph can be
represented by a diagram.

This is similar to the handling of formulas and their representations, as we
have discussed it in Section 5.4. Thus, from now on, we have the opportunity
to use the diagrams of formal alpha graphs in mathematical proofs.

For the further treatise, especially for the calculus, the notation of a subgraph
is needed. Informally spoken, a subgraph is a part of a graph placed in a
context c such that

• if the subgraph contains a cut d, then it contains all what is enclosed by

d, i.e. (cid:12)[d], and

• every element of the subgraph is enclosed by another cut of the subgraph

or by c.

Deﬁnition 7.9 (Subgraph). Let G := (V, >, Cut, area, κ) be a formal alpha graph. The formal graph alpha G0 := (V 0, >0, Cut0, area0, κ0) is called a
subgraph of G in the context >0 if

• V 0 ⊆ V , Cut0 ⊆ Cut and >0 ∈ Cut ∪ {>} ,
• κ0 = κ(cid:12)
(cid:12)V 0 (i.e., the mapping κ0 is the restriction of κ to V 0),
• area0(>0) = area(>0) ∩ (V 0 ∪ Cut0) and area0(d) = area(d) for each cut

d ∈ Cut0, and

• ctx(x) ∈ Cut0 ∪ {>0} for each x ∈ V 0 ∪ Cut0.

We write: G0 ⊆ G and area−1(G0) = >0 resp. ctx(G0) = >0.

The claim that if a subgraph contains a cut d, is has to contain all what is
enclosed by d, is somewhat hidden in the third condition of its deﬁnition. That
this claim is fulﬁlled is shown with the next lemma.

Lemma 7.10 (Subgraphs Respect Enclosing Relation). Let a formal alpha graph G := (V, >, Cut, area, κ) be given, let G0 := (V 0, >0, Cut0, area0, κ0)
be a subgraph. If d ∈ Cut0, then (cid:12)[d] ⊆ V 0 ∪ Cut0.

7 Syntax for Alpha Graphs

71

Proof: It holds x (cid:12) d ⇔ ∃n ∈ N : x ∈ arean(d) ⇔ ∃n ∈ N ∃d1, . . . , dn ∈ Cut :
d = d1, d2 ∈ area(d1), . . . , dn−1 ∈ area(dn) and x ∈ area(dn) for each cut or
vertex x ∈ V ∪ Cut.
We have d = d1 ∈ Cut0. The third condition for subgraphs yields now that
d2 ∈ area(d1) = area0(d1), thus we have d2 ∈ Cut0 as well. Analogously,
we can now conclude that we have d3 ∈ Cut0, etc., and ﬁnally we conclude
2
x ∈ area(dn) = area0(dn), thus x ∈ V 0 ∪ Cut0.
In Figs. 7.3 and 7.4, some examples for the deﬁnition of subgraphs, based on
the graph of Figure 7.1, are provided. We consider substructures of this graphs
which are depicted by printing them black (the items which do not belong to
the substructures are grey). Note that we have for example two diﬀerent sub-
(cid:12)
(cid:15)
(cid:13). Considered as graphs, these two subgraphs are isomorphic and
graphs P4
(cid:14)
therefore treated to be identical. Considered as subgraphs, there are treated
to be diﬀerent.

,

,

Fig. 7.3. Four diﬀerent subgraphs

,

Fig. 7.4. Two substructures which are no subgraphs

The next two deﬁnitions are essential in the deﬁnitions of calculus we will
present in Chpt. 8. Most of the rules in this calculus modify only parts of a
graph which are enclosed by a speciﬁc context, the rest of the graph remains
unchanged. We will say that the starting graph and the resulting graph are
isomorphic except for that context, which is captured by Def. 7.11.

Deﬁnition 7.11 (Partial Isomorphism). Let two formal alpha graphs
Gi
:= (Vi, >i, Cuti, areai, κi) with contexts ci ∈ Cuti ∪ {>i}, i = 1, 2 be
given. For i = 1, 2, we set

• V i
• Cuti

0 := {v ∈ Vi | v 6≤ ci} and

0 := {d ∈ Cuti ∪ {>i} | d 6< ci} .

4P4P3P2PP1P12P3P4P4PP1P12P3P2P3P4PP1P12P3P2P3P4P4P4PP1P12P3P2P3P2P4P3PP1P12P3P4P4PP1P12P3P2P3P4P72

7 Syntax for Alpha Graphs

0 be the restriction of Gi to V i
0 := (V i
0 := κi
0 , we set Gi

(cid:12)
0 := areai
Let Gi
(cid:12)Cuti
.
(cid:12)
and κi
∪ fCut
(cid:12)V i
is an isomorphism between G0
2 with fCut(c1) = c2, then f is called
(partial) isomorphism from G1 to G2 except for c1 ∈ Cut1 ∪ {>1}
and c2 ∈ Cut2 ∪ {>2}.

0, i.e., for areai
0, κi
0, areai

0 and Cuti
0, >, Cuti

0). If f = fV

1 and G0

0

Let us draw two technical remarks on this deﬁnition.

1. Please note that we have deﬁned Cuti

0 := {d ∈ Cuti ∪ {>i} | d 6< ci}
0 := {d ∈ Cuti ∪ {>i} | d 6≤ ci}. This yields that we have
0 for vi ∈ area(ci) ∩ Vi, i = 1, 2 and

0 for i = 1, 2, but not vi ∈ V i

instead of Cuti
ci ∈ Cuti
not ei ∈ Ei

0 for ei ∈ area(ci) ∩ Ei, i = 1, 2.

2. For the restrictions areai
0 ∪ Cuti

is restricted to V i
no diﬀerence: We simply have areai
areai

0(ci) = ∅.

(cid:12)
0 := areai
(cid:12)Cuti
0 as well. For di ∈ Cuti

0 , we agree that the range of areai
0 with d 6= ci, this makes
0(di) = areai(di), but for ci, we have

0

For some rules we have to distinguish whether this context is enclosed by an
odd or even number of cuts. For this reason the next deﬁnition is needed.

Deﬁnition 7.12 (Evenly/Oddly Enclosed, Pos./Neg. Contexts). Let
G = (V, >, Cut, area, κ) be a formal alpha graph, let x be a subgraph or let x
be an element of V ∪ Cut ∪ {>}. We set set n := |{c ∈ Cut | x ∈ ≤[c]}|. If n is
even, x is said to be evenly enclosed or positive enclosed, otherwise x is
said to be oddly enclosed or negative enclosed. The sheet of assertion
> and each oddly enclosed cut is called a positive context, and each an
evenly enclosed cut is called negative context.

Writing diagrams side by side is a common operation called juxtaposition. On
the level of formal Alpha graphs, it is the disjoint2 union of a set of graphs,
which is captured by the next deﬁnition.

Deﬁnition 7.13 (Juxtaposition of Formal Alpha Graphs). For an
n ∈ N0 and for each i = 1, . . . , n, let Gi
:= (V ei, >ei, Cutei, areaei, κei)
be a formal alpha graph. The juxtaposition of the Gi is deﬁned to be the
following formal alpha graph G := (V, >, Cut, area, κ):

• V := S

i=1,...,n Vi × {i} , and Cut := S

i=1,...,n Cuti × {i} ,

• area is deﬁned as follows:

area((c, i)) = areai(c) × {i} for c ∈ Cuti

area(>) = S

i=1,...,n areai(>i) × {i}

, and

• κ(v, i) := κi(v) for all v ∈ V ∪ E and i = 1, . . . , n.

2 In order to ensure that the graphs are disjoint, a simple technical trick – all sets

of the ith graph are indexed by i – is applied in the deﬁnition.

7 Syntax for Alpha Graphs

73

In the graphical notation, the juxtaposition of the Gi is simply noted by writing
the graphs next to each other, i.e. we write: G1 G2 . . . Gn

.

It should be noted that the juxtaposition of an empty set of graphs is allowed,
too. It yields the empty graph, i.e. (∅, >, ∅, ∅, ∅).

8

Semantics and Calculus for Formal Alpha
Graphs

In this chapter, the semantics and calculus for formal Alpha graphs are provided.

8.1 Semantics for Formal Alpha Graphs

In this section we provide a semantics for formal alpha graphs. As in propositional logic, we assign truth values to the propositional variables by valuations.
Propositional variables stand for propositions which are simply true or false.

Deﬁnition 8.1 (Valuation). Let ff stand for the truth-value ‘false’ and tt
for the truth-value ‘true’. A valuation is a mapping val : P → {ff, tt}.

Now we have to extend valuations to graphs by reﬂection of the meaning of
cuts and juxtaposition. This is done close to the so-called endoporeutic method
of Peirce.

Deﬁnition 8.2 (Evaluations).
Let a valuation val and let a formal alpha
G := (V, >, Cut, area, κ) be given. We evaluate G for val inductively over
c ∈ Cut ∪ {>}. The evaluation of G in a context c is written val |= G[c], and
it is inductively deﬁned as follows: val |= G[c] :⇐⇒

• val(κ(v)) = tt for each v ∈ V ∩ area(c) (vertex condition), and
• val 6|= G[c0] for each c0 ∈ Cut ∩ area(c) (cut condition: iteration over

Cut ∪ {>})

For val |= G[>] we write val |= G and say that G is valid for val resp. val
is a model for G. If we have graphs G1, G2 such that val |= G2 for each
valuation val, we write G1 |= G2.

76

8 Semantics and Calculus for Formal Alpha Graphs

8.2 Some Remarks to the Calculus

Before we come to the formal deﬁnition of the rules in the next section, some
further scrutiny of the rules, particularly iteration and deiteration, is helpful.
In order to do that, consider the following graph (to improve the readability
of the examples, we use the letters ‘A,B,C’ as propositional variables):

G :=

The graph G contains the subgraph
, which is placed in a negative
context. As the subgraph alway evaluates to ff, it is easy to see that the
whole graph alway evaluates to tt, i.e., it represents a tautology.

We start out investigations with the rules ‘erasure’ and ‘insertion’. The
erasure-rule allows to erase a subgraph from a positive context, the insertionrule allows to insert a subgraph into a negative context. In this sense, the rules
are mutually dual, and it is suﬃcient to investigate the erasure-rules only.

Possible results of the erasure-rule, applied to G, are

But erasing the subgraph

is not allowed. This would yield

and

.

,

which may evaluate to ff (e.g. for val(B) = ff), thus erasing a subgraph from
a negative context may lead from a true premise to a false conclusion. Analogously, inserting a subgraph into a positive context is not allowed, neither.

The erasure-rule removes information from a graph, i.e., it is a generalizing
rule. For this reason, in contrast to the rules iteration, deiteration or double
cut, it may only be carried out in one direction. This cannot be seen with G
(because it represents a tautology), but an example for an application of the
erasure-rule which may not be reversed can easily be found. Below, the right
graph is obtained from the left with the erasure-rule, and the left graph is not
semantically implied by the right graph.

era
‘

.

Analogously, the insertion-rule may only be carried out in one direction too.

AABCAAABCAAAABCBCB8.2 Some Remarks to the Calculus

77

Next we consider the iteration- and deiteration-rule. The iteration-rule allows
to add redundant copies of the subgraph to the graph, the deiteration-rule in
turn allows to remove such redundant copies. For this reason, it is suﬃcient
to discuss only the iteration-rule.

For the iteration-rule, it is crucial that if a redundant copy of a subgraph is
added to a graph, this redundant copy may not be placed in arbitrary context.
It may only be placed in the same or a deeper nested context of the subgraph,
and this context is not allowed to be a cut of the subgraph. That is, the
following three graphs are the possible applications of the iteration-rule to
the graph G, when the subgraph

is iterated:

Similar to G, it is easy to check that all three graphs always evaluate to tt. On
the other hand, if the subgraph is in another contexts, we may obtain graphs
which are no more tautologous. The next two graphs are obtained from a
wrong application of the iteration-rule:

The ﬁrst graph is obtained by an application of the subgraph into a higher
context, namely the sheet of assertion. In contrast to G, this graph always
evaluates to ff, thus this application of the rule is a fault. The second graph
is obtained by an application of the subgraph into a cut of the subgraph. If
we assign the truth-value tt to the propositional variables A, B, C, the whole
graph evaluates to ff. Thus this application of the rule may lead from a true
premise to wrong conclusion, i.e., it is a fault, too.

The iteration-rule does not add information to a graph, neither it removes
information. For this reason, it may be carried out in both directions (the
opposite direction is exactly the deiteration-rule).

The same holds for the double-cut rule, which adds or removes double negations. Here are three pairs of alpha graphs which can mutually be derived
from each other with the double cut rule.

and

,

and

,

Note that adding or removing a empty double cut is possible, too. For example,

and

can mutually be derived from each other as well.

AAAAAABCAAAABCAAAABCAAAABCAABCAABCBCCBCBCBCB78

8 Semantics and Calculus for Formal Alpha Graphs

8.3 Calculus for Alpha Graphs

In this section we will provide a calculus for formal alpha graphs. For the sake
of intelligibility, the whole calculus is ﬁrst described using common spoken
language. After this, the rules are described in a mathematically precise manner. The calculus we present here should be understood as a diagrammatic
calculus, i.e., all rules can be carried out by manipulating the diagrams of
formal alpha graphs.

Deﬁnition 8.3 (Calculus for Formal Alpha Graphs). The calculus for
formal alpha graphs over P consists of the following rules:

• erasure (era)

In positive contexts, any subgraph may be erased.

• insertion (ins)

In negative contexts, any subgraph may be inserted.

• iteration (it)

Let G0 := (V0, >0, Cut0, area0, κ0) be a subgraph of G and let c ≤ ctx(G0)
be a context such that c /∈ Cut0. Then a copy of G0 may be inserted into
c.

• deiteration (deit)

If G0 is a subgraph of G which could have been inserted by rule of iteration,
then it may be erased.

• double cut (dc)

Double cuts (two cuts c1, c2 with area(c1) = {c2}) may be inserted or
erased.

These rules have to be written down mathematically. Here are the appropriate
mathematical deﬁnitions:

• erasure and insertion

We ﬁrst provide a general deﬁnition for inserting and erasing a subgraph.

Let G := (V, >, Cut, area, κ) be a graph which contains the subgraph
G0 := (V0, >0, Cut0, area0, κ0). Let G0 := (V 0, >0, Cut0, area0, κ0) be deﬁned as follows:
– V 0 := V \V0, >0 := > and Cut0 := Cut\Cut0 ,

(cid:26)

area(d) d 6= >0
area(d)\(V0 ∪ Cut0) d = >0

.

– area0(d) :=

– κ0 := κ(cid:12)

(cid:12)V 0

8.3 Calculus for Alpha Graphs

79

Then we say that G0 is derived from G by erasing the subgraph G0
from the context >0, and G is derived from G0 by inserting the
graph G0 into the context >0. The rules ‘erasure’ and ‘insertion’ are
restrictions of the general deﬁnition as follows: Let G be a graph and let
G0 be a subgraph of G with c := ctx(G0), and let G0 be obtained from G
by erasing G0 from the context c. If c is positive, then G0 is derived from
G by erasing G0 from a positive context, and if c is negative, than
G0 is derived from G by inserting G0 into a negative context.

• iteration and deiteration

Let G := (V, >, Cut, area, κ) be a graph which contains the subgraph
G0 := (V0, >0, Cut0, area0, κ0), and let c ≤ >0 be a context with c /∈ Cut0.
Let G0 := (V 0, >0, Cut0, area0, κ0) be the following graph:
– V 0 := V ×{1} ∪ V0×{2}, >0 := > and Cut0 := Cut×{1} ∪ Cut0×{2}.
– area0 is deﬁned as follows:

For (d, i) ∈ Cut0 ∪ {>0} and d 6= c let area0((d, i)) := area(d)×{i}, and
area0((c, 1)) := area(c)×{1} ∪ area0(>0)×{2}.

– κ0((k, i)) := κ(k) for all (k, i) ∈ V 0
Then we say that G0 is derived from G by iterating the subgraph G0
into the context c and G is derived from G0 by deiterating the
subgraph G0 from the context c.

• double cuts

Let G := (V, >, Cut, area, κ) be a graph and c1, c2 ∈ Cut with area(c1) =
{c2}. Let c0 := ctx(c1) and set G0 := (V, >, Cut0, area0, κ) with
– Cut0 := Cut\{c1, c2}

– area0(d) :=

(cid:26)

area(d) for d 6= c0
area(c0) ∪ area(c2) for d = c0

.

Then we say that G0 is derived from G by erasing the double cuts
c1, c2 and G is derived from G0 by inserting the double cuts c1, c2.

Based on the calculus, we can now deﬁne the syntactical entailment relation.

Deﬁnition 8.4 (Syntactical Entailment Relation). Let Ga, Gb be two
graphs. Then Gb can be derived from Ga (which is written Ga ‘ Gb),
if there is a ﬁnite sequence (G1, G2, . . . , Gn) with Ga = G1 and Gb = Gn
such that each Gi+1 is derived from Gi by applying one of the rules of the
calculus. The sequence is called a proof for Ga ‘ Gb. Two graphs G1, G2
with G1 ‘ G2 and G2 ‘ G1 are said to be provably equivalent.
If H := {Gi | i ∈ I} is a (possibly empty) set of graphs, then a graph G
can be derived from H if there is a ﬁnite subset {G1, . . . , Gn} ⊆ H with
G1 . . . Gn ‘ G (remember that G1 . . . Gn is the juxtaposition of G1, . . . , Gn).

80

8 Semantics and Calculus for Formal Alpha Graphs

8.4 Some Simple Theorems

In [Pei35] Peirce provided 16 useful transformation rules for EGs which he
derived from his calculus. These rules are logical metalemmata in the sense
that they show some schemata for proofs with EGs, i.e., they are derived
‘macro’-rules. In this section we provide the formal alpha graph versions for
two of these transformation rules. We start with a (weakened) version of the
ﬁrst transformation rule of Peirce.

Lemma 8.5 (Reversion Theorem). Let Ga and Gb be two formal alpha
graphs. Then we have Ga ‘ Gb if and only if Gb

(cid:11)
(cid:8)
(cid:9)‘ Ga
(cid:10)

(cid:8)
(cid:9).

(cid:11)
(cid:10)

G1

(cid:11)
(cid:10)

(cid:8)
(cid:9)) is a proof for Gb

Proof: Let (G1, G2, . . . , Gn) with G1 = Ga and Gb = Gn be a proof for
(cid:8)
(cid:11)
Ga ‘ Gb. Then, due to the symmetry of the calculus, ( Gn
(cid:9), . . .,
(cid:10)
(cid:8)
(cid:11)
(cid:8)
(cid:11)
(cid:9). The inverse direction holds as well. 2
(cid:9)‘ Ga
(cid:10)
(cid:10)
All rules in the calculus which are applied in a context only depend on whether
the context is positive or negative. In particular if a proof for Ga ‘ Gb is given,
this proof can be carried out in arbitrary positive contexts. Together with the
previous lemma, this yields the following lemma, which is a combination of
the (full) ﬁrst and the sixth transformation rule of Peirce. It can also be found
in [Sow97a] (from where we adopted the name of the theorem).

(cid:11)
(cid:8)
(cid:9), Gn−1
(cid:10)

Lemma 8.6 (Cut-And-Paste-Theorem). Let Ga ‘ Gb for two formal
alpha graphs Ga, Gb, let G be a further graph. Then we have:

• If Ga is a subgraph of G in a pos. context, then Ga may be replaced by Gb.
• If Gb is a subgraph of G in a neg. context, then Gb may be replaced by Ga.

In particular we have that derivable graphs G0 (i.e., graphs with ‘ G0) can be
inserted into arbitrary contexts of arbitrary graphs.

From this lemma we obtain the formal alpha graph version of the well known
deduction theorem.

Lemma 8.7 (Deduction Theorem). Let Ga, Gb be formal alpha graphs.
Then we have

(cid:23)

(cid:15)

(cid:20)

(cid:12)

Ga ‘ Gb ⇐⇒ ‘

Ga Gb

(cid:14)

(cid:22)

(cid:13)

(cid:21)

Proof: We show both directions separately.
(cid:20)
(cid:12)
it
‘
(cid:13)
(cid:21)

(cid:20)
(cid:12)
ins
‘
(cid:13)
(cid:21)

Ga
(cid:22)

‘=⇒’:

(cid:22)

(cid:23)

(cid:23)

(cid:14)

(cid:15)

(cid:14)

(cid:15)

dc
‘

(cid:23)

(cid:15)
Ga Ga
(cid:14)
(cid:22)

(cid:20)
(cid:12)
L. 8.6
‘
(cid:13)
(cid:21)

(cid:23)

(cid:15)
Ga Gb
(cid:14)
(cid:22)

(cid:20)
(cid:12)

(cid:13)
(cid:21)

‘⇐=’: Ga

L. 8.6

‘ Ga

(cid:23)

(cid:15)
Ga Gb
(cid:14)
(cid:22)

(cid:20)
(cid:12)
deit
‘ Ga

(cid:13)
(cid:21)

The following lemma is quite obvious:

(cid:23)

8.4 Some Simple Theorems
(cid:20)
(cid:12)
dc
‘ Ga Gb
(cid:13)Gb

(cid:15)

(cid:14)

(cid:21)

(cid:22)

era
‘ Gb 2

81

Lemma 8.8. Let G, Ga and Gb be formal alpha graphs with G ‘ Ga and
G ‘ Gb. Then G ‘ Ga Gb.

Proof:

it
‘ G G

G

L. 8.6

‘ Ga G

L. 8.6

‘ Ga Gb

2

9

Soundness and Completeness

In this chapter we will show that the rules we presented in Chapter 8 are
sound and complete with respect to the given semantics. In the ﬁrst section,
we will prove the soundness of the calculus, in the next section we will prove
its completeness.

9.1 Soundness

Most of the rules modify only the area of one speciﬁc context c (for example,
the rule ‘erasure’ removes a subgraph from the area of a positive context).
If a graph G0 is derived from a graph G by applying one of these rules (i.e.,
by modifying a context c in the graph G), G and G0 are isomorphic except
for c. As it has to be shown that no rule can transform a valid graph into a
nonvalid one, the following theorem is the basis for proving the soundness of
most rules.

Theorem 9.1 (Main Soundness Lemma). Let G := (V, >, Cut, area, κ)
.
and G0 := (V 0, >0, Cut0, area0, κ0) be formal alpha graphs, let f = fV
∪ fCut
be an isomorphism from G to G0 except for the contexts c ∈ Cut ∪ {>} and
c0 ∈ Cut0 ∪ {>0}. Let val : P → {ff, tt} be a valuation. Let P (d) be the
following property for Cuts d ∈ Cut ∪ {>}:

• If d is positive and val |= G[d], then val |= G0[f (d)], and
• If d is negative and val 6|= G[d], then val 6|= G0[f (d)].

If P holds for c, then P holds for each d ∈ Cut ∪ {>} with d 6< c. In particular
follows v |= G0 from v |= G.

Proof: We set D := {d ∈ Cut ∪ {>} | d 6< c}. D is a tree such that for each
d ∈ D with d 6= c and each e ∈ Cut ∪ {>} with e < d we have e ∈ D. For this

84

9 Soundness and Completeness

reason we can carry out the proof by induction over D. As c satisﬁes P , it is
suﬃcient to carry out the induction step for d 6= c. So let d ∈ D, d 6= c be a
context such that P (e) holds for all cuts e ∈ area(d) ∩ Cut.

First Case: d is positive and val |= G[d].

We have to check the vertex- and cut-conditions for f (d). We start with the
vertex conditions for f (d), i.e., for vertices v0 ∈ V 0 with ctx0(v0) = f (d).
For each v ∈ V with ctx(v) = d, it holds κ(v) = κ0(f (v)), hence

val(κ(v)) = tt ⇐⇒ val(κ0(f (v))) = tt.

As fV is a bijection from area(d)∩V to area0(f (d))∩V 0, we gain the following:
All vertex conditions in d hold iﬀ all vertex conditions in f (d) hold.

As we have val |= G[d], we get that val 6|= G[e] for all cuts e ∈ area(d). These
cuts are negative and are mapped bijectively to the cuts e0 ∈ area(f (d)). As
they are negative, we conclude from the induction hypothesis or the presupposition (for e = c) that val 6|= G0[f (e)] for all cuts e ∈ area(d), i.e., val 6|= G0[e0]
for all cuts e0 ∈ area0(f (d)).

As we have checked all vertex- and cut-conditions for f (d), we get val |=
G0[f (d)].

Second Case: d is negative and val 6|= G[d].

This is shown analogously to the ﬁrst case.

2

With this lemma, we can prove the correctness of the rules. We start with the
soundness of the rules ‘iteration’ and ‘deiteration’.

Lemma 9.2 (Iteration and Deiteration are Sound). If G and G0 are
two formal alpha graphs, val is a valuation with val |= G and G0 is derived
from G by applying one of the rules ‘iteration’ or ‘deiteration’, then val |= G0.

Proof: Let G0 := (V0, >0, Cut0, area0, κ0) be the subgraph of G which is
iterated into the context c ≤ ctx(G0), c /∈ Cut0. We use the mathematical
notation which was given in Section 8.3. In particular, (c, 1) is the context in
G0 which corresponds to the context c in G. There are two cases to consider:

First Case: val
|=
G0[(c, 1)]. As G and G0 are isomorphic except for c ∈ Cut ∪ {>} and
(c, 1) ∈ Cut0 ∪ {>0}, Lemma 9.1 can be applied now. This yields

|= G0. From this we conclude val

|= G[c] ⇐⇒ val

val |= G ⇐⇒ val |= G0 .

(∗)
Second Case: val 6|= G0. This yields val 6|= G[>0] and val 6|= G0[(>0, 1)]. As
G and G0 are isomorphic except for >0 ∈ Cut∪{>} and (>0, 1) ∈ Cut0 ∪{>0},
Lem. 9.1 can be applied now. This yields again (∗).

The direction ‘=⇒’ of (∗) yields the correctness of the iteration-rule. The
opposite direction ‘⇐=’ of (∗) yields the correctness of the deiteration-rule. 2

9.1 Soundness

85

If G and G0 are two
Lemma 9.3 (Erasure and Insertion are Sound).
formal alpha graphs, v is a valuation with val |= G and G0 is derived from G
by applying one of the rules ‘erasure’ or ‘insertion’, then val |= G0.

Proof: We start with ‘erasure’. Let G0 := (V0, >0, Cut0, area0, κ0) be the
subgraph which is erased. G0 is erased from the area of the positive context
c := >0. Obviously, if val |= G[c], then val |= G0[c]. Furthermore G and G0
are isomorphic except for c ∈ Cut ∪ {>} and c ∈ Cut0 ∪ {>0}, hence Lemma
9.1 can be applied now. This yields val |= G0.

The soundness of the insertion-rule is proven analogously.

2

Lemma 9.4 (Double Cut is Sound). If G and G0 are two formal alpha
graphs, val is a valuation with val |= G and G0 is derived from G by applying
the rule ‘double cut’, then val |= G0.

Proof: Let G be derived from G0 by erasing two cuts c1, c2 with area(c1) =
{c2}. We set c := ctx(c1). We want to apply Lemma 9.1 and therefore have
to show that property P of Lemma 9.1 is valid for c ∈ G and c ∈ G0. We have

area0(c) = (area(c) ∪ area(c2))\{c1}

(∗)

With (∗) we get

val |= G[c]

Def |=
⇐⇒ val fulﬁlls all vertex- and cut-conditions of area(c)
⇐⇒ val fulﬁlls all v.-, c.-cond. of area(c)\{c1}, and v 6|= G[c1]
⇐⇒ val fulﬁlls all v.-, c.-cond. of area(c)\{c1}, and val |= G[c2]
(∗)
⇐⇒ val fulﬁlls all v.-, c.-cond. of area0(c)
Def |=
⇐⇒ val |= G0[c]

Now Lemma 9.1 yields that we have val |= G ⇐⇒ val |= G0.

2

From the preceding lemmata we obtain the soundness of the calculus.

Theorem 9.5 (Soundness of the Alpha-Calculus). A set H ∪ {G} of
formal alpha graphs over A satisﬁes

H ‘ G =⇒ H |= G .

Proof: Let H ‘ G. Then there are G1, . . . , Gn with G1 . . . Gn ‘ G. From the
preceding Lemmata 9.3, 9.4 and 9.2 we conclude

G1 . . . Gn |= G

(9.1)

Now let val be a valuation val |= H, i.e., val |= G0 for each G0 ∈ H. Then we
have particularly val |= Gi for each 1 ≤ i ≤ n, thus val |= G1 . . . Gn. Now
2
Eqn. 9.1 yields val |= G.

86

9 Soundness and Completeness

9.2 Completeness

As the empty sheet of assertion is always true, the graph
This leads to the following deﬁnition and lemmata.

(cid:3)
(cid:2)

(cid:0)
(cid:1)is always false.1

Deﬁnition 9.6 (Consistent Sets of Alpha Graphs). A set H of formal
(cid:0)
alpha graphs is called consistent if H ‘
(cid:1)does not hold. A formal alpha
graph G is called consistent if {G} is consistent.

(cid:3)
(cid:2)

Lemma 9.7 (Consistency Lemma 1). A set H∪{G} of formal alpha graphs
is not consistent if and only if H ‘ G0 for every formal alpha graph G0.

Proof: Only ‘=⇒’ has to be shown. Let G1, . . . , Gn ∈ H with G1 . . . Gn ‘
We conclude:

G1 . . . Gn

‘

(cid:3)
(cid:2)

(cid:0)
(cid:1)

ins.
‘

(cid:19)
(cid:11)
(cid:10)
(cid:18)

(cid:16)
(cid:8)
dc
(cid:9)G0
‘ G0
(cid:17)

Def. ‘=⇒ H ‘ G0

(cid:3)
(cid:2)

(cid:0)
(cid:1).

2

Lemma 9.8 (Consistency Lemma 2). Let H∪{G} be a set of formal alpha
graphs. Then we have
(cid:11)
H ‘ G ⇐⇒ H ∪ { G
(cid:10)

(cid:8)
(cid:9)⇐⇒ H ∪ {G} ‘

(cid:11)
(cid:0)
(cid:1) and H ‘ G
(cid:10)

(cid:8)
(cid:9)} ‘

(cid:0)
(cid:1) .

(cid:3)
(cid:2)

(cid:3)
(cid:2)

In particular, for two formal alpha graphs G1 and G2, we have
(cid:3)
(cid:2)

(cid:0)
(cid:1) and G1 ‘ G2

G1 ‘ G2 ⇐⇒ G1 G2

(cid:8)
(cid:9)⇐⇒ G1 G2 ‘

(cid:8)
(cid:9)‘

(cid:11)
(cid:10)

(cid:11)
(cid:10)

(cid:3)
(cid:2)

(cid:0)
(cid:1)

Proof of the ﬁrst equivalence (the second is shown analogously): We have

H ‘ G Def. ‘⇐⇒ there are G1, . . . , Gn ∈ H with G1 . . . Gn ‘ G

(cid:15)

dc⇐⇒ there are G1, . . . , Gn ∈ H with ‘

T. 8.7⇐⇒ there are G1, . . . , Gn ∈ H with ‘

(cid:11)
G1 . . . Gn G
(cid:10)
(cid:11)
G1 . . . Gn G
(cid:10)
(cid:8)
(cid:11)
T. 8.7⇐⇒ there are G1, . . . , Gn ∈ H with G1 . . . Gn G
(cid:9)‘
(cid:10)
(cid:11)
(cid:0)
Def. ‘⇐⇒ H ∪ { G
(cid:1)
(cid:10)

(cid:8)
(cid:9)} ‘

(cid:14)
(cid:19)

(cid:18)

(cid:3)
(cid:2)

(cid:12)

(cid:13)

(cid:8)
(cid:9)
(cid:8)
(cid:11)
(cid:3)
(cid:2)
(cid:9)
(cid:10)
(cid:0)
(cid:3)
(cid:1)
(cid:2)

(cid:0)
(cid:1)

(cid:8)
(cid:9)

(cid:16)

(cid:17)

2

Consistent sets of graphs can be extended to maximal (with respect to ⊆) consistent sets graphs, which have canonically given valuations satisfying them.
This will be elaborated with the next lemmata.

1 Peirce treated EGs as judgments, i.e., as propositions which are asserted to be true
in some context. A ‘graph’ which is never true in any context cannot be asserted
and is therefore in Peirce’s view not a graph. For this reason Peirce called the
sketched graph (and all equivalent graphs) ‘pseudograph’ (see [Pei35]).

9.2 Completeness

87

Lemma 9.9 (Properties of Maximal Consistent Sets). Let H be a maximal (with respect to ⊆) consistent set of graphs. Then:

(cid:11)
1. Either H ‘ G or H ‘ G
(cid:10)

(cid:8)
(cid:9) for each formal alpha graph G.

2. H ‘ G ⇐⇒ G ∈ H for each formal alpha graph G.

3. G1 G2 ∈ H ⇐⇒ G1 ∈ H and G2 ∈ H for all formal alpha graphs G1, G2.
(cid:8)
(cid:3)
(cid:2)
(cid:9)‘

(cid:0)
(cid:1). Hence if H is consistent, H ‘ G
(cid:8)
(cid:9) cannot hold both. Now we can prove all propositions of this

(cid:11)
Proof: It is easy to see that G G
(cid:10)
(cid:11)
and H ‘ G
(cid:10)
lemma:

(cid:11)
1. Assume H 6‘ G for a graph G. Lem. 9.8 yields that H ∪ { G
(cid:10)

(cid:8)
(cid:9)} is consis-
(cid:8)
(cid:9)∈ H, hence we have H ‘

(cid:11)
tent. As H is maximal, we conclude that G
(cid:10)
(cid:11)
G
(cid:10)

(cid:8)
(cid:9).

(cid:11)
2. Let H ‘ G. As H is consistent, we get that H 6‘ G
(cid:10)

(cid:8)
(cid:9). So Lem. 9.8 yields

that H ∪ {G} is consistent. As H is maximal, we conclude G ∈ H.

3. Follows immediately from 1. and 2.

2

Consistent sets of formal alpha graphs can be extended to maximal consistent
sets of formal alpha graphs. This is done as usual in logic.

Lemma 9.10 (Extending Consistent Sets to Maximal Sets). Let H be
a consistent set of formal alpha graphs. Then there is a maximal set H0 of
formal alpha graphs with H0 ⊇ H.

Proof: Let G1, G2, G3, . . . be an enumeration of all formal alpha graphs.2 We
deﬁne inductively a set of graphs Hi for each i ∈ N. We start with setting
H1 := H. Assume now that Hi ⊇ H is deﬁned and consistent.
(cid:11)
If Hi ‘ Gi
(cid:10)
Lemma 9.8.

(cid:8)
(cid:9)does not hold, then Hi+1 := Hi ∪ {Gi} is consistent due to

(cid:11)
(cid:8)
(cid:9)holds, then Hi+1 := Hi ∪ { Gi
(cid:10)

(cid:11)
(cid:10)
n is a consistent maximal graph set with H0 ⊇ H.

Otherwise, if Hi ‘ Gi
Now H0 := S
Maximal consistent set of graphs have canonically given valuations, i.e., models.

(cid:8)
(cid:9)} is consistent.
2

n∈N H0

Theorem 9.11 (Valuations for Maximal Consistent Sets). Let H be a
maximal consistent set of formal alpha graphs. Then there exists a canonically
given valuation val such that val |= G for each graph G ∈ H.

2 Remember that we assumed that A is ﬁnite, hence we have only countably many
formal alpha graphs (more precisely: countably many isomorphism-classes of formal alpha graphs). If we allowed inﬁnite alphabets, the proof could be carried out
with an application of the prim ideal theorem or of (the stronger) Zorn’s Lemma.

88

9 Soundness and Completeness

Proof: Let us ﬁrst deﬁne a graph which states the propositional variable Pi.
We set

G(Pi) := ({v}, >, ∅, ∅, {(v, Pi)}) with an arbitrary vertex v .

Now let val : P → {ff, tt} be deﬁned as follows:

val(Pi) := tt : ⇐⇒ H ‘ G(Pi)

Now let G0 := (V, >, Cut, area, κ) be a formal alpha graph. We show

val |= G0[c] ⇐⇒ H ‘ G0[c]

(9.2)

for each c ∈ Cut ∪ {>}. The proof is done by induction over Cut ∪ {>}. So
let c ∈ Cut ∪ {>} be a cut such that (9.2) holds for each d < c. We have:

val |= G0[c]

Def. evaluation
⇐⇒

Def. val and Ind.Hyp.
⇐⇒

L. 9.9⇐⇒

val(κ(v)) = tt for each v ∈ V ∩ area(c)
and val 6|= G[d] for each d ∈ Cut ∩ area(d)

H ‘ G(κ(v)) for each v ∈ V ∩ area(c)
and H 6‘ G0[d] for each d ∈ Cut ∩ area(d)

G(κ(v)) ∈ H for each v ∈ V ∩ area(c)

(cid:15)
and G0[d]
(cid:14)

(cid:12)
(cid:13)∈ H for each d ∈ Cut ∩ area(d)

L. 9.9⇐⇒

G[c] ∈ H

As we have G = G[>], (9.2) yields for c := >

val |= G0 ⇐⇒ H ‘ G0

thus we are done.

2

Now we are prepared to prove the completeness of the calculus.

Theorem 9.12 (Completeness of the Calculus). A set H∪{G} of formal
alpha graphs over an alphabet A satisﬁes

H |= G =⇒ H ‘ G

Proof: Each valuation which satisﬁes H satisﬁes G as well, i.e., H ∪

has no model. Thus, according to Thm. 9.11, H ∪

(cid:11)
(cid:8)
n
o
G
is not consistent.
(cid:9)
(cid:10)
(cid:11)
(cid:8)
(cid:0)
(cid:3)
(cid:1). The Deduction
(cid:2)
That is, there are G1, . . . , Gn ∈ H with G1 . . . Gn G
(cid:9)‘
(cid:10)
(cid:8)
(cid:11)
(cid:0)
(cid:1), yields
Theorem Thm. 8.7, applied to the two graphs G1 . . . Gn G
(cid:9)and
(cid:10)
(cid:19)

(cid:3)
(cid:2)

‘

(cid:11)
G1 . . . Gn G
(cid:10)

(cid:18)

(cid:11)
(cid:8)
(cid:7)
(cid:6)
(cid:10)
(cid:9)

(cid:8)
(cid:4)
(cid:5)
(cid:9)

(cid:16)
.
(cid:17)

n

(cid:11)
G
(cid:10)

(cid:8)
o
(cid:9)

With the double-cut rule we conclude:

‘

(cid:19)

(cid:18)

(cid:11)
G1 . . . Gn G
(cid:10)

(cid:8)
(cid:9)

(cid:16)

(cid:17)

9.2 Completeness

89

.

Now we apply the Deduction Theorem in the opposite direction to G1 . . . Gn
(cid:11)
and G
(cid:10)

(cid:8)
(cid:9), which yields:

G1 . . . Gn

‘ G

Thus we have H ‘ G .

2

10

Translation to Propositional Logic

In the last chapters, the Alpha part of EGs is developed as a mathematical
logic. This includes deﬁnitions for a syntax, semantics, and a calculus, as well
as a proof that the calculus is adequate, i.e., sound and complete. In formal
Alpha graphs, we have propositional variables and the possibility to construct
the negation of a given graph, as well as the conjunction of some given graphs.
Thus, it is somewhat evident that the system of Alpha graphs correspond to
propositional logic.

This correspondence will be worked out in this section by providing translations from Alpha graphs to formulas of propositional logic, and vice versa,
and by showing that these translations are meaning-preserving. In the Betapart of this treatise, corresponding the translations between Beta graphs and
formulas of ﬁrst order logic are provided. In Beta, these translations turn
out to be much more important (as the completeness-proof in Beta refers to
them), and the deﬁnition and understanding of these translations will be discussed in more detail. For Alpha, the deﬁnitions and proofs in this chapter
are straight-forward. For a deeper discussion of translations, I refer to the
Beta-part.

We start with the deﬁnition of formulas of propositional logic. For our purpose,
it is convenient to consider that fragment which uses only the junctors ‘¬’ (not)
and ‘∧’ (and). It is well-known that all other junctors can be expressed with
these two, i.e., this fragment of propositional logic is functionally complete.

Deﬁnition 10.1 (Propositional Logic). The formulas of propositional formulas (over the set of propositional variables P) is inductively be deﬁned as
follows:

1. Each propositional variable Pi ∈ P is a formula,
2. If f 0 is a formula, then f := ¬f 0 is a formula, and

3. if f1 and f2 are formulas, then f := (f1∧f2) is a formula.

92

10 Translation to Propositional Logic

The evaluation of formulas for a given valuation is canonically be deﬁned as
follows:

Deﬁnition 10.2 (Evaluations Of Formulas). We deﬁne the semantical
entailment relation val |= f between valuations and formulas inductively over
the composition of formulas as follows:

• For Pi ∈ P we set val |= Pi
• For f = f1 ∧ f2, we set val |= f1 ∧ f2 :⇐⇒ val |= f1 and val |= f2.
• For f = ¬f 0, we set val |= ¬f 0

:⇐⇒ val(Pi) = tt .

:⇐⇒ val 6|= f1 .

Now we are prepared to deﬁne the translations between the system of Alpha
graphs and propositional logic. Both translations are inductively deﬁned.

Translations from graphs to symbolic logic are denoted by the letter Φ, translations in the opposite direction by the letter Ψ .1 In order to distinguish the
mappings from the Alpha part from the mappings which will be deﬁned in
the Beta part, they are indexed with the letter α.

We start with the deﬁnition of the translation Ψα from the system of formal
alpha graphs to propositional logic. This deﬁnition is straight-forward.

Deﬁnition 10.3 (Ψα). We deﬁne Ψα inductively over the composition of formulas.

• For Pi ∈ P, let Ψα(Pi) := ({v}, >, ∅, ∅, {v, Pi)}). That is, we set:

Ψα(Pi) := Pi

.

• For f = f1 ∧ f2 , let

Ψα(f ) := Ψα(f1) Ψα(f2)

be the juxtaposition of Ψα(f1) and Ψα(f2) .

• For f = ¬f 0 with Ψα(f 0) = (V, >, Cut, area, κ), let c0 /∈ V ∪ Cut ∪ {>} be
a new cut, and let Ψα(f ) := (V, >, Cut0, area0, κ) with Cut0 := Cut ∪ {c0}
and area0 = area\{(>, area(>))} ∪ {(c0, area(>)), (>, c0)} . I.e., we set:
(cid:15)

Ψα(f ) := Ψα(f )

(cid:14)

(cid:12)
(cid:13) .

For the deﬁnition of the translation Φα, we have to take care that in existential
graphs, empty cuts may occur, which have no counterparts in propositional

1 These letters are used for Sowa’s conceptual graphs, which are based on Peirce’s

existential graphs, too.

10 Translation to Propositional Logic

93

(cid:3)
(cid:2)

(cid:0)
(cid:1)’ is a well-formed graph, but ‘¬’ is not a well-formed formula). We
logic (’
use the following workaround: An empty area (the area of an empty cut or the
empty sheet of assertion) is translated to the formula ¬(P1 ∧ ¬P1), which is
always evaluated to true. The remaining deﬁnition of Φα is straight-forward.

Deﬁnition 10.4 (Φα). Let G := (V, >, Cut, area, κ) be a formal alpha
graph. Using Lem. 7.6, we assign inductively to each context c ∈ Cut ∪ {>} a
formula Φα(G, c) as follows:
If c is an empty context, i.e., area(G, c) = ∅, we set Φα(G, c) := ¬(P1 ∧ ¬P1).
If c is not empty, let Φα(c) be the conjunction of the formulas ¬Φα(d) for cuts
d ∈ area(c) and the formulas κ(v) for vertices v ∈ area(c).

Finally we set Φα(G) := Φα(G, >), and the deﬁnition of Φα is ﬁnished.

It should be noted that Φα is, strictly speaking, not a function. The phrase
’let Φα(c) be the conjunction of the formulas’ does does not specify in which
order the formulas ¬Φα(d) for d ∈ area(c) and κ(v) for v ∈ area(c) have to
be composed, neither how brackets are used. Thus, Φα(G) is only given up
the order of subformulas of conjunctions. For example, the graph

(cid:19)

(cid:16)

P1

P2 P3

(cid:18)

(cid:17)

can be translated to the following formulas:

P1 ∧ ¬(P2 ∧ P3) , P1 ∧ ¬(P3 ∧ P2) , ¬(P2 ∧ P3) ∧ P1 , and ¬(P3 ∧ P2) ∧ P1 .

But, as conjunction is (in a semantical sense) an associative and commutative
operation, all possible translations of a graph are semantically equivalent, thus
we consider Φα as a mapping which assigns one formula to each graph.
To provide a further example, we consider the graph of Fig. 7.1, i.e.

.

This graph is translated to:

P1 ∧ P1 ∧ P2 ∧ ¬(¬(P3 ∧ ¬P4 ∧ ¬P4) ∧ ¬P2 ∧ P3 ∧ ¬¬(P1 ∧ ¬P1))

and, vice versa, this formula is translated back into the following graph:

The next theorem shows that Ψα and Φα are indeed meaning-preserving.

.

4P4P3P2P3PP1P12P2PP1P14P4P3P2P3PP1P194

10 Translation to Propositional Logic

Theorem 10.5 (Ψα and Φα are Meaning-Preserving). Let a valuation
val : P → {ff, tt} be given, let G be a formal alpha graph and f be a formula
of propositional logic. Then we have:

val |= f ⇐⇒ val |= Ψα(f )

and

val |= G ⇐⇒ val |= Φα(G)

.

Proof: Both the set of all propositional formulas and the deﬁnition of Ψα are
deﬁned inductively. Thus, the proof for the ﬁrst equivalence is carried out
induction over the composition of formulas. If Pi is a propositional variable,
it is easy to see that we have val |= Pi ⇐⇒ val |= Ψα(Pi). If g = g1 ∧ g2 is a
formula, we obviously have

val |= g Def.10.2⇐⇒ val |= g1 and val |= g2

Ind. Hyp.

⇐⇒ val |= Ψα(g1) and val |= Ψα(g2)
Def.8.2⇐⇒ val |= Ψα(g1) Ψα(g2)

The proof for the case g = ¬g0 can be done analogously, which proves the ﬁrst
equivalence.

Now let G := (V, >, Cut, area, κ) be a ﬁxed, formal alpha graph. Similar to
the proof for Ψα, we can prove by induction over the tree Cut ∪ {>} that we
have

val |= G[c] ⇐⇒ val |= Φα(G, c)

(10.1)

for each context c ∈ Cut ∪ {>} (see Def. 8.2 for the deﬁnition of val |= G[c]).
Thus we have

val |= G Def.8.2⇐⇒ val |= G[>]

Eqn. 10.1

⇐⇒ val |= Φα(G, >) Def.10.4⇐⇒ val |= Φα(G) ,

which proves the second equivalence.

2

The next corollary ﬁxes some immediate consequences of this theorem.

Corollary 10.6. Let f be a formula of and let F be a set of formulas. Then
we have:

F |= f ⇐⇒ Ψα(F ) |= Ψα(f )

.

(10.2)

Analogously, let G be a formal alpha graph and let H be a set of formal alpha
graphs. Then we have:

H |= G ⇐⇒ Φα(H) |= Φα(G)

.

(10.3)

Moreover we have that G and Ψα(Φα(G)), as well as f and Φα(Ψα(f )), are
semantically equivalent.

Proof: The semantical equivalence of G and Ψα(Φα(G)), resp. f and Φα(Ψα(f )),
follows immediately from Thm. 10.5. It remains to prove Eqns. 10.2 and 10.3.

10 Translation to Propositional Logic

95

We show only the direction ‘=⇒” of the Eqn. 10.2, the other direction and
the Eqn. 10.3 are shown analogously. So let f be a formula of and let F be
a set of formulas with F |= f . Let val be a valuation with val |= Ψα[F ], i.e.,
val |= Ψα(f 0) for all f 0 ∈ F . Theorem. 10.5 yields val |= f 0 for all f 0 ∈ F .
2
From F |= f we obtain val |= f . Now Thm. 10.5 yields val |= Ψα(F ).

96

10 Translation to Propositional Logic

Beta

11

Getting Closer to Syntax and Semantics of
Beta

We have already seen in the introduction some examples for Beta-graphs. Let
us repeat the ﬁrst examples of Chpt. 2:

In all cases we have a heavy line (It will become clear soon why I do not write
‘line of identity’) which can be understood to denote one object. The meaning
of the graphs are ‘there is a cat’, ‘it is not true that there is a cat’, and ‘there
is something which is not a cat’, respectively.

But a heavy line does not necessarily stands for one object. We have already
seen that the graph

Etwothings :=

has the meaning ‘there are at least to things’. This is due to the fact that
a heavy line traversing a cut denotes non-identity. But so far, this seemed
to be a mere convention. Moreover, a comprehensive method for interpreting
more complex diagrams is still missing. For example, what about the following
diagrams with more complex structures of heavy lines crossing cuts? Can we
be sure to grasp the precise meaning of them?

In this chapter, several examples of EGs will be discussed in detail. These
examples should hopefully cover all features and aspects of EGs. The purpose
of the discussion it twofold:

catcatcatRPSQTPRQS98

11 Getting Closer to Syntax and Semantics of Beta

1. It will be elaborated how EGs are read. This is a reconstruction of Peirce’s

understanding of EGs.

2. From the reconstruction of Peirce’s understanding we will obtain the basis

for the forthcoming formalization of EGs in the next chapters.

These two purposes are more connected with each other than one would expect. Of course, we need a precise understanding of the readings of EGs to
elaborate an appropriate formalization. It will turn out that the main clue
to a deeper understanding of EGs is the idea that LoIs are composed of socalled identity spots. This insight will not only yield a method which allows
to understand arbitrarily complex diagrams. Moreover, from this idea we will
obtain the main idea for an appropriate formalization of diagrams.

11.1 Lines of Identities and Ligatures

We start with an investigation of the element which is added to existential
graphs in the step from Alpha to Beta: the line of identity. Peirce describes
a LoI as follows: ‘The line of identity is [. . .] a heavy line with two ends and
without other topical singularity (such as a point of branching or a node), not
in contact with any other sign except at its extremities.’ (4.116), and in 4.444
he writes: ‘Convention No. 6. A heavy line, called a line of identity, shall be
a graph asserting the numerical identity of the individuals denoted by its two
extremities.’).

It should be noted that Peirce does not claim that a LoI denotes one object.
Instead of this, each of the two ends of the LoI denotes an object, which are
identical. Of course, this is semantically equivalent to the existence of one
object. The reason why Peirce does not use this interpretation of a LoI is,
although Peirce called LoI ‘indivisible graphs’, that LoIs bear a kind of inner
structure, which shall be unfolded now. Roughly speaking: Lines of identity are
assembled of overlapping, heavily marked points. These points are described
by Peirce in 4.405 by the following convention:

Convention No. V. Every heavily marked point, whether isolated, the
extremity of a heavy line, or at a furcation of a heavy line, shall denote
a single individual, without in itself indicating what individual it is.

We ﬁnd a similar quotation later in 4.474, where he writes

Now every heavily marked point, whether isolated or forming a part
of a heavy line, denotes an indesignate individual. [. . .] A heavy line
is to be understood as asserting, when unenclosed, that all its points
denote the same individual.

11.1 Lines of Identities and Ligatures

99

Thus, the most basic graph is not a single LoI. It is a simple, heavy marked
point, a heavy dot like this:

From now on, these dots will be called ‘identity spots’. Thus an identity spot
‘shall denote a single individual, without in itself indicating what individual it
is’, that is, it stands for the proposition ‘there exists something’.

These spots may overlap, and this means that they denote the same object. As
Peirce writes in 4.443: ‘Convention No. 5. Two coincident points, not more,
shall denote the same individual.’ Moreover, a LoI is composed of identity
spots which overlap. Peirce writes in 4.561:

A heavy line shall be considered as a continuum of contiguous dots;
and since contiguous dots denote a single individual, such a line without any point of branching will signify the identity of the individuals
denoted by its extremities.

Let us consider the following existential graph which is a simple LoI:

E1 :=

The best way to depict Peirces understanding of LoIs is, roughly speaking, to
magnify them, such that identity spots the LoI is composed of become visible.
In a letter to Lady Welby, p.4, Peirce remarks that ‘every line of identity
ought to be considered as bristling with microscopic points of teridentity, so

when magniﬁed shall be seen to be

that
’ (this quotation is
adopted from Roberts ([Rob73], p. 117, footnote 5). We conclude that Peirce
understands a heavy line, i.e., a LoI, to be composed of identity spots.1 In his
book ‘A Peircean Reduction Thesis’ ([Bur91a]), Burch provides magniﬁcations
of existential graphs.2 As these magniﬁcations are invented by Burch, they
cannot be found in the works of Peirce, but they depict very clearly Peirce’s
understanding of LoI and are therefore very helpful to understand Peirce
intuition. One possible magniﬁcation of E1 is

1 The teridentity mentioned by Peirce is the triadic relation expressing the identity
between tree objects. Its vital role in existential graphs is thoroughly discussed
by Burch in ‘A Peircean Reduction Thesis’ ([Bur91a]). We will come back later in
some places to this relation to unfold some of its speciﬁc properties, and particularly Chpt. 26 is dedicated to an extension of Burch’s proof of Peirce’s reduction
thesis.

2 Furthermore, he writes ‘lines of identity are simply lines that are themselves composed of spots of identity (of various adicities) that are directly joined together’,
thus he shares this understanding of LoIs as well.

100

11 Getting Closer to Syntax and Semantics of Beta

The identity spots are drawn as circles. The overlapping of these circles represents that the identity spots are coincident. Each point ‘denotes an indesignate
individual’, and ‘two coincident points [. . .] shall denote the same individual’,
that is, the individuals are identiﬁed. This identity relation is represented by
the small dot in the intersection of two circles.

In the magniﬁcation, we have chosen a number of ten identity spots, but of
course, this number is arbitrary. For a number of 10, the most explicit meaning
of E1 is: There are individuals o1, o2, o3, . . . , o10, o1 is (identical with) o2, o2 is
(identical with) o3, . . ., and o9 is (identical with) o10. Of course, the meaning
of a LoI does not depend on the number of identity spots it is composed of, as
all identity spots ﬁnally denote the same object. As Peirce writes in a diﬀerent
place ([PS00]): ‘The line of identity can be regarded as a graph composed of
any number of dyads ’-is-’ or as a single dyad’ and he describes the graph

as follows: ‘There is a man that is something that is something that is not
anything that is anything unless it be something that will not die.’ The precise
understanding of this passage will become clear in Sect. 11.3, where we discuss
heavy lines crossing cuts. Moreover, describing a graph this way appears to
be ‘unspeakably triﬂing, – not to say idiotic’, as Peirce admits. Nonetheless,
for our discussion, it is worth to note that these passages makes clear that the
magniﬁcations we use are indeed very close to Peirce’s understanding of LoIs.

As a LoI and a single, heavy spot are diﬀerent items, we can know understand
why Peirce does not regard a LoI simply to denote one object. We conclude
that Convention No. 6 of 4.444, where Peirce writes that a LoI is ‘asserting the
numerical identity of the individuals denoted by its two extremities’ is not a
convention or deﬁnition, but a conclusion from Peirce’s deeper understanding
of LoIs.

The next graph we have to investigate is a device of branching heavy lines,
i.e., we consider

E2 :=

In order to understand a branching of heavy lines, Peirce provides in 4.445
and in [PS00] similar examples, which are depicted in Fig. 11.1. In 4.445,
he explains the left graph of Fig. 11.1 as follows: ‘The next convention to be
laid down is so perfectly natural that the reader may well have a diﬃculty in
perceiving that a separate convention is required for it. Namely, we may make
a line of identity branch to express the identity of three individuals. Thus,
Fig. 79 will express that some black bird is thievish.’ Similar, in his tutorial
[PS00] of 1909 he writes that the right graph of Fig. 11.1 ‘is a graph instance
composed of instances of three indivisible graphs which assert ‘there is a male’,

manwill die11.1 Lines of Identities and Ligatures

101

Fig. 11.1. Fig. 79 of 4.445 and an example the of the tutorial [PS00]

‘there is something human’ and ‘there is an African’. The syntactic junction
or point of teridentity asserts the identity of something denoted by all three.’

In contrast to the common notation of identity as dyadic which expresses the
identity of two objects,3 the teridentity expresses the identity of three objects.
Consider the following magniﬁcation of E2:

The point where all lines meet is the point of teridentity (4.406 ‘Also, a point
upon which three lines of identity abut is a graph expressing the relation of
teridentity’). In the magniﬁcation, the three identities are depicted by the
three small dots in the circle in the middle.

The so-called teridentity, that is, the identity relation for three objects, plays
a crucial role in Peirce’s diagrammatic logic. In a linear representation of
ﬁrst order predicate logic like FO, where devices like variables or names are
used to denote objects, it is suﬃcient to have a dyadic identity relation. For
example, to express that three variables x, y, z denote the same object, we
simply use the formula x = y ∧ x = z or x = y ∧ y = z ∧ x = z. But, it seems
quite obvious that in the system of existential graphs, we need a device like
branching heavy lines to express the identity of more than two objects. In
4.445, Peirce writes ‘Now it is plain that no number of mere bi-terminal bonds
[. . .], can ever assert the identity of three things, although when we once have
a three-way branch, any higher number of terminals can be produced from it,
as in Fig. 80.’4

This passage contains two kinds of informations. First of all, Peirce states
that branching points are needed to express the identity of more than two

3 More precisely: The identity of the objects which are denoted by two signs. To
quote Peirce (4.464): ‘But identity, though expressed by the line as a dyadic rela-

is thieviesh is a birdis blackmaleAfricanhuman102

11 Getting Closer to Syntax and Semantics of Beta

Fig. 11.2. Fig. 80 of 4.445

objects. But Peirce did not take branching points with an arbitrary number of branches into account: It is likely that he considered only EGs where
no branching points with more than three branches occur. For example, in
Convention No. 7, which will immediately be provided, Peirce says that a
branching line of identity expresses the identity of three individuals), or in
the quotation in the letter to Lady Welby given on page 99 he explicitely
states that a line of identity is composed of teridentity spots. In fact, none of
the examples Peirce provides in Book II, ’Existential Graphs’ of [HB35] have
branching points with more than three branches. existential graphs only

A branching point with three branches expresses the identity of three objects.
The other information in the above-quoted passage is an argument that identity between more than three objects can be expressed by means of teridentity.
To put it diﬀerently: Allowing only branching points three branches (which
is a syntactical restriction) does not lead to a loss of expressiveness. In the
formal elaboration of EGs, this will be mathematically proven (see Lem. 16.3
and the following examples).

For this reason, Peirce hardly considers EGs where branching points with more
than three branches occur. The quotations above indicate, as they explicitely
refer to the identity of three objects, that Peirce did even not allow branching
points with more than three branches.

Considering EGs where only branching points with three branches are allowed
is in my view a restriction which leads to an unnecessary syntactical overhead.
Moreover, it will turn out that the semantics and transformation rules can be
canonically extended to existential graphs where branching points with more

tion, is not a relation between two things, but between two representamens of the
same thing.’

4 In this diagram, two slight thoughtlessnesses are remarkable: First of all, it should
recognized that Peirce uses singular terms, i.e. names for objects, in this diagram
(namely ‘Aristotle’, ‘Alexander’ and ‘Plato’). Secondly, he implicitly brings in an
universal quantiﬁcation by the use of a relation ‘any disciple of’.

conqueror of the worldAlexanderfather of logicrecognized as the prince of philosophersa great naturalista wretched physicistgreater philosopher thanother thanany disciple ofPlatoan asclepiadteacher ofAristotle11.1 Lines of Identities and Ligatures

103

than three branches are permitted. Thus we will consider existential graphs
having branching points with more than thee branches, too. For example, the
graph of Fig. 11.1 could be transformed into the following graph, having such
a branching point.

The need of incorporating the teridentity into existential graphs, and the fact
that identity relations of higher arities than 3 can be expressed by means of
teridentity, is a part of Peirce’s famous reduction thesis.. Roughly speaking,
this thesis claims that each each relation with an arity greater than three can
be reduced in some sense to ternary relations, but it is impossible to reduce
relation to binary relations. In fact, the need of the branching points is not
based on the graphical representations of EGs, i.e., on the syntax of EGs. It
can be be proven semantically that we need the teridentity relation (which
is diagrammatically represented by a branching point with three branches).
This will be elaborated in Chpt. 26.

To conclude the short discussion of the number of branches, I provide one one
the rare examples of an graph where such a branching point is allowed and
discussed. In the paper ’the logic of relatives’ (The monist, vol. 7, 1897, see
3.456–3.552), he writes in 3.471

Several propositions are in this last paragraph stated about logical
medads which now must be shown to be true. In the ﬁrst place, although it be granted that every relative has a deﬁnite number of
blanks, or loose ends, yet it would seem, at ﬁrst sight, that there is
no need of each of these joining no more than one other. For instance,
taking the triad ”– kills – to gratify –,” why may not the three loose

Fig. 11.3. Fig. 3 of 4.471

conqueror of the worldAlexanderan asclepiadteacher offather of logicrecognized as the prince of philosophersa great naturalista wretched physicistgreater philosopher thanother thanany disciple ofPlatoAristotleJohn it is thatto grativykills104

11 Getting Closer to Syntax and Semantics of Beta

ends all join in one node and then be connected with the loose end of
the monad ”John is –” as in Figure 3 making the proposition ”John it
is that kills what is John to gratify what is John”? The answer is, that
a little exercise of generalizing power will show that such a four-way
node is really a tetradic relative, which may be expressed in words
thus, ”– is identical with – and with – and with –”; so that the medad
is really equivalent to that of Figure 4 [. . .]

Fig. 11.4. Fig. 4 of 4.471

The graphical notation Peirce uses in this place diﬀers from the common
notation for EGs. In this passage, Peirce explicitely discusses the identity
.=4 for this identity, the last graph could
with four places. If we had a symbol
be depicted as follows:

We will come back to this in Chpts. 21 and 16. Moreover, it is remarkable
that Peirce uses here a dedicated bold spot to refer to an individual, and this
spot is linked with lines to the relatives (relations). This notation is very close
to the formal elaboration of EGs, which will be soon be provided.

Peirce sometimes uses the term ‘line of identity’ for a linked structure of
heavy lines. In his Cambridge lectures of 1898 ([Pei92]) we ﬁnd the phrase:
‘Now as long as there is but one such line of identity, whether it branches
or not [. . .].’, and even in the collected papers, 4.446, we ﬁnd ‘Convention
No. 7. A branching line of identity shall express a triad rhema signifying the
identity of the three individuals, whose designations are represented as ﬁlling
the blanks of the rhema by coincidence with the three terminals of the line.’
But Peirce’s quotation should be understood to be a simpliﬁcation for the
sake of convenience. In both quotations, he speaks about linked structures of
heavy lines which are wholly placed on the sheet of assertion. In this case, such
a linked structure can -similar to a LoI- be still understood to denote a single
object, and in this respect, using the term ‘line of identity’ is not misleading.
But linked structures of heavy lines may cross cuts, and it will turn out that
this situation deserves a special treatment, and there are cases where such
a linked structure cannot any more be understood to denote a single object.

to grativykillsJohn it is thatis identical withand withand withJohn it is thatkillsto gravity1213443211.1 Lines of Identities and Ligatures

105

For this reason, Peirce introduces a new term for linked structures of LoIs. In
the collected papers, he writes in 4.407: ‘A collection composed of any line of
identity together with all others that are connected with it directly or through
still others is termed a ligature. Thus, ligatures often cross cuts, and, in that
case, are not graphs’, and later on in 4.416, he writes ‘The totality of all the
lines of identity that join one another is termed a ligature. A ligature is not
generally a graph, since it may be part in one area and part in another. It is
said to lie within any cut which it is wholly within.’ So he explicit discriminates
between one line of identity and a linked structure of lines of identity which
he calls ligature. In this treatise, the distinction between lines of identity and
ligatures is adopted.

The quoted passages indicate even more: Peirce speaks of collections of LoIs
‘together with all others’, and he considers ‘the totality of all the lines of
identity that join one another’, thus Peirce’s understanding of a ligature is a
maximal connected network of LoIs. In this treatise, this condition will not be
used, when ligatures are formally deﬁned.

A single LoI is understood to be a ligature as well, but a ligature, as soon as it
has branches or when it crosses a cut, is not a LoI. As Peirce writes in 4.499:
‘Let us, then, call a series of lines of identity abutting upon one another at
seps, a ligature; and we may extend the meaning of the word so that even a
single line of identity shall be called a ligature. A ligature composed of more
than one line of identity may be distinguished as a compound ligature.’ Thus,
E2 is made up of three LoIs which form a (compound) ligature.

Comment:
In secondary literature, linked structures of heavy lines are sometimes
called ‘line of identity’ as well. For example, Roberts writes in [Rob73]: ‘We could
consider the [. . .] lines as a single line of identity with three extremities which have
a point in common [. . .]. And the totality of all the lines of identity that join one
another he (Peirce) called a ‘ligature’. we prefer the former terminology [. . .]’, and
he provides the following convention: ‘C8: A branching line of identity with n number of branches will be used to express the identity of the n individuals denoted by
its n extremities.’ Sowa shares the understanding that the linked structure can be
regarded as a single LoI. For example, in [Sow97a] he says: ‘In Peirce’s graphs, a
bar or a linked structure of bars is called a line of identity’, and in his commentary
in [PS00] he describes a graph similar to the right graph of Fig.11.3 as follows: ‘[. . .]
part of the line of identity is outside the negation. When a line of identity crosses
one ore more negations [. . .]’.

Finally, it should be noted that we have closed heavy lines as well. Consider
the following graph and its magniﬁcation:

E3 :=

This graph can be magniﬁed as follows:

106

11 Getting Closer to Syntax and Semantics of Beta

One might have the impression that the discussion so far is much too tedious.
But it will help us to understand how existential graphs are read, no matter
how complicated they are. Particularly, they will help us to answer the questions we raised at the beginning of this chapter. Moreover, it leads us to an
approach how existential graphs can be mathematically be formalized. The
ﬁrst step will be presented now.

It is a natural approach to use the notations of (mathematical) graph theory
for a formalization of Peirce’s graphs. The main idea is to encode the identity
spots of an existential graph by vertices in a mathematical graph. When two
identity spots are coincident (i.e., they denote the same object), we draw an
edge between the corresponding edges. For example, below we have depicted
two mathematical graphs which could be seen to be formalizations of E1 resp.
E2:

for E1

, and

for E2

.

Fig. 11.5. Two possible formalizations for E1 and E2

The number of identity spots which form a LoI is of course not ﬁxed. In
contrast, in the magniﬁcations, we have chosen an arbitrary, ﬁnite number
of spots to represent a LoI ( Peirce said that a LoI ‘can be regarded as a
graph composed of any number of dyads ’-is-’ or as a single dyad.’). Thus, the
following mathematical graphs can be understood to be formalizations for E1
and E2 as well:

for E1

, and

.

for E2

Fig. 11.6. Two diﬀerent possible formalizations for E1 and E2

11.2 Predicates

107

E3 could be seen as two LoI which are joined at both extremities. Then we
would formalize E3 as graph with two vertices and two edges. On the other
hand, E3 could be seen as one LoI of which both extremities are joined: This
would yield a mathematical graph with one vertex and one ‘self-returning’
edge. We will allow this graph as well, i.e., the following two graphs will be
possible formalizations of E3.5

In the ongoing formalization, an isolated heavy point • is distinguished from
a line of identity. That is, E0 is formalized only by the mathematical graph
which is made up of a single vertex. Vice versa, a single vertex is not an
appropriate formalization of E3.

11.2 Predicates

In Fig. 11.1, we have already used an EG with predicates in this chapter. In
order to start our investigation on predicates, we consider the following two
subgraphs of the graph in Fig. 11.1:

Fig. 11.7. Two subgraphs of Fig. 11.1

At a ﬁrst glance, the meanings of both graphs are clear: The left graph is read
‘there is a father of logic’, and the right graph is read ‘Aristotle is the teacher
of Alexander’. This understanding is not wrong, but for the right graph, some
further discussion is needed.

First of all, in the left graph, we have a LoI attached to the string ‘father of
logic’. This string does not denote an object: It is the name of a unary predicate. Being ‘father of logic’ is an attribute: Some objects (of our universe of
discourse) may have this attribute, while others have not. For our reading of
the right graph, we used our (background) knowledge that the names ‘Aristotle’ and ‘Alexander’ denote unique objects instead of unary predicates. This
makes of course a crucial diﬀerence.

Peirce wanted to develop a ‘logic of relatives’ (i.e., relations). In fact, in his
calculus for EGs, Peirce did not provide any rules for the treatment of object

5 One might think that it is better to consider only those mathematical graphs with
a ‘minimal number’ of vertices (i.e., the graphs of Fig. 11.6 should be dismissed).
But the forthcoming formalization of the transformation rules is much easier if
we allow graphs with a higher number of vertices as well.

father of logicteacher ofAlexanderAristotle108

11 Getting Closer to Syntax and Semantics of Beta

names, i.e. he treated all names in EGs as names for predicates.6 Thus, more
formally, the meaning of the right graph is ‘there are two objects such that the
ﬁrst object is Aristotle (is of type ’Aristotle’), the second object is Alexander
(is of type ’Alexander’), and the ﬁrst object is a teacher of the second object.’

teacher of

Peirce understood a predicate as a ‘blank form of [a] proposition’ (4.438 and
4.560). The relation ‘teacher of’ can be written as such a blank form as fol-
. The two blanks, i.e., the places of the predicate, have to
lows:
be ﬁlled with two (not necessarily diﬀerent) arguments to obtain a proposition. Similar to the identity spots LoIs are composed of, in EGs, predicates
occur as so-called predicate spots. Peirce imagined that to each blank of an nary predicate corresponds a ‘certain place’ on the periphery of the predicate
spot, called a hook of the spot. We can attach extremities of LoIs to these
hooks (which corresponds to the ﬁlling of the blanks of the proposition with
arguments). EGs are formalization of propositions: Particularly, in EGs, all
blanks of predicates are ﬁlled, that is, to each hook of each predicate an LoI
is attached. For this reason, there is no graphical representation for hooks,
or, as Zeman writes in [Zem64]: ‘Strangely enough, however, we shall not in
practice see these hooks; in any graph properly so called, all hooks are already
ﬁlled, connected to the appropriate signs for individuals.’ At a ﬁrst glance, an
empty hook of a spot can be compared with a free variable in a formula of
ﬁrst order predicate logic, but an empty hook should better be understood
to correspond to a missing variable in an n-ary predicate, thus leading to a
non-well-formed-formula.

For the magniﬁcation of EGs, I adopt the approach of Burch and draw the
predicate spots larger than the identity spots. Moreover, for the magniﬁcation
it makes sense to represent the hooks graphically. The n hooks of an n-ary
predicate are are indicated by n small dots (similar to the dots in the intersection of identity spots) which are (in contrast to Burch) labeled with the
numbers 1, . . . , n. Thus, the graphs of Fig. 11.2 can be magniﬁed as follows:

Of course, the order of the hooks is crucial. For example, considering the right
graph of Fig. 11.2, it makes a diﬀerence whether Aristotle was the teacher of

6 As the right graph of Fig. 11.2 show, it is desirable to have object names. In the
part ’Extending the System’, object and function names will be added to EGs.

1of logicfather21teacherofAristotle11anderAlex11.2 Predicates

109

Alexander, or Alexander was the teacher of Aristotle. We read the graph from
left to right: Therefore we grasp its intended meaning. Of course, Peirce was
aware that the order of the arguments of a relation is important, but there
are only very few passages where Peirce explicitely discusses how this order
is depicted graphically in EGs. In 4.388, we ﬁnd:

In taking account of relations, it is necessary to distinguish between
the diﬀerent sides of the letters. Thus let l be taken in such a sense
will mean ”Y loves
that

means ”X loves Y.” Then

X.”

Moreover, for the gamma system, in 4.470, he writes that some LoI are attached to the hooks of a spot are ‘taken in their order clockwise.’ Our goal
is still to provide a formalization of EGs which prescinds from the graphical
properties of the diagrams. So far, for the formalization of LoIs, we used the
notation of mathematical graph theory: Identity spots are formalized by vertices of a mathematical graph, and LoIs by edges between these vertices. An
edge encodes the identity between the objects denoted by the vertices. Identity
spots have a two-fold purpose: First of all, they denote objects. Moreover, by
letting identity spots overlap, the identity relation is represented by identity
spots as well. In our ongoing formalization, these two diﬀerent functions are
formalized by two diﬀerent syntactical entities: Vertices will denote objects,
and the identity relation is formalized by edges. Identity is a special dyadic
relation, so it is natural to extend the formalization to relations as follows: We
consider graphs with so-called so-called directed hyper-edges. An occurrence
of an n-ary relation name will be formalized as an n-ary directed hyper-edge,
labeled with the relation name. The identity relation will be captured by 2-ary
edges, labeled with the special relation name =. The precise deﬁnition will be
given in the next chapter; in this chapter, this idea shall be illustrated with
some examples.7

The left graph of Fig. 11.2 is encoded with one vertex and one edge which is
attached to this vertex. Furthermore, this edge is labeled with the predicate
name ‘father of logic’. This yields the following mathematical graph:

The edge is represented by writing the name of its label and drawing lines
from this name to the dot which represent the incident vertex.

7 The magniﬁcations oﬀer another possibility to formalize the predicates of EGs.
It is possible to encode the predicates as vertices as well. Formalizations like this
have been carried out by several authors, for example by Chein and Mugnier for
CGs (see [CM92, CM95]), or by Pollandt in [Pol02] and by Hereth Correia and
P¨oschel in [HCP04, HCP06] for relation graphs. I consider an encoding with edges
instead of vertices more practical, but somehow, this decision depends on matter
of (mathematical) taste.

XlYXlYfather of logic1110

11 Getting Closer to Syntax and Semantics of Beta

The right graph of Fig. 11.2 is encoded as follows:

Here we have two vertices and three edges. The ﬁrst edge is an edge which is
coincident with one vertex (the left one) and labeled with the name ‘Aristotle’.
The second edge is coincident with both vertices. This edge is represented by
writing the name of its label, i.e., ‘teacher of’ and drawing lines from this name
to the dots which represent the incident vertices. The order of the incident
vertices is represented by writing the numbers 1 resp. 2 above the lines which
go from the name to the ﬁrst resp. second vertex (i.e., the representing dots).
Analogously, we have a third edge which is labeled with ‘Alexander’ and which
is incident with the second vertex. The next ﬁgure is another representation
of exactly the same mathematical graph, where the three edges are informally
indicated.

As said above: Identity is a special relation, and the former ‘identity edges’
are formalized as as directed edges which are labeled with a name for identity,
like ‘=’. That is, we have the following formalizations of E1 and E2:

and

instead of

instead of

.

As we used directed hyper-edges, we have no diﬃculties to encode relations of
arity three or higher as well. For example, if we have a ternary relation ‘sales
to’, then we can depict an EG with the meaning ‘a ﬁsherman sales a carp to
a cook’ and its formalization as follows:

A possible magniﬁcation of this graph is given in Fig. 11.2.

Finally, a vertex may be linked multiple to a predicate. In the next ﬁgure, you
ﬁnd an EG with the meaning ‘somebody loves himself’ (with l standing for
‘loves’, like in the above quotation of Peirce) and two possible formalizations.

1Aristotleteacher of1Alexander21teacher of11AlexanderAristotle2112112212sales tocookfishermancarp1sales tofisherman1cook1carp213ll12l121211.3 Cuts

111

Fig. 11.8. A magniﬁcation of a graph with a ternary relation ’ sales to ’.

11.3 Cuts

In this section, we extend our investigation to the cuts of existential graphs.
In existential graphs without cuts, every LoI, even every ligature can be understood to represent a single object. The investigation of LoIs and ligatures
has to be extended when we take existential graphs with cuts into account.
Even Peirce writes in 4.449: ‘There is no diﬃculty in interpreting the line of
identity until it crosses a sep. To interpret it in that case, two new conventions
will be required.’

We start with the graph Etwothings and two further examples of Peirce in
which a LoI seems to cross resp. pass a cut.8

Fig. 11.9. Fig. 67 and 68 of 4.407, and Etwothings

In all graphs, one might think we have only one LoI, which, then, should
denote one object. In fact, the meaning of the left graph is ‘there is a man
who is not mortal’, i.e., the heavy line stands for one object.

But we have already seen that the meaning of Etwothings is ‘there are at least
two things’; that is, the heavy line of this graph does not stand for one object.
Analogously, the meaning of the graph n the middle is ‘it is not true that
there are two suns which are diﬀerent’, or ‘there is at most one sun’ for short.

Peirce explains in 4.407 the ﬁrst and second graph (for the ﬁrst graph, an
similar graph an explanation can be found in [PS00] as well) as follows:

8 I changed the shape of the LoIs and cuts.

fisher−mansales to31211carp1cookis mortalis a manis sunis sun112

11 Getting Closer to Syntax and Semantics of Beta

A heavily marked point may be on a cut; and such a point shall be
interpreted as lying in the place of the cut and at the same time as
denoting an individual identical with the individual denoted by the
extremity of a line of identity on the area of the cut and abutting
upon the marked point on the cut. Thus, in Fig. 67, if we refer to the
individual denoted by the point where the two lines meet on the cut,
as X, the assertion is, ”Some individual, X, of the universe is a man,
and nothing is at once mortal and identical with X”; i.e., some man
is not mortal. So in Fig. 68, if X and Y are the individuals denoted
by the points on the [inner] cut, the interpretation is, ”If X is the sun
and Y is the sun, X and Y are identical.”

There are two things remarkable in this quotation: First of all, Peirce speaks
about ‘points on cuts’. These points deserve a deeper investigation. Secondly,
he says we have in the left graph two lines of identity which meet on the cut.
It has to be clariﬁed how such an overlapping of two lines of identity on a cut
has to be interpreted. These questions are addressed by the two convention
Peirce spoke about in 4.449. These conventions are as follows:

4.450: Convention No. 8. Points on a sep shall be considered to lie
outside the close of the sep so that the junction of such a point with
any other point outside the sep by a line of identity shall be interpreted
as it would be if the point on the sep were outside and away from the
sep.

4.451: Convention No. 9. The junction by a line of identity of a point
on a sep to a point within the close of the sep shall assert of such
individual as is denoted by the point on the sep, according to the
position of that point by Convention No. 8, a hypothetical conditional
identity, according to the conventions applicable to graphs situated as
is the portion of that line that is in the close of the sep.

These conventions shall be discussed in detail. We start our investigation with
points on a cut, particularly, why Peirce says that ‘ Points on a sep shall be
considered to lie outside the close of the sep’. In 4.502, Peirce provides the
background of this convention. Consider the graphs of Fig. 11.3.

Fig. 11.10. Fig. 154, 155 and 156 of 4.502

In 4.502, he writes: ‘[. . .] consider Fig. 154. Now the rule of erasure of an
unenclosed graph certainly allows the transformation of this into Fig. 155,

is uglyis uglyis ugly11.3 Cuts

113

which must therefore be interpreted to mean ”Something is not ugly,” and
must not be confounded with Fig. 156, ”Nothing is ugly.” ’ In fact, if we
interpreted a point on a cut to lie inside the area of the cut, Figs. 155 and
156 had the same meaning, and the rule of erasure would allow to conclude
’nothing is ugly’ from ’something is not ugly’, which obviously is not a correct
implication. This explains why points on a cut must be interpreted to lie
outside the area of the cut.

Now, before we discuss conventions No. 8 and 9 further, we ﬁrst have to investigate how heavily drawn lines which cross cuts are syntactically understood
in terms of lines of identity and ligatures. The heavy line in Peirce’s Fig. 154
can still be interpreted to denote one object, thus, is seems to be natural that
the heavy line can be understood to be a line of identity. But it has already
been mentioned that lines of identity do not cross cuts. Recall that a LoI is
a heavy line ‘without other topical singularity (such as a point of branching
or a node), not in contact with any other sign,’, or in 4.406, Peirce writes
that a LoI does not have ‘any sort of interruption’. For this reason, he can
draw the following corollary in 4.406: ‘ Corollaries. It follows that no line of
identity can cross a cut.’ Recall that a line of identity is ‘a heavy line with two
ends and without other topical singularity (such as a point of branching or a
node), not in contact with any other sign except at its extremities.’ Networks
of heavy lines of heavy lines crossing cuts are called ligatures. Consider the
following diagrams:

The left diagram depicts an EG. Obviously, this EG contains one network
of heavy lines, i.e., it contains only one maximal ligature. This ligature is
composed of at least 10 lines of identity. We have to write ”at least”, because
each of the lines of identity can be understood to be a ligature which is
composed of (smaller) lines of identity as well. In the right diagram, these 10
lines of identity are enumerated.

After we have have clariﬁed the term ligature, we need to know how ligatures
in EGs are interpreted. We already know how LoIs are interpreted (they assert
the identity of the two objects denoted by its extremities), hence we know how
to interpret branching points as well. So we are able to interpret ligatures in
a given context. But this does not help if we have a heavy line which crosses
a cut. Thus, we have to investigate heavy lines crossing cuts further.

How shall the heavy line of Peirce’s Fig. 154 be understood? In 4.416, Peirce
says: ‘Two lines of identity, one outside a cut and the other on the area of
the same cut, may have each an extremity at the same point on the cut.’
This explains how the heavy line of Peirce’s Fig. 154 can syntactically be
understood: It is composed of two LoIs which meet on a cut. Let us denote

PQPRPPR123Q78910465114

11 Getting Closer to Syntax and Semantics of Beta

the left LoI, which is placed outside the cut, with l1, and the right LoI, which
is placed inside the cut, with l2.
Now we have to investigate how this device of l1 and l2 is semantically be
interpreted. Peirce’s Conventions No. 8 and 9 make the interpretation of points
on a cut which are endpoints of one more more LoIs explicit. This shall be
discussed now.

A LoI expresses that the objects denoted by its two extremities are identical.
The LoIs l1 and l2 have a point in common, namely the point on the cut.
Let us denote the object denoted by the left endpoint of l1 by o1, the object
denoted by the common endpoint of l1 and l2 on the cut by o2, and the object
denoted by the right endpoint of l2 by by o3.
Now Conventions No. 8 and 9, applied to our example, yield the following:
The existence of o1 and o2 is asserted, but the existence of o3, as the right
endpoint of l2 is placed inside the cut, is negated. The LoI l1 expresses that
o1 and o2 are identical, the LoI l2 expresses that o2 and o3 are identical. The
ﬁrst identity is expressed by a LoI outside the cut, the second by a LoI inside
the cut, thus, the identity of o1 and o2 is asserted, but the identity of o2 and
o3 has to be negated. A very explicit (but hardly understandable) translation
of the graph of Peirce’s Fig. 154 in English is therefore: ‘We have two objects
o1 and o2 which are identical, and it is not true that we have a third object
o3 which is identical with o2 and which is ugly.’ This proposition is equivalent
to ‘We have an object which is not ugly.’

Peirce’s conventions are very helpful for our formalization of existential
graphs. We have to add cuts to our formalization, but there is no need to
formalize graphs where it is possible to express that a vertex is on a cut: It is
suﬃcient to consider structures where the vertex is inside or outside the cut.
That is, we will not consider graphs like the following two graphs:

Due to Conventions 8 and 9, we will consider the following two graphs instead:

i.e.,

, and

i.e.,

.

(But we have to keep in mind that for the second graph, the identity expressed
by the edge between the two vertices takes place inside the cut.) For Peirce’s
Fig. 154, if we ‘translate’ each of the two LoIs by two vertices (the extremities)
and an identity edge between them (expressing the identity of the extremities),
the following graph is a possible formalization:

It will turn out in the next chapter that this graph can be transformed to

is ugly11.3 Cuts

115

For this graph, it is easy to see that its meaning is ‘there is something which
is not ugly’.

Comment: Peirce investigates heavy lines crossing a cut with another example. In
4.449, he asks: ‘How shall we express the proposition ’Every salamander lives in ﬁre,’
or ’If it be true that something is a salamander then it will always be true that that
something lives in ﬁre’ ?’ He comes to the conclusion that the only reasonable is the
graph depicted below.

Particularly, he obtains: ‘In order, therefore, to legitimate our interpretation of
Fig. 83, we must agree that a line of identity crossing a sep simply asserts the
identity of the individual denoted by its outer part and the individual denoted by its
inner part.’ Then, he comes to Conventions 8. and 9. quoted above.

In our magniﬁcations, we sketched the join of two identity spots, which expresses the identity denoted by identity spot, by small black dots. From the
discussion above, we conclude that the following three diagrams are reasonable
magniﬁcations of the graphs of Fig. 11.3:

Again, we see that the magniﬁcations correspond to the ongoing formalization
of Peirce’s graphs.

Consider now the graph Etwothings. The meaning of Etwothings is ‘there are at
least two things’. We now have the ability to analyze why this is the correct
interpretation of Etwothings. A possible magniﬁcation of the graph is

Possible formalizations of Etwothings can be obtained from the possible magniﬁcations of Etwothings or from Peirce’s conventions. The formalization obtained from the given magniﬁcation is depicted below. Thus, the following is
a possible formalization of the graph:

is uglylives in fireis a salamanderis uglyis uglyis ugly116

11 Getting Closer to Syntax and Semantics of Beta

A formalization of Etwothings can be better obtained from Peirce’s Convention
No. 9. Etwothings contains a ligature which is composed of three LoIs. The LoI
in the middle has with each of the other two LoIs an identity spot in common,
and these two spots are placed on the cut, that is, they are considered to
be outside the cut. Moreover, the argumentation above from which Peirce
concluded Convention No. 9 explains that the LoI inside the cut corresponds
to a ‘hypothetical conditional identity, according to the conventions applicable
to graphs situated as is the portion of that line that is in the close of the sep.’
Together with the two LoIs outside the cut end their endpoints, we get the
following formalization:

.

Again, we will see in the next chapter that these formalizations can be simpliﬁed. The following graph contains only two vertices, which are placed on
the sheet of assertion, and one identity-edge, which is placed in the cut and
which connects the vertices.

As the identity-edge is placed inside the cut, the identity of the objects denoted
by the vertices is denied. I.e., this graph has in fact the meaning ‘there are two
objects o1 and o2 such that it is not true that o1 and o2 are identical’, that is,
there are at least two things. This is probably the best readable formalization
of Etwothings.
We have seen that understanding of Etwothings as ‘there are at least two things’
is not a convention or deﬁnition, but it can be obtained from a deeper discussion of EGs. Consequently, Peirce states in 4.468 the meaning of Etwothings as
a corollary: ‘Interpretational Corollary 7. A line of identity traversing a sep
will signify non-identity.’

Analogously, we can now understand the next EG, which is Fig.118 in 4.469:

Due to our discussion, a possible formalization of this graph is

We see that the meaning of this graph is ‘there are three things which are
not all identical’. Note that this is a strictly weaker proposition than ‘there

11.4 Border cases: LoI touching or crossing on a Cut

117

are at least three things’. Again, Peirce states the meaning of this graph as a
corollary. Directly after the last corollary, he writes in 4.469. ‘Interpretational
Corollary 8. A branching of a line of identity enclosed in a sep, as in Fig.
118, will express that three individuals are not all identical.’

If we had a symbol
could even simpler be formalized as follows:

.=3 for teridentity (identity of three objects), the graph

This is even better readable. In the formal deﬁnition of EGs, we will use only
the usual, dyadic identity, but in Chapter 16, we will come back to this idea
in order to obtain an improved reading ‘algorithm’ for EGs.

11.4 Border cases: LoI touching or crossing on a Cut

In the last section, in the discussion after Convention 8 and 9, I have already
argued that we do not need to incorporate points on a cut in our forthcoming
formalization of EGs. In this section we will discuss a few more examples of
Peirce’s graphs where LoIs only touch a cut, or when more than two LoIs
meet on directly on a cut. Let us informally call graphs like these ‘degenerated’. In some places, Peirce indeed uses degenerated graphs (in Chpt. 14,
where the rules of Peirce will be discussed, on page 153 an example of Peirce
with two degenerated graphs is provided). We will see that to each degenerated graph corresponds a canonically given non-degenerated graph, thus, for
Peirce’s graphs as well, it is suﬃcient to consider only non-generated graphs.

The main rule to transform a degenerated graph into an non-degenerated
graph is: Points on a cut are considered outside the cut. This rule shall be
elaborated in this section. We start with a simple example. Consider the following graph and its magniﬁcation:

If we consider the points which terminate on the cut to lie outside the cut, we
obtain the following diagram

3118

11 Getting Closer to Syntax and Semantics of Beta

which is simply another way of drawing Etwothings. This is captured by the
ongoing formalization as well: Due to the discussion in the last section,

,

is a possible translation of this graph, which again yields that this graph is
equivalent to Etwothings.
A similar example is the following graph and its magniﬁcation:

Contrary to the last example, we have one identity spot instead of two (which
is an endpoint of a LoI). The magniﬁcation makes clear that

is an appropriate formalization of this graph, which again can be simpliﬁed,
for example to

From the possible magniﬁcations, thus the possible formalizations, we conclude that the following Peircean graph is an appropriate substitute for the
starting graph:

(This is the graph of Fig. 18, page 54 in the book of Roberts. Its meaning is
‘there is a thing which is not identical with itself’, i.e., this EG is contradictory.)

11.4 Border cases: LoI touching or crossing on a Cut

119

Analogous considerations show that it is suﬃcient

• to consider

instead of

or

• to consider

instead of

.

The meaning of the last two graphs is ‘there is an object which has property
P , but is has not both properties R and S’. It should be noted that these two
graphs are semantically equivalent to

This will be elaborated further in Chpt. 14 and Chpt. 16.

When a LoI touches a cut from the outside, we already know from the discussion after Convention 8 and 9 in the last section that the touching can be
omitted. For example,

• we consider

instead of

• we consider

instead of

or

.

The meaning of the last two graphs is ‘there is an object which has properties
P and Q, but not R’. It should be noted that the last two graphs entail, but
are not semantically equivalent to the next graph.

.

(The meaning of this graph is: ‘There is an object o1 with property P and
an object o2 with property Q, such that either o1 and o2 are not identical, or
o1 and o2 are identical, but the property R does not hold for the (identical
objects) o1 and o2’).
Finally we discuss a graph where two heavy lines cross directly on a cut.
Consider the following graph and its magniﬁcation:

SRRSPSRPSRPSRRPQPQRPRQPRQPRQ120

11 Getting Closer to Syntax and Semantics of Beta

Again the magniﬁcation helps to see that the following graph is the appropriate, non-degenerated substitute:

The following graph is semantically equivalent, too:

The meaning of these graphs is ‘there is an object which has property P and
Q, but is has not both properties R and S’.

The examples show how the statement ‘points on a cut are considered outside
the cut’ can be understood to dismiss degenerated EGs. Assume we have a
degenerated EG, where some LoIs meet on a cut. This shall be depicted as
follows (from the cut, only a segment of the cut-line is depicted):

Then this device can be replaced by

to obtain a equivalent Peircean graph. Note that this ‘transformation-rule’
can even be applied for m = 0 or n = 0. With this rule, we can transform

QRSPPQRSQRSPQPRS12mn1212mn1211.4 Border cases: LoI touching or crossing on a Cut

121

each degenerated EG into a non-degenerated EG. Roughly speaking, if we
have a degenerated EG with a ’critical’ heavy point on a cut, we can move
this point (and the attached LoIs) a little bit outwards.

In the next chapter, a formalization of Peirce’s EGs is given. The idea of this
formalization is obtained from the discussion of Peirce’s EGs in this chapter
and has already been introduced in an informal manner: Peirce’s EGs will be
formalized as mathematical graphs with vertices, (labeled) edges and cuts. It
has already been said that in this formalization, although we have in Peirce’s
graphs identity spots which are placed on cuts, it is reasonable to provide a
formalization where vertices cannot be placed vertices on cuts. Moreover, it
will turn out that the formalization is in fact ‘only’ a formalization of nondegenerated EGs. Peirce discussed and sometimes used degenerated EGs, but
our discussion shows that these graphs can be replaced by equivalent nondegenerated EGs, that is, degenerated EGs can be dismissed. Thus the ongoing
formalization grasps the whole realm of Peirce’s EGs.

12

Syntax for Existential Graphs

In this chapter, the syntax for our formalization of existential graphs is provided. We have already discussed that an existential graph may have diﬀerent
representations, depending on our choice of identity spots a LoI is composed
oﬀ (see the discussion in Sect. 11.1). For this reason, the deﬁnition of formal
existential graphs is done in two steps: First, formal existential graph instances
are deﬁned. An existential graph instance (EGI) is one possible formalization
of an EG where we have for each LoI chosen a number of identity spots. Depending of this choice, an EG has diﬀerent EGI which can be understood as
formalization of this EG. The class of all these EGIs will be the formalization
of the EG.
The underlying structure of EGIs are so-called called relational graphs.
An EGI is a relational graph whose edges are additionally labeled with predicate names. In the part ‘Extending the System’, the expressivity of EGIs is
extended by adding object names or query markers (which can compared to
free variables in FO), and these extensions are obtained from EGIs by extending the labeling function. For this reason, we ﬁrst deﬁne in Sect. 12.1
relational graphs and investigate their structure. In Sect. 12.2, the labeling of
the edges with relation names is added to these graphs: The resulting graphs
are EGIs. Then, in Sect. 12.3, some further syntactical notations for EGIs like
subgraph etc. are introduced. Finally, in Sect. 12.4, we deﬁne formal existential
graphs as sets of EGIs which can be mutually transformed into each other by
a set of very simple rules.

12.1 Relational Graphs with Cuts

As we have already discussed in the last chapter, the underlying structures for
our formalization of EGs will be mathematical graphs with directed hyperedges and cuts. Based on the conventions of graph theory, these structures

124

12 Syntax for Existential Graphs

should be called directed multi-hypergraphs with cuts, but as this is
a rather complicated technical term, we will call them relational graphs
with cuts or, even more simply, relational graphs instead.

In this section, the basic deﬁnitions and properties for relational graphs with
cuts are presented.

Deﬁnition 12.1 (Relational Graphs with Cuts).
graph with cuts is a structure (V, E, ν, >, Cut, area), where

A relational

• V , E and Cut are pairwise disjoint, ﬁnite sets whose elements are called

vertices edges and cuts, respectively,

• ν : E → S
• > is a single element with > /∈ V ∪ E ∪ Cut, called the sheet of asser-

V k is a mapping,1

k∈N0

tion, and

• area : Cut ∪ {>} → P(V ∪ E ∪ Cut) is a mapping such that

a) c1 6= c2 ⇒ area(c1) ∩ area(c2) = ∅ ,
b) V ∪ E ∪ Cut = S
d∈Cut∪{>} area(d),
c) c /∈ arean(c) for each c ∈ Cut ∪ {>} and n ∈ N (with area0(c) := {c}

and arean+1(c) := S{area(d) | d ∈ arean(c)}).

(cid:12)i := vi.
(cid:12)i, and e = (v1, . . . , vk) instead of

For an edge e ∈ E with ν(e) = (v1, . . . , vk) we set |e| := k and ν(e)(cid:12)
(cid:12)i instead of ν(e)(cid:12)
Sometimes, we will write e(cid:12)
ν(e) = (v1, . . . , vk). We set E(k) := {e ∈ E | |e| = k}.
For v ∈ V let Ev := {e ∈ E | ∃ i.ν(e)(cid:12)
Ve := {v ∈ V | ∃ i.ν(e)(cid:12)
moreover ve := v.
The elements of Cut ∪ {>} are called contexts.

(cid:12)i = v}. Analogously, for e ∈ E let
(cid:12)i = v}. For an edge e with ν(e) = {(v)}, we write

As for every x ∈ V ∪ E ∪ Cut we have exactly one context c ∈ Cut ∪ {>} with
x ∈ area(c), we can write c = area−1(x) for every x ∈ area(c), or even more
simple and suggestive: c = ctx(x).

In particular the empty graph, i.e. the empty sheet of assertion, exists. Its
form is G∅ := (∅, ∅, ∅, >, ∅, ∅).
We have to extend some notations we have already introduced for formal
alpha graphs, like the order ≤ on the elements of the graphs, subgraphs,
isomorphisms etc., to relational graphs as well. We start with the order ≤,
which is a canonical extension of the corresponding deﬁnition for formal alpha
graphs (see Def. 7.3).

1 The union S

k∈N0

V k is often denoted by V ∗. We do not adopt this notation, as

V ∗ will be used in this treatise to denote the set of all generic vertices.

12.1 Relational Graphs with Cuts

125

Deﬁnition 12.2 (Ordering on the Contexts, Enclosing Relation). Let
G := (V, E, ν, >, Cut, area) be a relational graph with cuts. We deﬁne a mapping β : V ∪ E ∪ Cut ∪ {>} → Cut ∪ {>} by

β(x) :=

(cid:26)

x for x ∈ Cut ∪ {>}

,

ctx(x) for x ∈ V ∪ E
and set x ≤ y :⇐⇒ ∃n ∈ N0.β(x) ∈ arean(β(y)) for x, y ∈ V ∪E ∪Cut∪{>}.

We deﬁne x < y :⇐⇒ x ≤ y ∧ y 6≤ x and x (cid:12) y :⇐⇒ x ≤ y ∧ y 6= x. . For a
context c ∈ Cut ∪ {>}, we set furthermore

≤[c] := {x ∈ V ∪ E ∪ Cut ∪ {>} | x ≤ c} and
(cid:12)[c] := {x ∈ V ∪ E ∪ Cut ∪ {>} | x (cid:12) c} .

Every element x of S
n∈N arean(c) is said to be enclosed by c, and vice
versa: c is said to enclose x. For every element of area(c), we say more
speciﬁcally that it is directly enclosed by c.

Analogously to Alpha, we have that x is enclosed by a cut c if and only if
x (cid:12) c (see Lem. 7.4), and we obtain the following corollary:

Corollary 12.3 (≤ Induces a Tree on the Contexts). For a relational
graph with cuts G := (V, E, ν, >, Cut, area), ≤ is a quasiorder. Furthermore,
≤ (cid:12)
(cid:12)Cut∪{>} is an order on Cut∪{>} which is a tree with the sheet of assertion
> as greatest element.

The ordered set of contexts (Cut ∪ {>}, ≤) can be considered to be the ‘skeleton’ of a relational graph. According to Def. 12.1, each element of the set
V ∪ E ∪ Cut ∪ {>} is placed in exactly one context c (i.e. x ∈ area(c)). This
motivates the next deﬁnition.

The next deﬁnition corresponds to Def. 7.12 for formal alpha graphs.

Deﬁnition 12.4 (Evenly/Oddly Enclosed, Pos./Neg. Contexts). Let
G = (V, E, ν, >, Cut, area) be a relational graph with cuts. Let x be an element
of V ∪ E ∪ Cut ∪ {>} and set n := |{c ∈ Cut | x ∈ ≤[c]}|. If n is even, x is
said to be evenly enclosed, otherwise x is said to be oddly enclosed.
The sheet of assertion > and each oddly enclosed cut is called a positive
context, and each an evenly enclosed cut is called negative context.

It will turn out in the deﬁnition of the semantics that graphs in which vertices
exist which deeper nested than some edge they are incident with cannot be
evaluated (see the short discussion after Def. 13.4). This is captured by the
following deﬁnition.

Deﬁnition 12.5 (Dominating Nodes). If ctx(e) ≤ ctx(v) (⇔ e ≤ v) for
every e ∈ E and v ∈ Ve, then G is said to have dominating nodes.

126

12 Syntax for Existential Graphs

12.2 Existential Graph Instances

Existential graph instances (EGIs) are obtained from relational graphs by
additionally labeling the edges with names for relations. To start, we have to
deﬁne the set of these names, i.e. we deﬁne the underlying alphabet for EGIs.
Of course, as lines of identity are essential in EGs, this alphabet must contain
a symbol for identity. Then, using this alphabet, we can deﬁne EGIs on the
basis of relational graphs. This is done with the following two deﬁnitions.

Deﬁnition 12.6 (Alphabet). A pair A := (R, ar : R → N0) is called an
alphabet. The elements of R are called relation names, the function ar
assigns to each R ∈ R its arity ar(R). Let .= ∈ R with ar( .=) = 2 be a special
name which is called identity.2

We will often more easily say that R is the alphabet, without mentioning the
arity-function.

Deﬁnition 12.7 (Existential Graph Instance).
Let A be an alphabet. An existential graph instance (EGI) over A is a structure G :=
(V, E, ν, >, Cut, area, κ), where

• (V, E, ν, >, Cut, area) is a relational graph with cuts and dominating nodes,

and

• κ : E → R is a mapping such that |e| = ar(κ(e)) for each e ∈ E.

The set E of edges is partitioned into Eid := {e ∈ E | κ(e) = .= } and
Enonid := {e ∈ E | κ(e) 6= .= }. The elements of Eid are called identityedges. Moreover, If e is an identity-edge with ctx(e) = ctx(e(cid:12)
(cid:12)1) or ctx(e) =
ctx(e(cid:12)
(cid:12)2), then e is called strict identity-edge. The vertices, edges and cuts
of an EGI will be called the elements of the EGI. The system of all EGIs
over A will be denoted by EGI A.

In the part ‘Extending the System’, the last deﬁnitions will be extended.

In the following, we will introduce mathematical deﬁnitions for the terms
ligature and hook, which have no counterparts in Alpha. A ligature will be,
roughly speaking, a set of vertices and identity edges between these vertices,
i.e., a mathematical graph. For this reason, we ﬁrst have to recall some basic
notations of mathematical graph theory, as they will be used in this treatise.
An directed multigraph is a structure (V, E, ν) of vertices v ∈ V and
edges e ∈ E. The mapping ν assigns to each edge e the pair (v1, v2) of its incident vertices. Given an EGI (V, E, ν, >, Cut, area, κ), our aim is to describe

2 We will usually use the common symbol ‘=’ instead of ‘ .=’, but as we use the
symbol ‘=’ in the meta-language, too, sometimes it will be better to use the
symbol ‘ .=’ in order to distinguish it from the meta-level ‘=‘.

12.2 Existential Graph Instances

127

ligatures as subgraphs of (V, Eid, ν(cid:12)
(cid:12)Eid), that is why we start with directed
multigraphs. Nonetheless, the orientation of an identity edge has no signiﬁcance (recall that we have a transformation rule which allows to change the
orientation of identity edges), thus the remaining deﬁnitions are technically
deﬁned for directed multigraphs, but they treat edges as if they had no direction. In order to ease the notational handling of identity-edges in ligatures, we
introduce the following conventions: If e is an identity-edge which connects
the vertices v1 and v2, i.e. we have e = (v1, v2) or e = (v2, v1), we will write
e = {v1, v2} to indicate that the orientation of the edge does not matter, or we
will even use use an inﬁx notation for identity-edges, i.e. we will write v1 e v2
instead of e = {v1, v2}.
A subgraph of (V, E, ν) is a directed multigraph (V 0, E0, ν0) which satisﬁes V 0 ⊆ V , E0 ⊆ E and ν0 = ν(cid:12)
(cid:12)E0 . A path in (V, E, ν) is a subgraph
(V 0, E0, ν0) with V = {v1, . . . , vn}, E = {e1, . . . , en−1} such that we have
v1 e1 v2 e2 v3 . . . vn−1 en−1 vn, and we will say that the path connects v1
and vn. If we have moreover n > 1, v1 = vn and all vertices v2, . . . , vn−1 are
distinct from each other and v1, vn , then the path is called a cycle (some
authors assume n > 2 instead of n > 1, but for our purpose, n > 1 is the
better choice). We say that (V, E, ν) is connected if for each two vertices
v1, v2 ∈ V there exists a path in (V, E, ν) which connects v1 and v2. A loop
is a subgraph ({v}, {e}, {(e, (v, v))}, i.e., basically an edge joining a vertex to
itself. A forest is a graph which neither contains cycles, nor loops. A tree
is a connected forest. It is well known that a connected graph (V, E, ν) is a
tree iﬀ we have |V | = |E| + 1. A leaf of a tree (V, E, ν) is a vertex which is
incident with exactly one edge.

As already said, for a given EGI (V, E, ν, >, Cut, area, κ), our aim it to introduce ligatures as subgraphs of (V, Eid, ν(cid:12)
(cid:12)Eid). Strictly speaking, an edge
is given by an element e ∈ E together with ν(e), which assigns to e its incident vertices, thus we should incorporate the mapping ν into this deﬁnition.
To ease the notation, we will omit the mapping ν, but we agree that ν is
implicitly given. That is, if we speak about a subgraph (W, F ) of (V, Eid), it
is meant that we mean the subgraph (W, F, ν(cid:12)
(cid:12)Eid). Now it is
easy to deﬁne ligatures as follows:

(cid:12)F ) of (V, Eid, ν(cid:12)

Deﬁnition 12.8 (Ligature). Let G := (V, E, ν, >, Cut, area, κ) be an EGI.
Then we set Lig(G) := (V, Eid), and Lig(G) is called the ligature-graph
induced by G. Each connected subgraph of (W, F ) of Lig(G) is called a
ligature of G.

Note that the ligatures in an EGI which are loops or cycles correspond to
the closed, heavily drawn lines in the corresponding Peirce graph. Moreover,
please note that for each vertex v ∈ V , ({v}, ∅) is a ligature. That is, single
vertices can be considered ligatures as well.

128

12 Syntax for Existential Graphs

Next, we provide a formal deﬁnitions for Peirce’s hooks, and the basic operation of replacing a vertex on a hook.

Let G := (V, E, ν, >, Cut, area, κ) be an EGI.
Deﬁnition 12.9 (Hook).
Each pair (e, i) with e ∈ E and 1 ≤ i ≤ |e| is called a hook of e, or hook
for short. If v is a vertex with e(cid:12)
(cid:12)i = v, then we say that the vertex v is
attached to the hook (e, i).
A vertex v with is attached to more than two hooks is called a branching
point. The number of hooks v is attached to is called its number of branches.

Let G := (V, E, ν, >, Cut, area, κ) is an EGI, v be a vertex, e = (v1, . . . , vn) an
edge and 1 ≤ i ≤ |e| with vi = v, and let v0 be a vertex with ctx(v0) ≥ ctx(e).
Let G0 := (V, E, ν0, >, Cut, area, κ) be obtained from G, where ν0 is deﬁned as
follows:

ν0(f ) = ν(f ) for all f 6= e

, and

ν0(e) = (v1, . . . , vi−1, v0, vi+1, vn)

Then we say that G0 is obtained from G by replacing v by v0 on the hook
(e, i).

In order to work with EGIs, their mathematical representations are too clumsy
and too diﬃcult to handle. Hence one may prefer graphical representations
OF EGIs. It has to be explained how EGIs are drawn. This shall be done now.

The diﬀerent elements of an EGI are represented by diﬀerent kinds of graphical items, namely vertex-spots, edge-lines, cut-lines, signs which represent the
relation-names, and numbers (these terms will be introduced below). First of
all, we agree that no graphical items may intersect, overlap, or touch, as long
as it is explicitely allowed. Moreover, we agree that no further graphical items
will be used.

We start with the representation of the cuts. Similar to alpha, each cut is
represented by a closed, doublepoint-free and smooth curve which is called
the cut-line of the cut. A cut-line separates the plane into two distinct
regions: The inner and the outer region. Recall that we said that another item
of the diagram is enclosed by this cut-line if and only if it is placed in the inner
region of this cut-line. If c1, c2 are two cuts with c1 < c2, then the cut-line
of c1 has to be enclosed by the cut-line of c2. Due to our ﬁrst convention,
cut-lines may not intersect, overlap, or touch. Note that it is possible to draw
all cut-lines in the required manner because we have proven that the set of
contexts of an EGI form a tree (see Lemma 12.3). If c is a cut, then the part
of the plane which is enclosed by the cut-line of c, but which is not enclosed
by any cut-line of a cut d < c is called the area-space of c (the cut-line of
c does not belong to the area-space of c). The part of the plane which is not
enclosed by any cut-line is called the area-space of >.
Each vertex v is drawn as a bold spot, i.e. •, which is called vertex-spot of
v. This spot has to be placed on the area-space of ctx(v). Of course diﬀerent
vertices must have diﬀerent vertex-spots.

12.2 Existential Graph Instances

129

Now let e = (v1, . . . , vn) be an edge. We write the sign which represents κ(e)
on the area-space of ctx(e). Then, for each i = 1, . . . , n, we draw a non-closed
and doublepoint-free line, called the ith edge-line of e or the edge-line
between vi and the hook (e, i), which starts at the vertex-spot of vi and
ends close the to sign which represents κ(e). Moreover, this line is labeled,
nearby the sign which which represents κ(e), with the number i. Edge-lines
are allowed to intersect cut-lines, but an edge-line and a cut-line must not
intersect more than once. This requirement implies that the edge-line of e
intersects the cut-line of each cut c with vi > c ≥ ctx(e(cid:12)
(cid:12)2), and no further
cut-lines are intersected.

If it cannot be misunderstood, the labels of the edge-line(s) of an edge e are
often omitted.

For identity-edges, we have a further, separate convention: If e = (v1, v2) is
an identity-edge, it is furthermore allowed to replace the symbol ’ .=’ by an
simple line which connects the ends of the ﬁrst and second edge-line of e which
were former attached to the symbol ‘ .=’ (this connection has to be placed in
the area where otherwise the symbol ’ .=’ were). In this case, the labels of
the edge-lines are omitted. This convention will become clear in the examples
below.

There may be graphs such that its edge-lines cannot be drawn without their
crossing one another (i.e., they are not planar). For this reason, the intersection of edge-lines is allowed. But the intersection of edge-lines should be
avoided, if it possible.

To illustrate these agreements, I provide some examples. The ﬁrst three examples are adopted from Peirce’s Cambridge Lectures, Lecture three.

We start with a simple EGI without cuts, where only one vertex is incident
with two (unary) edges.

G1 := ({v}, {e1, e2}, {(e1, (v)), (e2, (v))}, >, ∅, {(>, {v, e1, e2})},

{(e1, is a good girl), (e2, obeys mamma)})

Below you ﬁnd two representations for this EGI. In the second one, the labels
for the edges are omitted. As both edges are incident with one vertex, this
causes no problems.

The next example is again a EGI without cuts and only one vertex. Here this
vertex is incident twice with an edge.

obeys mammais a good girl11is a good girlobeys mamma130

12 Syntax for Existential Graphs

G2 := ({v}, {e1, e2}, {(e1, (v)), (e2, (v, v))}, >, ∅, {(>, {v, e1, e2})},

{(e1, is a good girl), (e2, obeys the mamma of)})

This EGI can be represented as follows:

Fig. 12.1. One representation for G2

We allow edge-lines to cross each other. For example, consider the following
representation of an EGI:

It is well known from graph-theory that not every graph has a planar representation. For this graph, a planar representation would be possible, but the
given representation with crossing edge-lines shows nicely the symmetry of
the EGI. Crossing edge-lines cause no troubles in the reading of the diagram,
and as they are sometimes inevitable, they are allowed in the diagrammatic
representations of EGIs.

The next example is a more complex EGI with cuts.

G3 := ({v1, v2, v3}, {e1, e2}, {(e1, (v1, v2)), (e2, (v1, v3))}, >, {c1, c2, c3, c4},

{(>, {c1}), (c1, {v1, c2, c3}), (c2, {v2, e1}), (c3, {v3, c4}), (c4, {e2})},
{(e1, obeys), (e2, loves)})

Below, the left diagram is a possible representation of G3. In the right diagram
on the right, I have sketched furthermore assignments of the elements (the
vertices, edges, and cuts) of the EGI to the graphical elements of the diagram.
Finally, on the right, the order ≤ for G3 is depicted.

>

c1, v1
@@(cid:0)(cid:0)
c2, v2, e1 c3, v3

c4, e2

is a good girlobeys the mamma of112is father ofis father ofis mother ofis mother of112AdamKainEvaAbel11222obeys1loves122c4c3c21cv1v2v3e2e1obeys1loves12212.2 Existential Graph Instances

131

The next example shall explain the two diﬀerent conventions for identity
edges. We had already the ﬁrst examples in the last chapter on page 110.
Consider the following EGI:

G4 := ({v1, v2}, {e}, {(e, (v1, v2))}, >, {c}, {(>, {v1, v2}), (c, {e})}, {(e, .=)})

It is a formalization of the well-known graph claiming there exists at least
two things. Due to our normal convention for drawing edges, it is graphically
represented as follows:

The second convention says that the sign ’ .=’ may be replaced by a simple
line. For our example, we obtain:

Now the whole identity-edge is represented by a simple line.

First of all, in this this representation, we loose the information about the orientation of the edge, so this convention can only be used when the orientation
of the edge is of no signiﬁcance. But this will be often the case.
More importantly, as the sign ’ .=’ we had replaced was placed inside the cutline, it is important that the new, simple line goes through the inner area of
the cut-line as well. The following diagram, in which we have a simple line
connecting the vertex-spots as well, is therefore not a representation of G4:

If we follow the convention in this strict sense, even if an identity-edge is
drawn as a simple line, it is still possible to read from the diagram in which
cut the identity-edge is placed. For example,

can only be obtained from

, and

can only be obtained from

.

None of the identity-edges can be placed in a diﬀerent cut, because we consider
only graphs with dominating nodes.
This holds even for identity-edges e with e(cid:12)
to be closed. For example, consider

(cid:12)2. Their edge-lines appear

(cid:12)1 = e(cid:12)

12132

12 Syntax for Existential Graphs

G5 := ({v}, {e}, {(e, (v, v))}, >, {c}, {(>, {v}), (c, {e})}, {(e, .=))})

Due to the conventions, this graph may be represented as follows:

Although the edge-line cannot be mistaken with the cut-line, the right diagram
lacks readability, thus one should prefer the left diagram instead.

From the examples it should be clear that each EGI can be represented as
a diagram. Similar to Alpha, it shall shortly be investigated which kind of
diagrams occur as diagrams of an EGI. We have seen that a diagram is made
up of vertex-spots, edge-lines, cut-lines, signs which represent the relationnames, and numbers. Again, these signs may not intersect, touch, or overlap,
with the exception that we allow two edge-lines to cross, and we allow edgelines to cross cut-lines, but not more than once. A diagram of an EGI in which
identity edges are drawn to the usual convention of edges satisﬁes:

1. If the sign of a relation-name of an n-ary relation occurs in the diagram,
then there are n edge-lines, numbered with the numbers 1, . . . , n, which
are attached to the relation-sign, and each of these edge-lines end in a
vertex spot. It is allowed that diﬀerent edge-lines end the same vertex.
Only such edge-lines which go from a vertex to a relation-sign may occur.

2. If a vertex-spot is given which is connected to a relation-sign with an
edge-line, and if the vertex is enclosed by a cut-line, then the relation-sign
is enclosed by this cut-line, too.

The second condition is a restriction for the diagrams which reﬂects that EGIs
are relation-graphs with domination nodes. For example, the left diagram is
a diagram of an EGI, while the right graph is not:

We already used the condition of dominating nodes to provide the second
convention for drawing identity edges. So, even if identity edges are drawn
due the second condition, from each properly drawn diagram (that is, it has
to satisfy the above given conditions) we can reconstruct up to isomorphism
(which will we be deﬁned canonically in Def. 12.11) and the orientation of
those identity-edges which are drawn as simple lines) the underlying EGI.
Thus, from now on, we can use the diagrammatic representation of EGIs in
mathematical proofs.

Next, the correspondence between the diagrams of Peirce’s Beta graphs and
the diagrams of EGIs shall be investigated.

12child of12PersonPersonPersonPerson1child of212.3 Further Notations for Existential Graph Instances

133

If a diagram of an EGI is given, we can transform it as
follows: We draw all edge-lines bold, such that all vertexspots at the end of an edge-line cannot be distinguished
from this edge-line. For example, for G3 we get the right
diagram of an Peircean EG (the labels of the edges are
omitted, and this diagram is exactly one of the diagrams
of Peirce’s Cambridge Lectures):
It is easy to see that the diagrams we obtain this way are precisely the diagrams of non-degenerated existential graphs (including Peirce graphs with
isolated identity-spots).

The only problem in the transformation of diagrams of EGIs into Peirce diagrams which can occur are crossing edge-lines. If we draw these edge-lines
bold, then it would seem that we had intersecting lines of identity. Peirce has
realized that there may be EGs which cannot be drawn on a plane without the
intersection of LoIs.3 For this reason, he introduced a graphical device called
‘bridge’, which has to be drawn in this case (see 4.561). For our example with
intersecting edge-lines above, we draw

12.3 Further Notations for Existential Graph Instances

Similar to Alpha, we have to deﬁne subgraphs of EGIs. The basic idea is the
same like in Alpha, but he notation of subgraphs in Alpha has to be extended
to Beta in order to capture the extended syntax of Beta, particularly edges
which do not occur in formal alpha graphs. First of all, if a subgraph contains an edge, then it has to contain all vertices which are incident with the
edge, too. Moreover, we distinguish between subgraphs and closed subgraphs:
If a subgraph is given such that for each vertex of this subgraph, all incident
edges belong to the subgraph, too, then the subgraph is called a closed subgraph. The notation of a subgraph will become precise through the following
deﬁnition.4

3 This is a general problem of mathematical graphs which is extensively investigated

in graph theory.

4 In this deﬁnition, subgraphs are ﬁrst deﬁned for relational graph with cuts, then
for EGIs. The reason is that we will slightly extend the syntax for EGIs in Def. 24.1
by adding a second labeling function. Strictly speaking, the following deﬁnition

lovesobeysis father ofis father ofis mother ofis mother ofAdamKainEvaAbel134

12 Syntax for Existential Graphs

Deﬁnition 12.10 (Subgraphs). Let G := (V, E, ν, >, Cut, area) be a relational graph with cuts. A graph G0 := (V 0, E0, ν0, >0, Cut0, area0) is a subgraph of G in the context >0 iﬀ

• V 0 ⊆ V , E0 ⊆ E, Cut0 ⊆ Cut and >0 ∈ Cut ∪ {>} ,
• ν0 = ν(cid:12)
• area0(>0) = area(>0) ∩ (V 0 ∪ E0 ∪ Cut0) and area0(c0) = area(c0) for each

(cid:12)E0 (particularly, the restriction ν0 of ν to E0 is well deﬁned),

c0 ∈ Cut0 ,

• ctx(x) ∈ Cut0 ∪ {>0} for each x ∈ V 0 ∪ E0 ∪ Cut0 , and
• Ve0 ⊆ V 0 for each edge e0 ∈ E0 .

If we additionally have Ev0 ⊆ E0 for each vertex v0 ∈ V 0, then G0 is called
closed subgraph of G in the context >0 .
Now let G := (V, E, ν, >, Cut, area, κ) be an EGI. We call a graph G0 :=
(V 0, E0, ν0, >0, Cut0, area0, κ0) a subgraph of G in the context >0, iﬀ
(V 0, E0, ν0, >0, Cut0, area0) is a subgraph of (V, E, ν, >, Cut, area) in the context >0 which respects the labeling, i.e. if κ0 = κ(cid:12)
In both cases (relational graph with cuts and EGIs), we write G0 ⊆ G and
area−1(G0) = >0 resp. ctx(G0) = >0.

(cid:12)E0 holds.

Similar to Alpha (see Lem. 7.10), we get (cid:12)[c0] ⊆ E0 ∪ V 0 ∪ Cut0 for each c0 ∈
Cut0. In particular, Cut0 is an ideal in Cut ∪ {>}, but in general, Cut0 ∪ {>0}
is not an ideal in Cut ∪ {>} (there may be contexts d ∈ area(>0) which are
not a element of Cut0 ∪ {>0}).

A subgraph is, similar to elements of E ∪ V ∪ Cut ∪ {>}, placed in a context
(namely >0). Thus, we will say that the subgraph is directly enclosed by
>0, and it is enclosed by a context c if and only iﬀ >0 ≤ c. Moreover, we
can apply Def. 12.4 to subgraphs as well. Hence we we distinguish whether a
subgraph is evenly or oddly enclosed.

To get an impression of subgraphs of EGI, an example will be helpful. Consider
the following graph:

of subgraphs cannot be applied to these graphs, but if we deﬁne subgraphs ﬁrst
for relational graph with cuts, it should be clear how this deﬁnition should be
modiﬁed for the extended EGIs of Def. 24.1.

PRQQ12.3 Further Notations for Existential Graph Instances

135

In the following diagrams, we consider some substructures of this graph. All
items which do not belong to the substructure are lightened.

In the ﬁrst example, the marked substructure contains a cut d, but it does not
contain all what is written inside d. In the second example, the vertex which
is linked to the relation P is not enclosed by any context of the substructure.
In the last example, the substructure contains two edges, where a incident
vertex does not belong to the substructure. Hence, in none of the examples
above the marked substructure is a subgraph.

These marked substructures are subgraphs in the outermost cut. The ﬁrst
two subgraphs are not closed: In the ﬁrst example, we have two vertices with
incident edges Q and P which do not belong to the subgraph, and in the
second example, the identity edge which is incident with these vertices does
not belong to the subgraph. The third subgraph is closed.

In Chpt. 21, it is investigated how subgraphs can be diagrammatically depicted.

Analogously to Alpha, isomorphisms between EGIs are canonically deﬁned.
Similar (and for the same reasons) as in the deﬁnition of subgraphs, we ﬁrst
deﬁne isomorphisms for relational graph with cuts, then this deﬁnition is
extended for EGIs.

Deﬁnition 12.11 (Isomorphism). Let Gi := (Vi, Ei, νi, >i, Cuti, areai),
i = 1, 2, be relational graphs with cuts.
.
∪ fCut is called isomorphism, if

Then f = fV

.
∪ fE

• fV : V1 → V2 is bijective,
• fE : E1 → E2 is bijective,
• fCut : Cut1 ∪ {>1} → Cut2 ∪ {>2} is bijective with fCut(>1) = >2 ,

such that the following conditions hold:

RQQPQRQPQRQPRQQPPRQQPRQQ136

12 Syntax for Existential Graphs

• Each e = (v1, . . . , vn) ∈ E1 satisﬁes fE(v1, . . . , vn) = (fV (v1), . . . , fV (vn))

(edge condition)), and

• f [area1(c)] = area2(f (c)) for each c ∈ Cut1 ∪ {>1} (cut condition))

(with f [area1(c)] = {f (k) | k ∈ area1(c)}).

Now let Gi
:= (Vi, Ei, νi, >i, Cuti, areai, κi), i = 1, 2 be two EGIs. Then
.
.
∪ fCut is called isomorphism, iﬀ f is an isomorphism for the
∪ fE
f = fV
underlying relational graphs with cuts G := (Vi, Ei, νi, >i, Cuti, areai) which
respects the labeling, i.e. if κ1(e) = κ2(fE(e)) for all e ∈ E1 holds.

Furthermore, again a notation of a partial isomorphism is needed.

Deﬁnition 12.12 (Partial Isomorphism). For i = 1, 2, let a relational
graph with cut Gi := (Vi, Ei, νi, >i, Cuti, areai) and a context ci ∈ Cuti ∪{>i}
be given. For i = 1, 2, we set

1. V 0
2. E0

i := {v ∈ Vi | v 6≤ ci}, and
i := {e ∈ Ei | e 6≤ ci},

3. Cuti

0 := {d ∈ Cuti ∪ {>i} | d 6< ci}

i

i , E0

0 := areai

i). If f = fV 0

, >i, Cut0
1 and G0

(cid:12)
Let G0
i be the restriction of Gi to these sets, i.e., for areai
0 ,
(cid:12)Cuti
.
.
i, ν(cid:12)
let G0
i, area0
i := (V 0
is an iso-
∪ fCut0
∪ fE0
(cid:12)E0
2 with fCut(c1) = c2, then f is called (partial)
morphism between G0
isomorphism from G1 to G2 except for the contexts c1 ∈ Cut1∪{>1}
and c2 ∈ Cut2 ∪ {>2}.
Analogously to the last deﬁnition, partial isomorphisms between EGIs are partial isomorphisms between the underlying relational graph with cuts which respect κ.

1

1

1

To this deﬁnition, the same remarks as for its counterpart in Alpha apply (see
the remarks after Def. 7.11).

Finally, we have to deﬁne juxtapositions for EGIs.

Deﬁnition 12.13 (Juxtaposition). For an n ∈ N0 and for each i =
:= (Vi, Ei, νi, >i, Cuti, areai) be a relational graph with
1, . . . , n,
cuts. The juxtaposition of the Gi is deﬁned to be the following graph
G := (V, E, ν, >, Cut, area):

let Gi

i=1,...,n Vi × {i} ,
i=1,...,n Ei × {i} ,

• V := S
• E := S
• for e = (v1, . . . , vn) ∈ E, let ν((e, i)) := ((v1, i), . . . , (vn, i)) ,
• > arbitrary element,

12.4 Formal Existential Graphs

137

• Cut := S
• area is deﬁned as follows: area((c, i)) = areai(c) × {i} for c ∈ Cuti, and

i=1,...,n Cuti × {i} ,

area(>) = S

i=1,...,n areai(>i) × {i}.

Analogously to the last deﬁnitions, if Gi := (Vi, Ei, νi, >i, Cuti, areai) is an
EGI for i = 1, . . . , n, the juxtaposition of the Gi is deﬁned to be the
graph G := (V, E, ν, >, Cut, area, κ) where G := (V, E, ν, >, Cut, area) is the
juxtaposition of the graphs (Vi, Ei, νi, >i, Cuti, areai) which respects κ, i.e. we
have κ(e, i) := κi(e) for all e ∈ E and i = 1, . . . , n.
In the graphical notation, the juxtaposition of graphs Gi (relational graphs
with cuts or EGIs) is simply noted by writing the graphs next to each other,
i.e. we write:

G1 G2 . . . Gn

.

Again, similar to Alpha, the juxtaposition of an empty set of EGIs yields the
empty graph, i.e., (∅, ∅, ∅, >, ∅, ∅, ∅).

12.4 Formal Existential Graphs

In Sect. 12.2, I have argued that EGIs can be represented by diagrams, and
that we can reconstruct an EGI from a diagram up to isomorphism. Moreover,
we have discussed how the diagrams of EGIs can be transformed into Peircean
diagrams. Due to our discussion in the last chapter that the number of identity
spots which form a LoI is not ﬁxed, but up to our choice, it has to be expected
that diﬀerent EGIs may yield the same Peirce diagram as well. For example,
the next EGIs yield the same Peircean diagram as G3 from Sect. 12.2:

Neither the diagrams of EGIs, nor the Peircean graphs are deﬁned mathematically, so we cannot prove any correspondence between them. But from

obeys1loves12221obeys12loves122211loves1212obeys12obeys12loves121221loves12obeys1221obeys1loves12221138

12 Syntax for Existential Graphs

the example above, it should be clear that two EGIs yield the same Peirce
graph if they can mutually be transformed into each other by one or more
applications of the following informally given rules:

• isomorphism

An EGI may be substituted by an isomorphic copy of itself.

• changing the orientation of an identity edge

If e = (v1, v2) is an identity edge of an EGI, then its orientation may be
changed, i.e., v1 and v2 are exchanged.

• adding a vertex to a ligature

Let v ∈ V be a vertex which is attached to a hook (e, i). Furthermore let
c be a context with ctx(v) ≥ c ≥ ctx(e). Then the following may be done:
In c, a new vertex v0 and a new identity-edge between v and v0 is inserted.
On (e, i), v is replaced by v0.

• removing a vertex from a ligature

The rule ‘adding a vertex to a ligature’ may be reversed.

The rules ’changing the orientation of an identity edge’, ’adding a vertex to
a ligature’ and ’removing a vertex from a ligature’ will be summarized by
’transforming a ligature’.

In the next deﬁnition, a formal elaboration of these rules is provided. In this
deﬁnition, the term ‘fresh’ is used for vertices, edges or cuts, similar to the
following known use in logic for variables: Given a formula, a ‘fresh’ variable
is a variable which does not occur in the formula. Analogously, given a graph
G := (V, E, ν, >, Cut, area, κ), a vertex, edge or cut x is called fresh if we
have x /∈ V

.
∪ {>}.

.
∪ Cut

.
∪ E

Deﬁnition 12.14 (Transformation Rules for Ligatures). The transformation rules for ligatures for EGIs over the alphabet R are:

• isomorphism

Let G, G0 be EGIs such that there exists an isomorphism from G to G0.
Then we say that G0 is obtained from G by substituting G by the
isomorphic copy G0 of itself.

• changing the orientation of an identity edge

Let G := (V, E, ν, >, Cut, area, κ) be an EGI. Let e ∈ Eid be an identity
edge with ν(e) = (v1, v2). Let G := (E, V, ν0, >, Cut, area, κ) with

ν0(f ) = ν(f ) for f 6= e , and ν0(e) = (v2, v1)

Then we say that G0 is obtained from G by changing the orientation
of the identity edge e.

• adding a vertex to a ligature/removing a vertex from a ligature

12.4 Formal Existential Graphs

139

Let G := (V, E, ν, >, Cut, area, κ) be an EGI. Let v ∈ V be a vertex which
is attached to a hook (e, i). Let v0 be a fresh vertex and e0 be a fresh edge.
Furthermore let c be a context with ctx(v) ≥ c ≥ ctx(e). Now let G0 :=
(V 0, E0, ν0, >0, Cut0, area0, κ0) be the following graph:
– V 0 := V
– E0 := E
– ν0(f ) = ν(f ) for all f ∈ E with f 6= e, ν0(e0) = (v, v0), ν0(e)(cid:12)

.
∪ {v0},
.
∪ {e0},

(cid:12)j := ν(e)(cid:12)
(cid:12)j

for j 6= i, and ν0(e)(cid:12)

(cid:12)i := v0,

– >0 := >
– Cut0 := Cut
– area0(c) := area(c)

.
∪ {v0, e0}, and for d ∈ Cut0 ∪ {>0} with d 6= c we

set area0(d) := area(d), and
.
∪ {(e0, .=)}.

– κ0 := κ
Then we say that G0 is obtained from G by adding a vertex to a
ligature and G is obtained from G0 by removing a vertex from a
ligature.

Let Ga, Gb be EGIs
Deﬁnition 12.15 (Formal Existential Graphs).
over a given alphabet A. We set Ga ∼ Gb, if Gb can be obtained from Ga with
the four rules above (i.e., if there is a ﬁnite sequence (G1, G2, . . . , Gn) with
G1 = Ga and Gb = Gn such that each Gi+1 is derived from Gi by applying
one of the rules ’isomorphism’, ’changing the orientation of an identity edge’,
’adding a vertex to a ligature’ and ’removing a vertex from a ligature’).
Each class [G]∼ is called an (formal) existential graph over A. Formal
existential graphs will usually be denoted by the letter E.

To provide a simple example, a Peircean Beta graph and two elements (that
is: EGIs) of the corresponding formal Beta graph are depicted in Fig. 12.4.

A factorization of formulas due to some speciﬁc transformations is folklore in
mathematical logic. The classes of formulas are sometimes called structures,
but using this term in this treatise may lead to misinterpretations (esp., as
EGIs are already mathematical structures), thus we avoid this term.

There are no ’canonically given’ discrete structures which formalize Peirce’s
Beta graphs, but for our mathematical elaboration of Peirce’s Beta graphs,
discrete structures are of course desirable. Factorizing the class of EGIs by
the transformation rules for ligatures provides a means to formalize Peirce’s
graphs by classes of discrete structures. In the next chapters, nearly all mathematical work will be carried out with EGIs. Nonetheless, the relation ∼ can be
understood in some respect to be an ’congruence relation’, thus, it is – in some
sense – possible to carry over the deﬁnitions for EGIs to deﬁnitions for formal

140

12 Syntax for Existential Graphs

({v1, v2},
{e1, e2, e3},
{(e1, (v1)), (e2, (v1, v2)), (e3, (v2))},

>, {c1, c2},
{(>, {v1, e1, c1},
(c1, {v2, e2, c2}),
(c2, {e3})},

{(e1, Cat), (e2, on), (e3, Mat)})

({v1, v2, v3, v4, v5},
{e1, e2, e3, e4, e5, e6},
{(e1, (v1)), (e2, (v1, v2)),
(e3, (v2, v3)), (e4, (v3, v4))},
(e5, (v4, v5)), (e6, (v5))},
>, {c1, c2},
{(>, {v1, e1, c1},
(c1, {v2, v3, v4, e2, e3, e4, c2}),
(c2, {v5, e5, e6})},
{(e1, Cat), (e2, .=), (e3, on)
(e4, .=), (e5, .=), (e6, Mat)})

Fig. 12.2. A Peirce graph and two corresponding EGIs

EGs. For example, we can say that E0 is the juxtaposition of E1, . . . , En, if
we have EGIs G0, G1, . . . , Gn with Ei = [Gi]∼ for each 0 ≤ i ≤ n, and G0
is the juxtaposition of G1, . . . , Gn. For more complicated deﬁnitions, we will
have to elaborate further that ∼ is a ’congruence relation’. For example, in
the next section, this will be done for the semantical entailment relation, that
is, we will show that equivalent EGIs have the same meaning.

12onCatMatCat12MatononMatCat2113

Semantics for Existential Graphs

The main treatises dealing with Peirce’s Beta graphs provide a semantics for
them either in an informal, naive manner (like [Rob73]) or by providing a
mapping -let us call it Φ– of existential graphs to FO-formulas (e.g. [Bur91a],
[PS00], [Zem64], [Shi02a]). As Φ is a mapping of one syntactically given logical
language into another syntactically given logical language, in my view the use
of the term ‘semantics’ for Φ is not appropriate. Instead of this, a direct
extensional semantics based on the relational structures known from Chpt. 18
is provided.

In the ﬁrst section, it will be shown how EGIs are evaluated in relational
structures. It should be expected that equivalent EGIs have the same meaning
(i.e., their evaluation in arbitrary structures yield always the same result).
This will be shown in the second section.

13.1 Semantics for Existential Graph Instances

EGIs are evaluated in the well-known relational structures as they are known
from ﬁrst order logic. We start this section with a deﬁnition of these structures.

A relational structure
Deﬁnition 13.1 (Relational Structures).
or relational model over an alphabet (R, ar : R → N) is a pair
M := (U, I) consisting of a nonempty universe U and a function I : R →
S
k∈N P(U k) such that I(R) ∈ P(U k) for ar(R) = k, and (u1, u2) ∈ IR( .=) ⇔
u1 = u2 for all u1, u2 ∈ U .

The function I (the letter ‘I’ stands of course for ‘interpretation’) is the link
between our language and the mathematical universe, i.e., it relates syntactical
objects to mathematical entities.

142

13 Semantics for Existential Graphs

When an EGI is evaluated in a relational structure (U, I), we have to assign
objects of our universe of discourse U to its vertices. This is done – analogously
to FO (see Def. 18.5) – by valuations.

Let an EGI G :=
Deﬁnition 13.2 (Partial and Total Valuations).
(V, E, ν, >, Cut, area, κ) be given and let (U, I) be a relational structure over
A. Each mapping ref : V 0 → U with V 0 ⊆ V is called a partial valuation
of G. If V 0 = V , then ref is called (total) valuation of G. Let c ∈
Cut ∪ {>}. If V 0 ⊇ {v ∈ V | v > c} and V 0 ∩ {v ∈ V | v ≤ c} = ∅, then
ref is called partial valuation for c. If V 0 ⊇ {v ∈ V | v ≥ c} and
V 0 ∩ {v ∈ V | v < c} = ∅, then ref is called extended partial valuation
for c.

Now we can deﬁne whether an EGI is valid in a relational structure over A.
This shall be done in two ways. The ﬁrst way is directly adopted from FO
(see Def. 18.5). In FO, we start with total valuations of the variables of the
formula, i.e., an object is assigned to each variable. Whenever an ∃-quantiﬁer
is evaluated during the evaluation of the formula, the object which is assigned
to the quantiﬁed variable is substituted (i.e., the total valuation is successively
changed). As we adopt this classical approach of FO for EGIs, we denote the
semantical entailment relation by ‘|=class’. It is deﬁned as follows:

Let an EGI G :=
Deﬁnition 13.3 (Classical Evaluation of Graphs).
(V, E, ν, >, Cut, area, κ) be given and let (U, I) be a relational structure over
A. Inductively over the tree Cut ∪ {>}, we deﬁne1 (U, I) |=class G[c, ref ] for
each context c ∈ Cut ∪ {>} and every total valuation ref : V → U :

(U, I) |=class G[c, ref ] :⇐⇒

it exists a valuation ref : V → U with ref (v) = ref (v) for all v ∈
V \area(c) such that the following conditions hold:

• ref (e) ∈ I(κ(e)) for each e ∈ E ∩ area(c) (edge condition))
• (U, I) 6|=class G[d, ref ] for each d ∈ Cut ∩ area(c) (cut condition and

iteration over Cut ∪ {>}))

If there is a total valuation ref such that (U, I) |=class G[>, ref ], we write
(U, I) |=class G. If H is a set of EGIs and if G is an EGI such that (U, I) |=class
G for each model (U, I) that satisﬁes (U, I) |=class G0 for each G0 ∈ H, we
write H |=class G.

The second semantics we will provide is the formalization of Peirce’s endoporeutic method to evaluate EGIs. He read and evaluated existential graphs

1 In order to be in line with the notation ‘M |=val f ’ of F O (see Def.18.5), it
would be preferable to use a notation ‘(U, I) |=c,ref G’ for EGIs. But as we have
two diﬀerent entailment relations in EGI, we decided to distinguish them writing
‘|=class’ and ‘|=endo’ (see Def. 13.4). Thus, as the symbol ‘|=’ is already indexed,
we write the evaluated context c and the valuation ref in square brackets instead.

13.1 Semantics for Existential Graph Instances

143

from the outside, hence starting with the sheet of assertion, and proceeded
inwardly. During this evaluation, he assigned successively values to the lines
of identity. The corresponding semantical entailment relation is denoted by
‘|=endo’. But before we give a precise deﬁnition of ‘|=endo’, we exemplify it
with the left graph of Fig. 12.4.

We start the evaluation of the graph on the sheet of assertion >. As > contains
v1, e1, c1, G is true if there is an object o1 which is a cat, and the part of G
which is enclosed by c1 is not true. As c1 contains v2, e2, c2, the part of G
enclosed by c1 is true if there is an object o2 such that o1 is on o2 (that is why
the endoporeutic method proceeds inwardly: We cannot evaluate the inner
cut c1 unless we know which object is assigned to v1. Please note that the
assignment we have build so far is a partial valuation for the cut c1.) and the
graph enclosed by c2 is not true, i.e., o2 is not a mat. So G is true if there is
an object o1 which is a cat, and it is not true that there is an object o2 such
that o1 is on o2 and o2 is not a mat, i.e., there is a cat which is only on mats.

Deﬁnition 13.4 (Endoporeutic Evaluation of Graphs).
Let an EGI
G := (V, E, ν, >, Cut, area, κ) be given and let (U, I) be a relational structure
over A. Inductively over the tree Cut ∪ {>}, we deﬁne (U, I) |=endo G[c, ref ]
for each context c ∈ Cut ∪ {>} and every partial valuation ref : V 0 ⊆ V → U
for c:

(U, I) |=endo G[c, ref ] :⇐⇒

ref can be extended to an partial valuation ref : V 0 ∪ (V ∩ area(c)) → U
(i.e., ref is an extended partial valuation for c with ref (v) = ref (v) for
all v ∈ V 0), such that the following conditions hold:

• ref (e) ∈ I(κ(e)) for each e ∈ E ∩ area(c) (edge condition))
• (U, I) 6|=endo G[d, ref ] for each d ∈ Cut ∩ area(c) (cut condition and

iteration over Cut ∪ {>}))

For (U, I) |=endo G[>, ∅] we write (U, I) |=endo G. If H is a set of EGIs and
if G is an EGI such that (U, I) |=endo G for each model (U, I) that satisﬁes
(U, I) |=endo G0 for each G0 ∈ H, we write H |=endo G.

Please note that the edge-condition for an edge e can only be evaluated when
we have already assigned objects to all vertices being incident with e. This is
assured because we only consider graphs with dominating nodes.

The main diﬀerence of the last deﬁnition to Def. 13.3 is the following: In
Def. 13.3, we start with a total valuation of vertices which is, during the evaluation, successively changed. In the Def. 13.4, we start with the empty partial
valuation which is, during the evaluation, successively completed. Unsurprisingly, these two deﬁnitions yield exactly the same entailment relations, as the
following lemma shows.

144

13 Semantics for Existential Graphs

Lemma 13.5 (Both Evaluations are Equivalent). Let an EGI G :=
(V, E, ν, >, Cut, area, κ) be given and let M := (U, I) be a relational structure
over A. Then we have

M |=class G ⇐⇒ M |=endo G

Proof: We show inductively over Cut ∪ {>} that the following conditions
are satisﬁed for every context c ∈ Cut ∪ {>} and every partial valuation
ref 0 : V 0 ⊆ V → U for the context c:2

(U, I) |=endo G[c, ref 0]

(13.1)
⇐⇒ (U, I) |=class G[c, ref ] for all extensions ref : V → U of ref 0
(13.2)
⇐⇒ (U, I) |=class G[c, ref ] for one extension ref : V → U of ref 0 (13.3)

As G has dominating nodes, we have

Ve ⊆ {v ∈ V | v ≥ c} for each e ∈ E ∩ area(c)

(13.4)

Now the proof is done by induction over Cut ∪ {>}. Let c be a context such
that (13.1) ⇐⇒ (13.2) ⇐⇒ (13.3) for each cut d < c.
We start with the proof of (13.1) =⇒ (13.2), so let ref 0 : V 0 ⊆ V → U be a
partial valuation for c such that (U, I) |=endo G[c, ref ]. Hence there is a partial
valuation ref 0 which extends ref 0 to V 0 ∪ (V ∩ area(c)) and which fulﬁlls the
properties in Def. 13.4. Furthermore, let ref : V → U be an arbitrary total
valuation which extends ref 0 to V . We want to show (U, I) |=class G[c, ref ].
We set

ref := ref (cid:12)

(cid:12)V \area(c) ∪ ref 0(cid:12)

(cid:12)area(c)
(cid:12){v∈V |v>c} = ref 0(cid:12)

As ref is an extension of ref 0, we have ref (cid:12)
(cid:12){v∈V |v>c}, and
by deﬁnition of ref , we have ref (cid:12)
(cid:12)area(c). From this we con-
(cid:12){v∈V |v≥c} = ref 0(cid:12)
clude ref (cid:12)
(cid:12){v∈V |v≥c}. Since all edge conditions hold for ref 0,
(13.4) yields that all edge conditions hold for ref , too. Furthermore we have
(U, I) 6|=endo G[d, ref 0] for each d < c. Since ref is an extension of ref 0, the
induction hypothesis (13.3) =⇒ (13.1) for d yields (U, I) 6|=class G[d, ref 0]. So
the proof for (13.1) =⇒ (13.2) is done.

(cid:12)area(c) = ref 0(cid:12)

The implication (13.2) =⇒ (13.3) holds trivially.

Finally, we show that (13.3) =⇒ (13.1) holds for c. So assume that (13.3)
is true for c, i.e., there is an extension ref : V → U of ref 0 which satisﬁes
(U, I) |=class G[c, ref ]. So there is a valuation ref with ref (v) = ref (v) for
all v ∈ V \area(c) and which fulﬁlls the properties in Def. 13.3. Now deﬁne

2 The ongoing proof of Lem. 13.5 relies on the idea that a valuation does not
determine which values are assigned to the vertices v ∈ V ∩ area(c). For this
reason it is crucial to consider only partial valuations for the context c, i.e., partial
valuations ref 0 which satisfy in particular dom(ref 0) ∩ {v ∈ V | v ≤ c} = ∅.

13.2 Semantics for Existential Graphs

145

ref 0 := ref 0 ∪ ref (cid:12)

(cid:12)area(c)

Again, ref is an extension of ref 0, and ref (cid:12)
(cid:12){v∈V |v≥c}.
Similar arguments as in the proof for (13.1) =⇒ (13.2) yield that all edge
conditions hold for ref 0. Furthermore, if d < c is a cut, the cut-condition
(U, I) 6|=endo G[d, ref 0] holds because of the induction hypothesis (13.1) =⇒
(13.2). So we have that ref 0 fulﬁlls the properties in Def. 13.4, and the proof
2
for the implication (13.3) =⇒ (13.1) is done.

(cid:12){v∈V |v≥c} = ref 0(cid:12)

As Lem. 13.5 shows that Def. 13.3 and and Def. 13.4 yield the same entailment
relation between models and graphs, we will write |= instead of |=endo and
|=class. Nevertheless it will turn out that in some proofs it is more useful to
use Def. 13.3 for |=, and in other proofs it is more useful to use Def. 13.4.

13.2 Semantics for Existential Graphs

In the next section, a calculus for EGIs will be presented. This calculus will
have derivation rules, but recall that we already have four transformation
rules on EGIs, from which the relation ∼ is obtained. In this section, we
will show that these transformation rules are respected by the semantical
entailment relation, i.e., that they are sound (that is, ∼ can be considered to
be a ’congruence-relation’ with respect to the semantics). Unsurprisingly, the
proof-method is the same as the proof of the soundness of the forthcoming
calculus in Chpt. 17.

We start with a simple deﬁnition.

Deﬁnition 13.6 (Partial Isomorphism Applied to Valuations).
Let
EGIs G := (V, E, ν, >, Cut, area, κ), G0 := (V 0, E0, ν0, >0, Cut0, area0, κ0) be
given and let f be an isomorphism between G and G0 except for c ∈ Cut and
c0 ∈ Cut0. Let ref be a partial valuation on G with dom(ref ) ∩ {v ∈ V |
ctx(v) ≤ c} = ∅. Then we deﬁne f (ref ) on {f (v) | v ∈ V ∩ dom(ref )} by
f (ref )(f (v)) := ref (v).

Now we can start with the proof of the soundness. Like in Alpha, we have a
main theorem which is the basis for the soundness of nearly all rules, which
will be presented in two forms.

Theorem 13.7 (Main Lemma for Soundness, Implication Version).
Let EGIs G := (V, E, ν, >, Cut, area, κ), G0 := (V 0, E0, ν0, >0, Cut0, area0, κ0)
be given and let f be an isomorphism between G and G0 except for c ∈ Cut
and c0 ∈ Cut0. Set Cutc := {d ∈ Cut ∪ {>} | d 6< c}. Let M be a relational
model and let P (d) be the following property for contexts d ∈ Cutc:

146

13 Semantics for Existential Graphs

• If d is a positive context and ref is a partial valuation for d which fulﬁlls

M |=endo G[d, ref ], then M |=endo G0[f (d), f (ref )] , and

• if d is a negative context and ref is a partial valuation for d which fulﬁlls

M 6|=endo G[d, ref ], then M 6|=endo G0[f (d), f (ref )] .

If P holds for c, then P holds for each d ∈ Cutc.
Particularly, If P holds for c, we have

M |=endo G =⇒ M |=endo G0

.

Proof: Cutc is a tree such that for each d ∈ Cutc with d 6= c, then all cuts
e ∈ area(d) are elements of Cutc as well. Thus we can carry out the proof by
induction over Cutc. So let d ∈ Cutc, d 6= c (we know that c satisﬁes P ) be a
context such that P (e) holds for all cuts e ∈ area(d) ∩ Cut. Furthermore let
ref be a partial valuation for d. We have two cases to consider:

• First Case: d is positive and M |=endo G[d, ref ].

As we have M |=endo G[d, ref ], we can extend ref to a mapping ref :
dom(ref ) ∪ (V ∩ area(d)) → U such that all edge-conditions in d hold
and such that M 6|=endo G[e, ref ] for all cuts e ∈ area(d) ∩ Cut. Like in
Def. 13.6, f (ref ) can be canonically extended to f (ref ) such that we have
f (ref ) = f (ref ). The isomorphism yields that all edge conditions hold for
f (ref ), and the induction hypothesis yields that M 6|=endo G0[f (e), f (ref )]
for all cuts e ∈ area(d) ∪ Cut. Hence we have M |=endo G0[f (d), f (ref )].

• Second Case: d is negative and M 6|=endo G[d, ref ].

Assume that we have M |=endo G0[f (d), f (ref )], i.e., f (ref ) can be extended to f (ref ) such that all edge conditions hold in f (d) and such that
M 6|=endo G0[e0, f (ref )] for all cuts e0 ∈ area(f (d))∩Cut0. Obviously there
exists an extension ref of ref such that f (ref ) = f (ref ). We conclude
that all edge conditions hold for ref in d. Our assumption yields that we
have M 6|=endo G0[f (e), f (ref )], i.e., M 6|=endo G0[f (e), f (ref )] for all cuts
e ∈ area(d). By induction hypothesis we have M 6|=endo G[e, ref ] for all
cuts e ∈ area(d). So ref is an extension of ref which fulﬁlls all properties
of Def. 13.4, hence we have M |=endo G[d, ref ], a contradiction.

From both cases we conclude that P holds for each d ∈ Cutc. Finally we have

M |=endo Ga

Def. |=
⇐⇒ M |=endo Ga[>a, ∅]
P(>a)
=⇒ M |=endo Gb[>b, ∅]
Def. |=
⇐⇒ M |=endo Gb

which yields the particular property for >.

2

13.2 Semantics for Existential Graphs

147

This will be the main theorem to prove the soundness of those rules of the
(forthcoming) calculus which weaken the ’informational content’ of an EGI
(e.g. erasure and insertion). The transformation rules of Def. 12.14 and some
rules of the calculus (e.g. iteration and deiteration) do not change the informational content and may therefore be performed in both directions. For proving
the soundness of those rules, a second version of this theorem is appropriate
which does not distinguish between positive and negative contexts and which
uses an equivalence instead of two implications for the property P .

Theorem 13.8 (Main Thm. for Soundness, Equivalence Version).
Let EGIs G := (V, E, ν, >, Cut, area, κ), G0 := (V 0, E0, ν0, >0, Cut0, area0, κ0)
be given and let f be an isomorphism between G and G0 except for c ∈ Cut
and c0 ∈ Cut0. Set Cutc := {d ∈ Cut ∪ {>} | d 6< c}. Let M be a relational
model and let P (d) be the following property for contexts d ∈ Cutc:

Every partial valuation ref for d satisﬁes

M |=endo G[d, ref ] ⇐⇒ M |=endo G0[f (d), f (ref )]

If P holds for c, then P holds for each d ∈ Cutc.
Particularly, If P holds for c, we have

M |=endo G ⇐⇒ M |=endo G0

.

Proof: Done analogously to the proof of Lemma 13.7.
In the following, we will show that two EGIs G, G0 with G ∼ G0 have in every model M := (U, I) the same meaning. For the isomorphism-rule, this is
obvious. Next, let G0 is obtained from G0 with the rule ‘changing the orientation of an identity-edge. Due to Defs. 13.1 and 13.4, the relation-name .= is
interpreted by the –symmetric– identity-relation on u. Thus it is trivial that
G holds in M if and only if G0 holds in M. It remains to investigate the rules
’adding a vertex to a ligature’ and ’removing a vertex from a ligature’. This
will be done in the next lemma.

2

Lemma 13.9 (The Transformation Rules for Ligatures are Sound).
If G and G0 are EGIs, M := (U, I) is a relational structure with M |= G and
G0 is obtained from G by applying one of the transformation rules ’ adding a
vertex to a ligature’ and ’removing a vertex from a ligature’, then M |= G0.

Proof: We use the notation of Def. 12.14, i.e., we have a vertex v ∈ V , an
edge e ∈ E be an edge with e(cid:12)
(cid:12)i = w for an i ∈ N, and a context c with
ctx(v) ≥ c ≥ ctx(e) such that in c, a new vertex v0 and a new identity-edge
between v and v0 is inserted, and on e, e(cid:12)
(cid:12)i = v is substituted by e(cid:12)
G and G0 are isomorphic except the cut c, where the isomorphism is the
identity-mapping for {d ∈ Cut ∪ {>} | d 6< c}. Let ref be a partial valuation
for the cut c.

(cid:12)i = v0.

148

13 Semantics for Existential Graphs

First we suppose M |=endo G[c, ref ]. That is, ref can be extended to ref :
V 0 ∪(V ∩area(c)) → U such that the all edge- and cut-conditions in c hold (for
.
∪ {v0, e0}, i.e., we have –compared with
G). In G0, we have area0(c) = area(c)
G– the same edge- and cut-conditions in c plus an additional edge-condition for
.
the new edge e0. Thus, for ref 0 := ref
∪ {(v0, ref (v)}, we easily see that ref 0
is in G0 a partial valuation for the cut c which extends ref and which satisﬁes
all edge- and cut-conditions in c (for G0). So we get M |=endo G0[c, ref ].
Now let us suppose M |=endo G0[c, ref ], i.e., , ref can be extended to ref 0 :
V 0 ∪ (V ∩ area0(c)) → U such that the all edge- and cut-conditions in c hold
(for G0). Now we easily see that ref := ref 0\{v, ref 0(v0)} is in G0 a partial
valuation for the cut c which extends ref and which satisﬁes all edge- and
cut-conditions in c. So we get M |=endo G[c, ref ].
Both cases together yield the property P (c) of Lemma 13.7, so we conclude
2
M |=endo G ⇐⇒ M |=endo G0.
As we now know that all transformation rules respect the relation |=, we
immediately obtain the following theorem:

Theorem 13.10 (∼ Preserves Evaluations). Let G1, G2 be two EGIs
with G1 ∼ G2, and let M be a relational structure. Then we have:

M |= G1 ⇐⇒ M |= G2

.

Now we can carry over the semantics for EGIs to semantics for formal EGs:

Deﬁnition 13.11 (Semantics for Existential Graphs). Let E be an EG,
G be an representing EGI for E (i.e., E = [G]∼) and M be a relational
structure. We set:

M |= E :⇐⇒ M |= G .

The last theorem and deﬁnition can be understood as ’a posteriori’ justiﬁcation for Peirce’s understanding of LoIs as composed of an arbitrary number
of identity spots, as well as for its formalization in form of EGIs and classes
of EGIs.

14

Getting Closer to the Calculus for Beta

In Chpt. 11, we ﬁrst have extensively investigated Peirce’s understanding of
the form and meaning of existential graphs. Afterwards, the mathematical
deﬁnitions for syntax and semantics of formal existential graphs, which can be
seen as a formal reconstruction of Peirce’s view on his graphs, were provided.
The same attempt is now carried out for the calculus. In this chapter, which
corresponds to Sec. 8.2 in the Alpha-part, we will deeply discuss Peirce’s rules
for existential graphs, before the formal deﬁnition for the calculus is provided
in Chpt. 15.

The set of rules for the beta-part is essentially the same as for alpha graphs,
i.e., we have the rules erasure, insertion, iteration, deiteration and double cut.
These rules are now extended to handle LoIs as well. The additionally handling
of LoIs has to discussed in detail, particularly for the rules iteration and
deiteration. Furthermore, it will turn out that a further rule for the insertion
and erasure of single, heavy dots has to be added.

In diﬀerent writings on existential graphs, Peirce provided diﬀerent versions
of his rules, which diﬀer in details. Thus the elaboration of the rules which
will provided in this chapter should be understood as one possible formulation
which tries to cover Peirce’s general understanding of his rules, which can be
ﬁgured out from the diﬀerent places where Peirce provides and discusses them.
Roughly speaking, the following rules will be employed:

1. Rule of Erasure and Insertion

In positive contexts, any subgraph may be erased, and in negative contexts, any subgraph may be inserted.

2. Rule of Iteration and Deiteration

If a subgraph of a graph is given, a copy of this subgraph may be inserted
into the same or a deeper nested context. On the other hand, if we already
have a copy of the subgraph in the same or a deeper nested context, then
this copy may be erased.

150

14 Getting Closer to the Calculus for Beta

3. Double Cut Rule

Two Cuts one within another, with nothing between them, except ligatures which pass entirely through both cuts, may be inserted into or erased
from any context.

4. Rule of Inserting and Deleting a Heavy Dot

A single, heavy dot may be inserted to or erased from any context.

The double cut rule can be understood as a pair of rules: Erasing a double cut
and inserting a double cut. So we see that the rules of Peirce are grouped in
pairs. Moreover, we have two kinds of rules.1 The rules erasure and insertion
(possibly) weaken the informational content of a graph. These rules will be
called generalization rules. All other rules do not change the informational content of a graph. These rules will be called equivalence rules.

Each equivalence rule can be carried out in arbitrary contexts. Moreover, for
each equivalence rule which allows to derive a graph G2 from a graph G1,
we have a counterpart, a corresponding rule which allows to derive G1 from
G2. On the other hand, generalization rules cannot be carried out in arbitrary
contexts. Given a pair of generalization rules, one of the rules may only be
carried out in positive contexts, and the other rule is exactly the opposite
direction of the ﬁrst rule, which may only be carried out negative contexts
This duality principle is essential for Peirce’s rules.2 In the following sections,
we discuss each of the pairs of rules for Peirce’s EGs in detail, before we
elaborate their mathematical implementation for EGIs and formal EGs in the
next chapter. Due to the duality principle, it is suﬃcient to discuss only one
rule of a given pair in detail. For example, in the next section, where the pair
erasure and insertion is considered, only the erasure-rule is discussed, but the
results of the discussion can easily be transferred to the insertion-rule, too.

14.1 Erasure and Insertion

We have already discussed in Sec. 8.2 how subgraphs are erased and inserted
in Alpha. For Beta, we have to discuss how these rules are extended for the
handling of LoIs and ligatures. In 4.503, Peirce provides considers 20 graphs
and explains how LoI are treated with them, and in 4.505, he summarizes:
‘This rule permits any ligature, where evenly enclosed, to be severed, and any
two ligatures, oddly enclosed in the same seps, to be joined.’

The rule of erasure shall here be exempliﬁed with the following graph:

1 This has already be mentioned in Sec.8.2.
2 This principle will be adopted in the part ’Extending the System’, where the

expressiveness of EGIs is extended and new rules are added to the calculus.

14.1 Erasure and Insertion

151

G :=

The following three examples are obtained from G by erasing a part of the
ligature on the sheet of assertion.

Analogously, we can erase parts of the ligature in the innermost cut. For
example, we can derive

Similar to Alpha, whole subgraphs may be erased from positive contexts. This
is how the following two graphs are obtained:

In the ﬁrst graph, we have erased the whole subgraph of G which consists of
the outermost cut and all what it is scribed inside. In the second example,
in the innermost cut has been erased.
the subgraph

In these examples, we have erased a subgraph which was connected to the
remaining graph. In order to do this, we had to cut these connections. This
is explained by Peirce in 4.505, where he explains: ‘In the erasure of a graph
by this rule, all its ligatures must be cut.’ For the ongoing mathematization
of the rules, it is important to note that an erasure of a subgraph which is
connected to the remaining graph can be performed in two steps: First cut
all ligations which connect the subgraph with the remaining graphs (this has
to be done in the positive context where the subgraph is placed) in order to
obtain an isolated subgraph, then erase this isolated subgraph. For example,
the deletion of the subgraph in the ﬁrst example can be performed as follows:

cut
ligature

erase
isolated
subgraph

Analogously, the deletion of the subgraph in the second example can be performed as follows:

SRPQSRQPSRQPSRQPRPQSPQRPQSSRPQSRPQPQ152

14 Getting Closer to the Calculus for Beta

cut two
ligat.

erase
isol.
subg.

It will turn out that this consideration will be helpful for a mathematization
of these rules for EGIs.

14.2 Iteration and Deiteration

We start with a very simple example of an application of the iteration-rule.
Consider the following graph:

The next graph is derived from this left graph by iterating the subgraph P
into the cut.

This is a trivial application of the iteration-rule. But, of course, a crucial point
in the iteration-rule for beta is the handling of ligatures. In fact, the iterated
subgraph may be joined with the existing heavily drawn line. The question is:
how?

In 4.506, Peirce writes that the iteration rule ‘includes the right to draw a
new branch to each ligature of the original replica inwards to the new replica.’
Consider the following two graphs, which have the same meaning:

Fig. 14.1. two diﬀerent existential graphs with the same meaning

As we have in the left graph of Fig. 14.1 a branch from the old replica of P
which goes inwardly to the copy of the iterated subgraph, one might think
that this graph is the result from a correct application of the iteration-rule
to our starting graph, while the right is not. But, then, it must be possible
to show that the two graphs of Fig. 14.1 can be syntactically, i.e., with the
rules of the calculus, transformed into each other. With the just given, ﬁrst
interpretation of the iteration rule, this is probably impossible. In fact, it turns
out that the quotation of Peirce for the handling of LoIs might be misleading,

SRPQRPQSRPQQPPQPPQPPQP14.2 Iteration and Deiteration

153

and the right graph of Fig. 14.1 appears to be the result of an application of
the iteration-rule as well.

In 4.386 Peirce provides an example how the alpha-rule of iteration is amended

to beta. He writes: ‘Thus,
[A ( B)] can be transformed to [A (A B)] .’
Peirce uses in this place a notation with brackets. It is crucial to note that
is connected inside the cut with
the line of identity in the copy of A
the already existing ligature. Thus, using cuts, the example can be depicted
as follows:

‘

A similar example can be found in [PS00], where Peirce uses the rule of deiteration to remove a copy of M
(like in one example we referred to in
Chpt. 11, he uses shadings for representing cuts):

‘

was connected in the
Again it is crucial to note that the copy of M
second innermost cut with the ligature. For Gamma, Peirce provides 1906 in
4.566 another example with the same handling of ligatures when a subgraph
is iterated.

From these examples, I conclude the following understanding of handling ligatures in the iteration-rule:

Handling ligatures in the rule of iteration: Assume that a subgraph S is iterated from a cut (or the sheet of assertion) c into a cut
(or the sheet of assertion) d. Furthermore, assume that S is connected
to a ligature which goes inwardly from c to d. Then the copy of S may
be connected in d with this ligature.

In order to provide a (slightly) more sophisticated example for the handling of
ligatures, consider the following graphs. Each of the four graphs on the right

are resulting from a correct application for iterating the subgraph S of the
leftmost graph into its cut:

BAABA(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)PMMS(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:1)(cid:0)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)(cid:1)(cid:2)PMSQPSPRSQPPRSSQPPRSSQPPRSSQPPRS154

14 Getting Closer to the Calculus for Beta

The phrase ”which goes inwardly from c to d” is crucial for the correct application of the iteration-rule. Consider the following graph:

G :=

The four graphs of Fig. 14.2 are results of a correct application of the iterationrule to G. In fact, one can check that all graphs have the same meaning, which
is the meaning of G.

Fig. 14.2. Five results from a correct application of the iteration-rule to G

In the next two examples, the iterated subgraph is connected to a ligature
which does not ”go inwardly from c to d” (the ligature crosses some cuts
more than once), so these examples are results of an in-correct application of
the iteration-rule to G.

Fig. 14.3. two diﬀerent results from a incorrect application of the iteration-rule

These graphs have diﬀerent meanings than G. This can be seen if we consider
the following models:

M1 :=

P R Q
a × ×
b

×

P R Q

M2 :=

a ×
b

×

It can easily be seen that G does not hold in M1, but the left graph of Fig. 14.3
holds in M1, thus they have diﬀerent meanings. Analogously, G holds in M2,
but the right graph of Fig. 14.3 does not, thus these two graphs have diﬀerent
meanings as well.

The rule of iteration may be reversed by the rule of deiteration. Particularly,
if we derive a graph from another graph by the rule of iteration, both graphs
have the same meaning. Thus we now see that the graphs of Fig. 14.3 cannot
be allowed to be derived by the rule of iteration from G.

QPRPQPRPQPRQPPRQPPRPQPRPQPR14.2 Iteration and Deiteration

155

With our understanding, the right graph of of Fig. 14.1 is the result of a
correct application of the iteration-rule. We have now in turn to show how
the left graph of Fig. 14.1 can be derived from G.

In 4.506, Peirce continues his explanation of the iteration-rule as follows:

The rule permits any loose end of a ligature to be extended inwardly
through a sep or seps or to be retracted outwards through a sep or
seps. It permits any cyclical part of a ligature to be cut at its innermost
part, or a cycle to be formed by joining, by inward extensions, the two
loose ends that are the innermost parts of a ligature.

With our handling of ligatures in the iteration-rule, it is not clear why loose
ends of ligatures can be be extended inwardly through cuts. For this reason, this extension of ligatures will be a separate clause in the version of
the iteration-rule which will be used and formalized in this treatise. In other
words, the mathematical deﬁnition of the iteration/deiteration rule in the next
chapter will be a formalization of the following informal understanding of the
rules:

Iteration:

1. Let G be a graph, and let G0 be a subgraph of G which is placed
in a cut (or the sheet of assertion) c. Let d be a a cut (or the sheet
of assertion) such that d = c or d is deeper nested than c. Then a
copy of G0 can be scribed on the area of d.
If G0 is connected to a ligature which goes inwardly from c to d
and which crosses no cut more than once, then the copy of G0
may be connected in d with this ligature.

2. A branch with a loose end may be added to a ligature, and this

loose end may be extended inwardly through cuts.3

Deiteration:
The rule of iteration may be reversed. That is: If G0 can be derived
from G with the rule of iteration, then G can be derived from G0 with
the rule of deiteration.

3 In some places, extensions of ligatures, particularly the transformation carried
out by part 2. of the iteration-rule is for Peirce a part of the insertion-rule, not
of the iteration-rule. This understanding of this transformation is explained for
example in 4.503, where Peirce needs to consider EGs where LoIs terminate on a
cut. On the other hand, an extension of a ligature ﬁts very well in the idea behind
the iteration-rule, and in other places (e.g. 4.506), an extension of ligatures is
encompassed by the iteration-rule. As we moreover dismissed EGs where LoIs
terminate on a cut, it is convenient to subsume the extension of ligatures by the
iteration-rule.

156

14 Getting Closer to the Calculus for Beta

With this rule, clause 1., the right graph of Fig. 14.1 can be derived from G.
Using both clauses one after the other, it is possible to derive the left graph
of Fig. 14.1 from G as well, as the following derivation shows:

It. 2.
‘

It. 1.
‘

Moreover, our understanding of the iteration-rule allows to rearrange ligatures
in cuts in nearly arbitrary ways. In the following, this will be exempliﬁed
with some examples. In Chpt. 16, some lemmata are provided which capture
mathematically the ideas behind these examples.

The main idea in all ongoing examples is to iterate or deiterate a portion of
a ligature in a cut. If a portion of a ligature is iterated, the rule of iteration
allows to connect arbitrary points of the iterated copy with arbitrary points
of the ligature. For example, if we start with the graph

all the graphs in Fig. 14.4 can be derived by a single application of the
iteration-rule:

,

Fig. 14.4. Iterating a Ligature within a Context

In the ﬁrst example, a portion of the ligature is iterated without connecting
the copy with the ligature. In the second example, a portion of the ligature
is iterated, and one of its two ends is connected to the ligature (this could be
an application of part 2. of the iteration-rule as well). In the third example,
a portion of the ligature is iterated, and both ends are connected to the
ligature. The same holds for the fourth example. Finally, in the last example,
three points of the iterated copy are connected to the ligature (one of them
to a branching point).

On page 102, I have already mentioned that Peirce did not consider EGs
having branching points with more than three branches. An easy part of
Peirce’s reduction thesis is that we do not need to consider identity relations
with an arity higher than three, that is, graphs having identity spots in which

QPPQPQPQSQSQSQSQSQS14.2 Iteration and Deiteration

157

more than three LoIs terminate can be avoided without any loss in their
expressivity. This is probably the reason we do not ﬁnd in Peirce’s works any
EG where branching points with more than three branches occur. Nonetheless,
in this treatise, due to convenience, branching points with more than three
branches are allowed. But if a graph having spots in which more than three
LoIs terminate is given, using the iteration/deiteration-rule, it can easily be
transformed into a semantically equivalent graph in which no such spots occur.
In order to see that, consider a branching point with more than three branches.

A ligature may contain branching points with
more than three branches. A branching point with
n branches can be sketched as follows (the small
numbers are used to enumerate the branches):

With an n-fold application of the last lemma, we
can add n lines of identity to this part of the ligature, which yields:

Now, again with the last lemma, we can remove all
lines of identity within the circle. Then we obtain:

With this procedure, we can transform each identity spot in which more than
three LoIs terminate into a ‘wheel’ on which only teridentity spots occur.

A very slight modiﬁcation of this proof shows that each branching point with
more than three branches can be converted into a ’fork-like’ ligature as well, as
it is depicted below (this is the kind of graphical device which Zeman normally
uses in [Zem64] instead of branching points with n branches):

Next, I want to show that ”branches of a ligature may be moved within a
context along that ligature”. In order to understand this phrase, consider the
third, fourth and ﬁfth graph of Fig. 14.2. These graphs diﬀer only in the fact
of the ligature in the innermost cut is attached at
that the branch
diﬀerent positions to that ligature. These graphs can be easily transformed
into each other. I will exemplify this with the third and forth graph of Fig. 14.2
(the shape and length of some lines of identity are slightly diﬀerent to the
graphs of Fig. 14.2, but ”the shape and length [of some lines of identity] are
matters of indiﬀerence” (4.416)).

P

1234n1234n1234n123n158

14 Getting Closer to the Calculus for Beta

We start with the third graph of Fig. 14.2:

Now a line of identity which is part of the ligature
is iterated into the same cut. Both ends of the
copy of the line of identity are connected to the
ligature as follows:

The portion of the ligature between the two
branches above P could have been inserted by a
similar application of the iteration-rule like in the
last step. Thus we are allowed to remove it with
the deiteration-rule. This yields the graph on the
right, which is the fourth graph of Fig. 14.2:

The proof uses only iteration and deiteration and maybe therefore be carried
out in both directions.

In Chpt. 11 we have already seen that

and

have the same meaning (see page 119). They diﬀer only in the place of the
branching point, which has so-to-speak moved from the sheet of assertion into
the cut. In fact, moving a branching point inwardly can be done in arbitrary
graphs for branching points in arbitrary context. That is, in Peirce’s graph,
we have:4

A devise like

can be replaced by

and vice versa

(in this representation, a segment of a cut-line is sketched, and we agree that
the whole device is part of a graph, placed in an arbitrary context). With
the rules iteration/deiteration and the possibility to move branches along
ligatures, as is just has been discussed, we can now elaborate how these devices
can syntactically be transformed into each other. This shall be done now.

4 This result will be made precise and generalized with Def. 16.6 and Lemma 16.7.
Burch obtained for his algebraic elaboration of Peirce’s logic in ([Bur91a]) a corresponding result. It is Thm. 7.5. of [Bur91a], a theorem of which Burch claims
to be ’of great importance for the presentation of the Representation theorem’.

PRQPPRQPPRQPPSRPSR14.3 Double Cuts

159

Let a graph be given where the left device occurs.
I.e., we start with the device on the right, placed
in an arbitrary context:

First we iterate a part of the ligature of the outer
cut into the inner cut:

Now we move the branch in the inner cut:

The iteration of the ﬁrst step is reversed with the
deiteration-rule:

The ‘loose’ end of the ligature is retracted with
the deiteration-rule. We obtain right device, which
is the device we wanted to derive (drawn slightly
diﬀerent).

A more general and formally elaborated version of this transformation will be
provided for EGIs in Chpt. 16. Finally, recall that we have already seen that
the following graphs have diﬀerent meanings (see page 119):

and

Thus it is not allowed to move the branching point in this example. Indeed,
the above given proof cannot be applied to these graphs, as it relies on some
applications of the iteration-rule to parts of the ligature in the outer cut.

14.3 Double Cuts

In Alpha, a double cut is a device of two nested cuts c1, c2 with area(c1) =
{c2}). That is, the outer c1 contains nothing directly except the inner cut c2
(but, of course, it is allowed that c2 in turn may contain other items, as these
items are thus not directly contained by c1). This understanding of a double
cut has to be generalized in Beta. In an example for Beta in Chpt. 2, we have
already seen an application of the double-cut rule where a ligature passes
entirely through the double cut (see page 14). This handling of ligatures is
described by Peirce’s deﬁnition of the double cut rule for Beta in 4.567: ‘Two
Cuts one within another, with nothing between them, unless it be Ligatures
passing from outside the outer Cut to inside the inner one, may be made or

PRQPRQ160

14 Getting Closer to the Calculus for Beta

abolished on any Area.’ Let us ﬁrst consider a valid example of the doublecut-rule. We have:

dc
‘

It is obvious that the area of the outer cut is not allowed to contain
any relation-names. For example, although we have a ligature which passes
through both cuts, the following is an invalid application of the double-cut
rule (indicated by the crossing out of the symbol ‘‘’):

dc
6‘

In fact, if we consider the relational structure M1 with a single element a,
such that P (a) and R(a), but not Q(a) holds, the left graph holds in M1, but
the right graph does not.

Moreover, it is crucial that each ligature passes through both cuts: No ligature
may start or end in the area of the outer cut. If a ligature starts in the area of
the outer cut, we may obtain an invalid conclusion, as the following example
shows:

dc
6‘

The left graph has the meaning ‘if there is an object with property P , then
there is an object which has not property R’, while the meaning of the right
graph is ‘it is not true that there exists an object with the property P and an
object with the property R’, thus this conclusion is not semantically valid.

Strictly speaking, a ligature is not allowed to end in the area of the outer cut,
neither, that is, the next example is again an invalid application of the double
cut rule.

dc
6‘

But in fact, the right graph can be derived from the left graph by ﬁrst retracting the ligature with the deiteration-rule, and then by applying the double-cut
rule. Both graphs are semantically equivalent.

‘To pass through both cuts’ has to be understood very rigidly: A ligature
which passes through the cut, but which has branches in the area of the outer
cut, may cause problems. The next example is another invalid application of
the double-cut rule:

RPQQPRPQQPRPQRPQRPRPPRPR14.4 Inserting and Deleting a Heavy Dot

161

dc
6‘

To see that this implication is not valid, consider the following relational
structure M2:

P Q R

M2 :=

a ×
b

×

It is easy to check that the left graph holds in M2, but the right graph does
not.

So, for Beta, two cuts c1, c2 are understood to be a double cut if c2 is scribed in
the area of c1, and if c1 contains except c1 only ligatures which begin outside
of c1, pass completely through c1 into c2, and which do not have on the area
of c1 any branches.
It is a slightly surprising, but nice feature of the mathematical elaboration
of existential graphs that we do not have to change our understanding of a
double cut in EGIs if we go from Alpha to Beta. That is, for EGIs, which
are the mathematical implementations of Peirce’s Beta graphs, a double cut
is indeed still a device of two cuts c1, c2 with area(c1) = {c2}. To see this,
assume we consider a Peircean Beta graph with a double cut, such that there
is a ligature which passes entirely through this double cut. In the mathematical reconstruction of this EG, i.e. in the corresponding EGI, we do not have
to place a vertex in the area of the outer cut. This can be better seen if we
‘translate’ the example of the beginning of this section into EGIs. A application of the double cut rule of the corresponding EGIs is as follows (in order to
indicate that neither any vertex, nor any identity-edge is placed in the area
of the outer cut, the identity-edge is labeled with the relation-symbol ‘=’ in
the appropriate cut):

dc
‘

14.4 Inserting and Deleting a Heavy Dot

In our semantics, we consider, as usual in mathematics, only non-empty relational structures as models (see Def. 13.1). For this reason, it must be possible
to derive that there is an object.

Surprisingly, neither in Peirce’s manuscripts, nor in secondary literature, we
ﬁnd a rule which explicitely allows to derive a heavy dot or a line of identity.

PQRPQRRQQPPRQQPP162

14 Getting Closer to the Calculus for Beta

But, in his ’Prolegomena to an Apology For Pragmaticism’, he states in 4.567
‘that, since a Dot merely asserts that some individual object exists, and is
thus one of the implications of the Blank, it may be inserted in any Area.’
This principle is not stated as an explicit rule, but as a principle ‘the neglect
of which might lead to diﬃculties.’ In order to provide a complete calculus, it
is convenient to add this principle as a rule to it.

15

Calculus for Existential Graphs

In this chapter, we will provide the formal deﬁnitions for the calculus for EGIs
and EGs.

We start with the calculus for EGIs. Before its formal deﬁnition is given, we
ﬁrst have to introduce a simple relation on the set of vertices of an EGI. Recall
that in the iteration-rule, where a subgraph is iterated from a context c into a
context d, we had to consider ‘ligatures which go inwardly from c to d’. This
idea is formally captured as a relation Θ on the set of vertices.

Deﬁnition 15.1 (Θ). Let G := (V, E, ν, >, Cut, area, κ) be an EGI. On V ,
a relation Θ is deﬁned as follows: Let v, w ∈ V be two vertices. We set vΘw
iﬀ there exist vertices v1, . . . , vn (n ∈ N) with

1. either v = v1 and vn = w, or w = v1 and vn = v,
2. ctx(v1) ≥ ctx(v2) ≥ . . . ≥ ctx(vn), and
3. for each i = 1, . . . , n − 1, there exists an identity edge ei = {vi, vi+1}

between vi and vi+1 with ctx(ei) = ctx(vi+1).

It should be noted that Θ is trivially reﬂexive and symmetric, but usually not
transitive (i.e., Θ is no equivalence relation). This can easily be seen with the
following well-known graph:

The vertex in the cut is in Θ-relation with each of the two vertices on the
sheet of assertion, but these two vertices are not in Θ-relation.

Now we are prepared to provide the deﬁnition for the calculus. Similar to
Sect. 8.3, we will ﬁrst describe the whole calculus using common spoken language. After this, we present mathematical deﬁnitions for the rules.

Deﬁnition 15.2 (Calculus for Existential Graphs Instances). The calculus for EGIs over the alphabet R consists of the following rules:

164

15 Calculus for Formal Existential Graphs

• erasure

In positive contexts, any directly enclosed edge, isolated vertex, and closed
subgraph may be erased.

• insertion

In negative contexts, any directly enclosed edge, isolated vertex, and closed
subgraph may be inserted.

• iteration

– Let G0 := (V0, E0, ν0, >0, Cut0, area0, κ0) be a (not necessarily closed)
subgraph of G and let c ≤ ctx(G0) be a context such that c /∈ Cut0.
Then a copy of G0 may be inserted into c.
Furthermore, the following may be done: If v ∈ V0 with ctx(v) =
ctx(G0) is a vertex, and if w ∈ V0 with ctx(w) = c is a vertex with
vΘw, then an identity edge between v and w may be inserted into c.

– If v ∈ V is a vertex, and if c ≤ ctx(v) is a cut, then a new vertex w

and an identity edge between v and w may be inserted into c.

• deiteration

If G0 is a subgraph of G which could have been inserted by rule of iteration,
then it may be erased.

• double cuts

Double cuts (two cuts c1, c2 with area(c1) = {c2}) may be inserted or
erased.

• erasing a vertex

An isolated vertex may be erased from arbitrary contexts.

• inserting a vertex

An isolated vertex may be inserted in arbitrary contexts.

Next, the mathematical deﬁnition for the rules are provided.

• double cuts

Let G := (V, E, ν, >, Cut, area, κ) be an EGI graph and c1, c2 ∈ Cut
such that area(c1) = {c2}. Let c0 := ctx(c1) (i.e., c1 ∈ area(c0)) and
set G0 := (V, E, ν, >, Cut0, area0, κ) with
– Cut0 := Cut\{c1, c2}

– area0(d) :=

(cid:26)

area(d) for d 6= c0
area(c0) ∪ area(c2) for d = c0

.

Then we say that G0 is derived from G by erasing the double cuts
c1, c2 and G is derived from G0 by inserting the double cuts c1, c2.

15 Calculus for Formal Existential Graphs

165

• erasure and insertion, erasing and inserting a vertex

First, general deﬁnitions for inserting and erasing vertices, edges and closed
subgraphs are provided.

(cid:12)E(e)

Let G := (V, E, ν, >, Cut, area, κ) be an EGI with an edge e ∈ E, and let
G(e) := (V (e), E(e), ν(e), >(e), Cut(e), area(e), κ(e)) be the following graph:
– V (e) := V
– E(e) := E\{e}
– ν(e) := ν(cid:12)
– >(e) := >
– Cut(e) := Cut
– area(e)(d) := area(d)\{e} for all d ∈ Cut(e) ∪ {>(e)}
– κ(e) := κ(cid:12)
Let c := ctx(e). We say that G(e) is derived from G by erasing the edge
e from the context c, and G is derived from G(e) by inserting the
edge e into the context c.

(cid:12)E(e)

Let G := (V, E, ν, >, Cut, area, κ) be an EGI which contains the closed
subgraph G0 := (V0, E0, ν0, >0, Cut0, area0, κ0).
Let G0 := (V 0, E0, ν0, >0, Cut0, area0, κ0) be the following graph:
– V 0 := V \V0
– E0 := E\E0
– ν0 := ν(cid:12)
– >0 := >
– Cut0 := Cut\Cut0

(cid:12)E0

– area0(d) :=

(cid:26)

area(d)quadd 6= >0
area(d)\(V0 ∪ E0 ∪ Cut0)quadd = >0

.

(cid:12)E0

– κ0 := κ(cid:12)
Then we say that G0 is derived from G by erasing the subgraph G0
from the context >0, and G is derived from G0 by inserting the
graph G0 into the context >0.
Now the rules of the calculus are restrictions of the general deﬁnitions:

– erasure and insertion

Let G be an EGI and let k be an edge or a closed subgraph of G
with c := ctx(k), and let G0 be obtained from G by erasing k from
the context c. If c is positive, then G0 is derived from G by erasing
k from a positive context, and if c is negative, then G is derived
from G0 by inserting k into a negative context.

166

15 Calculus for Formal Existential Graphs

– erasing and inserting a vertex

Let G := (V, E, ν, >, Cut, area, κ) be an EGI and let v ∈ V be a vertex
with Ev = ∅ and κ(v) = >. Then G0 := ({v}, ∅, ∅, ctx(v), ∅, ∅, ∅) is a
closed subgraph only consisting v. Let G0 be obtained from G by erasing
v from the context ctx(v). Then G0 is derived from G by erasing the
isolated vertex v, and G is derived from G0 by inserting the
isolated vertex v.

• iteration and deiteration

Let G := (V, E, ν, >, Cut, area, κ) be an EGI with the subgraph G0 :=
(V0, E0, ν0, >0, Cut0, area0, κ0), and let c ≤ >0 with c /∈ Cut0 be a context.
Let W0 := V0 ∩ area(>0). For each vertex v ∈ W0 let Wv ⊆ V be a
(possibly empty) set of vertices which satisﬁes wΘv and w ∈ area(c) for
all w ∈ Wv. For each v ∈ W0 and w ∈ Wv, let ev,w be a fresh edge. We set
F := {ev,w | v ∈ W0 and w ∈ Wv}.
Now let G0 := (V 0, E0, ν0, >0, Cut0, area0, κ0) be the following graph:
– V 0 := V ×{1} ∪ V0 ×{2}
– E0 := E ×{1} ∪ E0 ×{2} ∪ F

– ν0(e0) :=






((v1, i), . . . , (vn, i)) for e0 = (e, i) ∈ E ×{1} ∪ E0 ×{2} and
ν(e) = (v1, . . . , vn)
((w, 1), (v, 2)) for v ∈ W0, w ∈ Wv and e0 = ev,w

– >0 := >
– Cut0 := Cut×{1} ∪ Cut0 ×{2}
– area0 is deﬁned as follows:

for (d, i) ∈ Cut0 ∪ {>0} and d 6= c, let area0((d, i)) := area(d)×{i} and
area0((c, 1)) := area(c)×{1} ∪ area0(>0)×{2} ∪ F
(cid:26) κ(e) for e0 = (e, i) ∈ E ×{1} ∪ E0 ×{2}

– κ0(e0) :=

.= for e0 ∈ F

Then we say that G0 is derived from G by iterating the subgraph G0
into the context c and G is derived from G0 by deiterating the
subgraph G0 from the context c.

It should be noted that the iteration/deiteration-rule may be applied to arbitrary subgraphs, whilst the erasure/insertion-rule may only be applied to
closed subgraphs. The reason is that the erasure (or insertion) of a subgraph
which is not closed does not yield a well-formed EGI. This causes no troubles,
as we already informally discussed in Sect. 14.1 how non-closed subgraphs can
be erased. To see an simple example for EGI, consider

with its non-closed subgraph

.

1P1Q1Q15 Calculus for Formal Existential Graphs

167

It is not possible to erase the subgraph, as the edge labeled with P is incident
with a vertex of the subgraph. but for the corresponding EGs, the following
derivation is allowed:

‘

This derivation is for EGIs performed as follows:

∼

erasure
of edge
‘

erasure
of subg.
‘

This idea can easily be transferred to more complex examples, thus, informally
speaking, it is possible to erase non-closed subgraphs with the erasure-rule as
well (and, analogously, to insert non-closed subgraphs with the insertion-rule).

Proofs are essentially deﬁned like for Alpha. For Beta, we have to take both
the transformation-rules and the rules of the calculus into account.

Let Ga, Gb be EGIs. Then Gb can be deDeﬁnition 15.3 (Proof ).
rived from Ga (which is written Ga ‘ Gb), if there is a ﬁnite sequence
(G1, G2, . . . , Gn) with G1 = Ga and Gb = Gn such that each Gi+1 is derived
from Gi by applying one of the rules of the calculus or one of the transformation rules. The sequence is called a proof for Ga ‘ Gb. Two graphs
G1, G2 with G1 ‘ G2 and G2 ‘ G1 are said to be provably equivalent or
syntactically equivalent.
If H := {Gi | i ∈ I} is a (possibly empty) set of EGIs, then a graph G
can be derived from H if there is a ﬁnite subset {G1, . . . , Gn} ⊆ H with
G1 . . . Gn ‘ G.

Similar to the semantics, the calculus for EGIs can be transferred to a calculus
for existential graphs.

Deﬁnition 15.4 (Calculus for Existential Graphs). Let Ea, Eb be EGs.
We say that Eb can be derived from Eb with one of the rules of the calculus
for EGIs (see Def. 15.2, if this holds for some representing EGIs Ga ∈ Ea
and Gb ∈ Eb.
Moreover, we say that Eb can be derived from Ea (which is written Ea ‘
Eb), if there is a ﬁnite sequence (E1, E2, . . . , En) of existential graphs with
E1 = Ea and Eb = En such that each Ei+1 is derived from Ei by applying one
of the rules of the calculus. The sequence is called a proof for Ea ‘ Eb.
If H := {Ei | i ∈ I} is a (possibly empty) set of existential graphs, then a
graph E can be derived from H if there is a ﬁnite subset {E1, . . . , En} ⊆ H
with E1 . . . En ‘ E. 1
1 Recall that the juxtaposition of existential graphs is carried over from the definition of the juxtaposition for EGIs, as it has been explained directly after
Def. 12.15.

1Q1PP11P1QQ11PQ11P1P168

15 Calculus for Formal Existential Graphs

If we have a proof (G1, G2, . . . , Gn) for two EGIs Ga, Gb with Ga ‘ Gb,
then this proof immediately yields a proof for [Ga]∼ ‘ [Gb]∼: We start
with the proof (G1, G2, . . . , Gn). From the sequence (G1, G2, . . . , Gn), we
remove all graphs Gi which are derived from Gi−1 with a transformationrule. From the remaining subsequence (Gi1, Gi2, . . . , Gik ), we obtain the proof
([Gi1, [Gi2]∼, . . . , [Gik ]∼) for [Ga]∼ ‘ [Gb]∼. First examples for this principle
will be given in the next chapter. A thoroughly discussion on how the calculus
for EGIs is be used for formal existential graphs will be provided in Chpt. 21.

16

Improving the Handling of Ligatures

Before the soundness of the calculus for EGIs is proven the next chapter, we
will investigate more deeply the understanding and handling of ligatures. This
will be ﬁrst done for EGIs, and the results for EGIs will then be transferred
to EGs. In the ﬁrst section of this chapter, we will derive some rules which
allow to rearrange ligatures in various ways. In the second section, we will
use the results of the ﬁrst section to investigate how ligatures can be better
understood.

16.1 Derived Rules For Ligatures

In Sect. 14.2, we had already discussed some examples which show that the
iteration/deiteration-rule allows to rearrange ligatures in Peirce’s graphs. The
ideas behind these examples are mathematically elaborated in this section.

We start with the mathematical elaboration of ‘moving branches along a ligature’ for EGIs, as it had been discussed for Peirce’s graphs on page 157 ﬀ.
Let an EGI G with a ligature in a cut c be given. Then any branch of this
ligature may be disconnected from that ligature and connected to it again
in an arbitrary other place on that ligature. This is formally captured and
proven in the next lemma.

Lemma 16.1 (Moving Branches along a Ligature in a Context).
Let G := (V, E, ν, >, Cut, area, κ) be an EGI, let va, vb be two vertices with
c := ctx(va) = ctx(vb) and vaΘvb, and let e be an edge such that the hook
(e, i) is attached to va. Let G0 := (V, E, ν0, >, Cut, area, κ) be obtained from
G by replacing va by vb on the hook (e, i). Then G and G0 are syntactically
equivalent.

Proof: The proof of this lemma is quite easy. To exemplify the graphical notation for proofs, this proof provided in two diﬀerent ways. In each application

170

16 Improving the Handling of Ligatures

of a rule of the calculus, the result is given as mathematical structure as well
as a digram representing the mathematical structure. In order to keep the
proof readable, we use in both notations some further notational conventions,
which shall be explained ﬁrst.

In the proof, the graph G will be modiﬁed only in area(va) (=area(vb)), and
the edge e (more precisely: the value ν(e) of the function ν) will be changed.
For this reason, we set ν0 := ν\{(e, ν(e))} and area0 := area\{(c, area(va))}.
Moreover, as only the hook (e, i) is changed, we will write ‘(e, (. . . , v, . . .))’ to
indicate that we have ν(e)(cid:12)
In the graphical notation, only the part of the graph G are shown which
are relevant for the proof. All vertex-spots and edges-lines are labeled with
their corresponding vertices and edges. The relation vaΘvb is depicted in the
graphical notation with the symbol Θ between the vertex-spots of va and
vb. To indicate that e might be placed in a deeper context than ctx(va), the
relation-symbol (we have chosen the letter R) of the edge e is placed in the
segment of a cut-line.

(cid:12)i = v.

We start the proof with the graph G:

( V, E,
.
∪ {(e, (. . . , va, . . .))},
ν0
>, Cut,
.
area0
∪ {(c, A)},
κ )

We add a vertex v1 (and an identity-edge e1) between va and the hook (e, i)
with the transformation-rule ’adding a vertex’. This yields:

.
∪ {v1},

( V
E
ν0
>, Cut,
.
area0
∪ {(c, A
.
∪ {(e1, .=)} )}
κ

.
∪ {e1},
.
∪ {(e, (. . . , v1, . . .)), (e1, (va, v1))},

.
∪ {v1, e1})},

We iterate the vertex v1. The copy of v1 is named v2, and an identity-edge
between v2 and v1 and an identity-edge between v2 and vb is added. This
yields the following graph:1

1 This graph is not the ‘direct’ result of an application of the iteration-rule, as
we considered in the deﬁnition of the rule the product V × {1} and V0 × {2}.
But we consider graphs only up to isomorphism, thus the next graph, which is
isomorphic to the ‘direct’ result of the iteration-rule, is considered to be a result
of the iteration-rule as well.

RvabvQvabvR1v1eQ16.1 Derived Rules For Ligatures

171

( V
E
ν0

.
∪ {v1, v2}
.
∪ {e1, e2, e3},
.
∪ {(e, (. . . , v1, . . .)), (e1, (va, v1)),
(e2, (v2, vb)), (e3, (v2, v1))},

>, Cut,
.
area0
∪ {(c, A
.
κ

∪ {(e1, .=), (e2, .=), (e3, .=)} )

.
∪ {v1, v2, e1, e2, e3})},

With the transformation-rule ’adding a vertex’, we add a vertex v3 (and an
identity-edge e4) between va and v1 as follows:

( V
E
ν0

.
∪ {v1, v2, v3}
.
∪ {e1, e2, e3, e4},
.
∪ {(e, (. . . , v1, . . .)), (e1, (v3, v1)),
(e2, (v2, vb)), (e3, (v2, v1)), (e4, (va, v3))},

>, Cut,
.
area0
∪ {(c, A
.
κ

.
∪ {v1, v2, v3, e1, e2, e3, e4})},

∪ {(e1, .=), (e2, .=), (e3, .=), (e4, .=)} )

The vertex v3 and the two identity-edges e4 and e1 could be the result of an
iteration of v2. Thus they can be erased with the rule of deiteration.

.
∪ {v1, v2}
.
∪ {e2, e3},
.
∪ {(e, (. . . , v1, . . .)), (e2, (v2, vb)), (e3, (v2, v1))},

.
∪ {v1, v2, e2, e3})},

∪ {(e2, .=), (e3, .=)} )

( V
E
ν0
>, Cut,
.
area0
∪ {(c, A
.
κ

.
∪ {v1},

( V
E
ν0
>, Cut,
.
area0
∪ {(c, A
.
∪ {(e3, .=)} )
κ

.
∪ {e3},
.
∪ {(e, (. . . , v1, . . .)), (e3, (vb, v1))},

.
∪ {v1, e3})},

The vertex v2 and the edge e2 are removed with the transformation-rule ’removing a vertex’. This yields:

Similar to the last step, the vertex v1 and the edge e3 are removed with the
transformation-rule ’removing a vertex’. This yields:

( V, E,
.
ν0
∪ {(e, (. . . , vb, . . .))},
>, Cut,
.
area0
∪ {(c, A)},
κ )
This is G0, thus we are done.

2

vabvR1v1e2e2v3eQR2v3ebv2e4e3v1v1evaQR2v3e1v2ebvvaQR3e1vbvvaQbvvaQR172

16 Improving the Handling of Ligatures

The proof should not only prove the lemma, but also show how the modiﬁcations of the mathematical structures are represented by the diagrams. As the
rules of the calculus correspond to modiﬁcations of the diagrams, the graphical
notation is easier to understand than the symbolic notation. For this reason in
all ongoing proofs, we will mainly use the graphical representations of EGIs.

For Peirce’s graphs, we have seen on page 156 in Fig. 14.4 that some simple
applications of the iteration-rule can add new branches to a given ligature,
and these branches may be connected several times to the that ligature. This
will now be elaborated for EGIs.

Informally speaking, we can do the following: If in an EGI an arbitrary ligature
is given, we can pick out a vertex v of this ligature, and the rule of iteration
allows iterate v, i.e., to add a new vertex v0 and new identity-links between v0
and the given ligature. This process can be applied to the new vertices as well,
and by an iterative application of the iteration-rule, we can ﬁnally add a new,
arbitrarily connected network of LoIs, i.a., a ligature, to our given ligature.
This idea is captured by the next lemma.

Lemma 16.2 (Extending or Restricting a Ligature in a Context).
Let a EGI G be given with a vertex v. Let V 0 be a set of fresh vertices and E0
be be a set of fresh edges. Let G0 := (V 0, E0, ν0, >0, Cut0, area0, κ0) be obtained
from G such that all fresh vertices and edges are placed in the context ctx(v),
.
∪ V 0 such
and all fresh edges are identity edges between the vertices of {v}
that we have vΘv0 for each v0 ∈ V 0. That is, G0 satisﬁes:

.
∪ V 0 and E0 := E
.
∪ V 0)2 for each e0 ∈ E0

.
∪ E0

• V 0 := V
• ν0 ⊇ ν and ν0(e0) ∈ ({v}
• >0 := > and Cut0 := Cut

• area0(d) :=

(cid:26)

area(d) for d 6= ctx(v)
.
∪ V 0 for d = ctx(v)

.
∪ E0

.

area(d)

• κ0 := κ

.
∪ E0 ×{ .=}

Then G and G0 are syntactically equivalent.

Proof: For each v0 ∈ V 0 let d(v0) be the length of the shortest path (in G0)
:= {v0 ∈ V 0 | d(v0) = i}. Let
from v0 to v along edges in E0, and we set V 0
i
m be the maximal number with V 0
m 6= ∅. Now, V 0 and E0 can be inductively
be constructed with the rule of iteration, applied to v: In the kth step, we
k and all fresh edges which are (in G0) incident in
can add all vertices of V 0
one place with a vertex of V 0
k and in the other place only with a vertex in
Sk−1
i . If this induction is done, it remains to add all fresh edges who are
n. Let e0 be such an fresh edge.
in both places incident with one vertex of V 0
This edge can be added as follows: The rule of iteration is applied, and a new
(cid:12)1 resp. between w and e0(cid:12)
vertex w and two identity-links between w and e0(cid:12)
(cid:12)2 is

i=1 V 0

16.1 Derived Rules For Ligatures

173

added, and afterwards, the transformation-rule ‘removing a vertex’ is applied
to v0 and one of the just added identity-links. The remaining-identity-link is
incident with e(cid:12)
(cid:12)2, thus is can be replaced by e.
As we have constructed G0 from G only with the iteration-rule and the
transformation-rule ‘removing a vertex’, G and G0 are syntactically equiv2
alent.

(cid:12)1 and e(cid:12)

With the last two lemmata, it is possible to ‘retract’ a ligature in a context
to a single vertex, and vice versa, which is the subject of the next lemma.

Lemma 16.3 (Retracting a Ligature in a Context). Let G be an EGI.
Let (W, F ) be a ligature which is placed in a context c, i.e., ctx(w) = c =
ctx(f ) for all w ∈ W and f ∈ F , and let w0 ∈ W . Let G0 be obtained from
G as follows: The ligature (W, F ) is retracted to w0, i.e., all vertices of
W \{w0} and all edges of F are removed from c, and if an edge e ∈ E\F was
incident with a vertex w ∈ W with w 6= w0, it is connected to the vertex w0.
That is, G0 is deﬁned as follows:

.
∪ {w0}

• V 0 := V \W
• E0 := E\F
• We deﬁne ν0 as follows: For ν(e) = (v1, . . . , vn), let ν0(e) = (v0

1, . . . , v0

n)

with v0

(cid:26) vi for vi /∈ W
w0 for vi ∈ W
• >0 := > and Cut0 := Cut

i :=

.

• area0(d) :=

(cid:26)

• κ0 := κ(cid:12)

(cid:12)E0

area(c)\(W

.
∪ F )

area(d) for d 6= c
.
∪ {w0} for d = c

.

Then G and G0 are syntactically equivalent.

Proof: Let (e, i) be an arbitrary hook with e /∈ F and which is attached to a
vertex w ∈ W with w 6= w0. Using Lem. 16.1, we can replace w by w0 on the
hook (e, i). If this is done for all such hooks, we obtain a graph G00 which is
syntactical equivalent to G, and for which no vertex w ∈ W with w 6= w0 is
incident with an edge e /∈ F . Thus we can remove all vertices in W \{w0} and
all edges in F with one application of Lem. 16.2. The graph G0 we obtain is
2
the desired graph, thus we are done.

It should be noted that the last lemma can be used in both directions: It does
not only allow to retract a ligature in a context to a single vertex; vice versa,
it allows to replace a single vertex by a ligature. An important consequence of
this direction is the possibility to avoid branching points with more than three
branches. For Peirce’s graphs, it has already been discussed on page 156 how
such branching points can be converted into ligatures having only branching
points with three branches. Now this can be be done for EGIs as well.

174

16 Improving the Handling of Ligatures

Lemma 16.3 allows to convert a single vertex which is attached to more than
three hooks into a ‘wheel’ or a ’fork’, i.e.,

can be converted into

or

For example, this application of Lem. 16.3 yields that the following three

graphs are provably equivalent:

Finally, we can use Lem. 16.3 to convert complete ligatures within the area
of a given context. This shall ﬁrst be formally deﬁned.

Deﬁnition 16.4 (Rearranging Ligatures in a Context). Let G be an
EGI. Let (W, F ) be a ligature which is placed in a context c, i.e., ctx(w) =
c = ctx(f ) for all w ∈ W and f ∈ F . Let G0 be obtained from G as follows:
The ligature (W, F ) is replaced by a new ligature (W 0, F 0), i.e., all vertices of
W and all edges of f are removed from c, the vertices of W 0 and edges of E0
are inserted into c, and if an edge e ∈ E\F was incident with a vertex w ∈ W
of the ligature, it is now connected to a vertex w0 ∈ W 0 of the new ligature.
That is, G0 satisﬁes:

.
∪ W 0
.
∪ F 0

• V 0 := V \W
• E0 := E\F
• For ν0, it holds the following: For e ∈ E\F , ν(e) = (v1, . . . , vn), and
i ∈ W 0, if vi ∈ W

i := vi, if vi /∈ W , and v0

n), we have v0

ν0(e) = (v0

1, . . . , v0

• >0 := > and Cut0 := Cut

• area0(d) :=

(cid:26)

area(c)\(W

.
∪ F )

area(d) for d 6= c
.
∪ F 0) for d = c

.
∪ (W 0

.

• κ0 := κ(cid:12)

(cid:12)E\F

.
∪ F 0 × { .=}

Then we say that G0 is obtained from G by rearranging the ligature
(W, F ) (to (W 0, F 0)).

If G0 is obtained from G by rearranging a ligature, it can easily seen that
these graphs are syntactically equivalent: First we can retract with Lem. 16.3

1234n234n11234nPRQPRQQRP16.1 Derived Rules For Ligatures

175

the ligature (W, F ) to a single vertex w0 ∈ W , afterwards w0 can be extended
with the opposite direction of Lem. 16.3 to the new ligature (W 0, F 0). I.e., we
have:

Corollary 16.5 ([Rearranging Ligatures in a Context). If G0 is obtained
from G by rearranging a ligature in a context, then G and G0 are syntactically
equivalent.

To summarize this result in sloppy way: A ligature in a context may be arbitrarily changed, as long as it keeps connected.

So far in this section, we have only modiﬁed ligatures which are wholly contained in the area of a given context. At the end of Sec. 14.2, we have already
discussed for Peirce’s graphs how branching points of a ligature can be moved
across cuts. The idea of moving branching points can now for EGIs be mathematically elaborated and canonically be generalized.

In Sec. 14.2, we have moved a branching point into a cut for which two
branches go from the branching point into the cut, but instead of exactly
two, we may consider an arbitrary number of such edge-lines. Moreover, the
branching point may move more than one cut inwardly. This generalization is
mathematically captured by the following deﬁnition.

Deﬁnition 16.6 (Splitting a Vertex/Merging two Vertices). Let G :=
(V, E, ν, >, Cut, area, κ) be an EGI, let v ∈ V . Let (e1, i1), . . . , (en, in) be an
enumeration of some (not necessarily all) hooks v is attached to. Let c be a
context with ctx(v) ≥ c and c ≥ ctx(ek) for all 1 ≤ k ≤ n, and let v0 be a fresh
vertex and e0 be a fresh edge. Now let G0 := (V 0, E0, ν0, >0, Cut0, area0, κ0) be
obtained from G as follows:

.
∪ {v0}
.
∪ {e0}

• V 0 := V
• E0 := E
• ν0 is deﬁned as follows: ν0(e0) = (v, v0), and for f 6= e0, we set

(cid:26)

ν0(f )(cid:12)

(cid:12)j :=

ν(f )(cid:12)

v0 for (f, j) = (ei, ni), 1 ≤ i ≤ n
(cid:12)j for else

,

• >0 := > and Cut0 := Cut
• area0(d) := area(d) for d 6= c, and area0(c) := area(c)
• κ0 := κ

.
∪ {(e0, .=)}.

.
∪ {v0, e0}, and

Then we say that G0 is derived from G by merging v1 into v2 and G is
derived from G0 by splitting v1.

Slightly more informally, but easier to understand, the rules can be described
as follows:

176

16 Improving the Handling of Ligatures

• splitting a vertex

Let v be a vertex in the context c0 attached to hooks (e1, i1), . . . , (en, in),
placed in contexts c1, . . . , cn, respectively. Let c be a context such that
c1, . . . , cn ≤ c ≤ c0. Then the following may be done: In c, a new vertex
v0 and a new identity-link between v and v0 is inserted. On the hooks
(e1, i1), . . . , (en, in), v is replaced by v0.

• merging two vertices

Let e ∈ Eid be an identity edge with ν(e) = (v1, v2) such that ctx(v1) ≥
ctx(e) = ctx(v2). Then v2 may be merged into v1, i.e., v2 and e are erased
and, for every edge e ∈ E, e(cid:12)

(cid:12)i = v1 is replaced by e(cid:12)

(cid:12)i = v2.

In the next example, the right graph is obtained from the left graph by splitting the outermost vertex. Please note that if a vertex v is incident more than
once with an edge, arbitrary occurrences of v are substituted by its copy:
For R, both occurrences are substituted, while for S, only one occurrence is
substituted.

If the rule ‘splitting a vertex’ is applied such that exactly one occurrence of v
on an edge is substituted by its copy v0, then this corresponds to an application
of the transformation-rule ‘adding a vertex’. Thus, the rules ‘splitting a vertex’
and ‘merging two vertices’ can be understood to be a generalization of the
transformation-rules ‘adding a vertex/removing a vertex’. These rules can
from derived from the calculus, as the next lemma shows.

Lemma 16.7 (Splitting a Vertex/Merging two Vertices). Let G :=
(V, E, ν, >, Cut, area, κ) be an EGI, let v in V , and let G0 be obtained from G
by splitting the vertex v. Then G and G0 are syntactically equivalent.

Proof: In diagrams for EGIs, each hook (ek, ik) corresponds to an edge-line
between the vertex-spot of v to the symbol of the relation κ(e). In the graphical
notation for this proof, each hookline (ek, ik) is labeled with n, the relationsymbols of the edges ek are not shown. In order to indicate that we might have
c < ctx(v), a cut-segment is drawn, but keep in mind that this cut-segment
may stand for more than one cut, or even no cut (roughly speaking, the proof

PTSRSPPSRSPT16.1 Derived Rules For Ligatures

177

would work as well if we had no or many cut-lines instead of exactly one).
The area right from the cut-line shall represent the area of c. So the starting
graph G is depicted as follows:

With the transformation-rule ‘adding a vertex’,
for each 1 ≤ k ≤ n, a vertex vi (and an identityedge idi) is added between v and the hook (ek, ik),
and vi is placed in area(c).

Now the vertex v is n − 1-times iterated. The ith
copy of v is placed in the context c and shall be
called v0
i. In the ith iteration, an identity-edge between v0
i and vi and an identity-edge between v0
i
and vi+1 is inserted.

The part of the ligature inside the context c can
now be rearranged.

v321nn−1v3vn−1n−1v22vnnv11v3v1v2v’1v’2v3v’nvnvvn−113n2v2v’1v’2v3v’nvn123nv1vvn−1178

16 Improving the Handling of Ligatures

The iteration of the last but one step of this proof
can be undone with the rule of deiteration.

Again with the rule of deiteration, we can now
erase the vertices vi and the identity-edges idi between v and vi.

The last part of the graph is the desired result. Note that the proof only needs
the rules of iteration and deiteration and the transformation-rules, thus it can
2
be carried out in both directions.

16.2 Improving the Reading of Ligatures

Based on the results of the last sections, we can now derive some methods
which ease the understanding and handling of ligatures.

In Sec. 11.1, we have seen that, strictly speaking, only identity spots are
used to denote objects. Due to Peirce’s convention No. 6, a line of identity
denotes the identity of the objects denoted by its two extremities, and, as we
have seen, this convention turned out to be a conclusion from Peirce’s deeper
understanding of the inner structure of LoIs. Nonetheless, in the common
reading, a line of identity is usually read as if they simply denote a single
object. The very ﬁrst example of a beta graph in this treatise was

The graph is read as follows: A cat is on a mat. It contains two lines of identity,
each of them is understood to denote a single object. Even when a heavy line
crosses a cut, it can be interpreted this way. On page 100, we have already
seen the graph

This graph can be read as follows: There is a man who will not die. That is,
the whole heavy line is understood to denote a single object, namely an immortal man. Analogously, the ligatures in the (equivalent) graphs of Fig. 14.1

v3v2vn123nv1vvn−1123nv1vcatonmatmanwill die16.2 Improving the Reading of Ligatures

179

on page 152 stand for a single object. Recall that Peirce admits that a more
complex reading, unfolding the understanding that a LoI is composed of overlapping identity spots, is ‘unspeakably triﬂing, – not to say idiotic’.

In Peirce’s graphs, heavily drawn lines crossing a cut or networks of heavily
drawn lines are called ligatures. Ligatures with branches can, similar to the last
two examples, usually be understood to stand for a single object. For example,
the complex left ligature in Fig. 11.1 on page 102 stands for Aristotle.

Nonetheless, other examples show that this interpretation of ligatures is not
in every case that simple. A ligature may stand for more than one object. The
most simple example where such a ligature occurs is the well-known graph
Etwothings, where a single, heavy line traverses a cut (see page 97). This graph
has the meaning ‘there are at least to things’, i.e., in this graph, the ligature
does not stand for a single object. Analogously, we have already seen on page
116 that in the graph of Fig.118 in 4.469, i.e.,

,

the ligature cannot be understood to denote one object (but it cannot be
understood to stand for three objects, neither, as the meaning of this graph is
‘there are three things which are not all identical’). So, naturally the following
question arises: When can a ligature be interpreted to denote a single object?
With the results of the preceeding section, this question can now be answered.

The clue to the answer can already been found in the discussed examples. We
have already seen that a heavy line traversing a cut denotes non-identity, for
this reason, such a heavy line cannot be understood to denote one object. The
same holds for the graph of Fig.118 in 4.469: It denotes that the three ends
of the ligature do not stand for a single object. But ligatures which do not
traverse2 any cut. In the following, we will formal deﬁne ligatures which do
not traverse any cut. As we will prove that this ligatures can be understood to
denote a single object, they are called single-object ligatures. For example, the
ligature in the left graph below is a single-object ligature, while the ligature
in the right graph is not.

Now we have to formally deﬁne single-object ligatures for EGIs.

2 A ligature traverses a cut c if there is a heavily drawn line l being a part of the
ligature both such that both endpoints of l are placed on c and the remainder of
l is enclosed by c.

loves12olduglysmartyoungugly180

16 Improving the Handling of Ligatures

Deﬁnition 16.8 (Single-Object Ligatures). Let (W, F ) be a ligature of
the EGI G := (V, E, ν, >, Cut, area, κ). Then it is called a single-object
ligature, iﬀ

• there are no (not necessarily diﬀerent) w1, w2 ∈ W and an identity-link

f ∈ F with w1 f w2, f < w1 and f < w2,

• there are no w1, w2, w ∈ W and f1, f2 ∈ F with w1 6= w2, w1 f1 w f2 w2,

w < w1 and w < w2, and

• there are no w1, w2 ∈ W which are part of a cycle in (W, F ) and for which

we have w2 < w1.

Recall how the graphical representations of EGIs are converted to Peirce’s
Beta graphs, as it has been described on page 133. A ligature in an EGI is
converted to a network of heavy lines, and this network crosses each cut-line
almost once if and only if the ligature is a single-object ligature. To see an
example for this deﬁnition, consider the following Peircean Beta graph:

This graph has the meaning ‘there is an object (with property) P which is
distinct from all all objects (with property) Q’. The ligature traverses the
inner cut. The following two EGIs are possible formalizations of this graph:

In the left graph, the ligature is not a single-object ligature, as it violates the
ﬁrst condition of Def. 16.8. Similarly, in the right graph, the ligature violates
the second condition of Def. 16.8.

To see why the third condition of Def. 16.8 is needed, consider the following
two examples:

G1 :=

G2 :=

A single-object ligatures still may contain cycles, as long as all vertices and
edges of a cycle are placed in the area of single context. The ligature of G1
is a single-object ligature, as all vertices and edges are placed on the sheet
of assertion, i.e., the are placed in the same context. Even this ligature denotes a single object. But G2 violates the third condition, and indeed, in the
corresponding Peircean Beta graph, the ligature crosses the cut-line twice.

PQQPQPQPQP16.2 Improving the Reading of Ligatures

181

Nonetheless, this graph can be transformed with the rule ‘splitting a vertex’
into the semantically equivalent graph

,

thus we see that in G2, the ligature denotes a single object as well. Being a
single-object ligature is thus a suﬃcient, but not necessary condition to stand
for a single object.

Let us ﬁrst ﬁx a simple fact about single-object ligatures. Let (W, F ) be a ligature in an EGI G := (V, E, ν, >, Cut, area, κ). Let wa, wb be two vertices of W .
As (W, F ) is connected, there are w1, w2, . . . , wn ∈ W and f1, f2, . . . , fn−1 ∈ F
with wa = w1 f1 w2 f3 . . . wn−1 fn−1 fn = wb. Due to Def. 16.8, there can be
no k ∈ {w1, w2, . . . , wn, f1, f2, . . . , fn−1} with k < wa and k < wb. From this
we immediately obtain that the set of context {ctx(w) | w ∈ W } contains a
greatest element. In the following, this element is denoted by ctx(W, F ).

In Lem. 16.3 we have proven that ligatures which are wholly placed in one
context can be retracted to a single vertex. Thus, in the light of Lem. 16.3, such
ligatures can be understood to denote a single object. Now we can extend this
lemma to the following lemma which states that even single-object ligatures
can retracted to a single vertex. Thus this lemma, which is an extension of
Lem. 16.3, elaborates mathematically why and how single-object ligatures can
be understood to denote a single object.

Lemma 16.9 (Retracting a Single-Object Ligature). Let a EGI G be
given and let (W, F ) be a single-object ligature of G. Let w0 ∈ W be a vertex
with ctx(w0) = ctx(W, F ). Let G0 be obtained from G by retracting (W, F )
to w0 (the formal deﬁnition of G0 is exactly like in Lem. 16.3, where the
condition that (W, F ) is placed in a single context is dropped). Then G and
G0 are syntactically equivalent.

Proof: The proof is carried out in two steps.

Assume ﬁrst that (W, F ) contains a ligature (W , F ) (i.e. (W , F ) is a subgraph
of (W, F )) which is wholly placed in a context c. Then, with Lem. 16.3, we can
retract (W , F ) to a single vertex w (if we have w0 ∈ W , we have to choose w :=
w0, as we want to ﬁnally retract (W, F ) to w0). As this transformation does
not change the context of w or any other vertex or edge which does not belong
to W ∪ F , the remaining ligature (W \W ∪ {w}, F \F ) is still a single-object
ligature in the graph we obtain. We perform this transformation as often as
necessary until we obtain a graph G1 := (V1, E1, ν1, >1, Cut1, area1, κ1) and
single-object ligature (W1, F1) which does not contain any non-trivial ligatures
(i.e., ligatures which contain an edge) which are placed within a single context.

PQ182

16 Improving the Handling of Ligatures

The ligature (W1, F1) does not contain any cycles: Circles contained in one
context have just been retracted, and circles which are not completely contained in one context cannot occur due to the third condition of Def. 16.8.
Analogously (now with the ﬁrst condition of Def. 16.8), the ligature (W1, F1)
does not contain any loops. Thus (W1, F1) is a tree (in the graph-theoretical
sense). Particularly, we we have |W1| = |F1| + 1.
The tree (W1, F1) can be understood as a tree in the order-theoretical understanding as well, which now shall be elaborated. For two vertices w, w0 ∈ W ,
we set

w v w0 :⇐⇒ if there are w1, . . . , wn ∈ W1, f1, . . . , fn−1 ∈ F1

with w = w1 f1 w2 . . . wn−1 fn−1 wn = w0
and ctx(w1) ≥ ctx(f1) ≥ ctx(w2) ≥ . . . ≥ ctx(wn)

This relation is trivially reﬂexive, it is anti-symmetric, as we have to two different vertices which are placed in the same context and which are linked with
an identity edge, and at two comparable elements, they are graph-theoretically
connected in the tree (W1, F1), the order v is a tree with g0 as greatest element.

Assume F1 6= ∅ (otherwise we are ﬁnished). Let w be a leaf of (W1, F1) (with
respect to v). Then, there exists exactly one vertex w0 ∈ W1 and exactly one
identity edge f ∈ F1 with w0 f w. Moreover, we have w0 > w. Thus, we can
merge w into w0 with the rule ‘merging two vertices’, and this transformation
rule removes w and f . The remaining ligature is still a tree, in the graphtheoretical as well as in the order-theoretical way. Thus, we can successively
merge the leafs of tree to decrease its size, until there is only one leaf left.
This must be the vertex w0, i.e. the graph we obtain is the desired graph G0.
Both transformations we used in this proof (applying Lem. 16.3 and merging two vertices) can be carried out in both directions, hence G and G0 are
2
equivalent.

In the following, an example for Lem. 16.9 and its proof shall be provided.
Consider the following EGI and the corresponding Peirce graph:

The ligature in the EGI is drawn unnecessarily complicated, but it is easy to
see that it is a single-object ligature. In the ﬁrst step of the proof, the part of
the ligature which is placed in the outermost cut is retracted. We obtain:

ROQPSROQPS16.2 Improving the Reading of Ligatures

183

In the next step, the remaining vertices (it is only one) are merged into the
vertex of the ligature which is placed in the outermost cut. In this step, we
get:

After the last step, the whole ligature is retracted to a single vertex. So we
see that the graph we obtain, thus the starting graph as well, can be read as
follows: ‘Each object which has the properties O, P and Q and which stands
in relation R to itself stands in relation S to itself as well’.

If a ligature is not a single-object ligature, it can be divided into single-object
ligatures. This shall be elaborated now.

To separate a non-single-object ligature into several single-object ligatures, a
simple technical trick is used: We add further identity-relations to our alphabet, and the relation symbols will be used to break up a ligature.

Let A be an arbitrary alphabet. For each k ≥ 2, we add k-ary identityrelation .=k to A. The resulting alphabet shall be denoted by A=. The symbol
.=k shall be interpreted in the models as the k-ary identity-relation IdU
k on
U , i.e. we extend the relational structures (see Def. 13.1) as follows: For the
interpretation function I and each k ≥ 2, we set

.

k

IdU

k := {(u1, u2, . . . , uk) ∈ U k | u1 = u2 = . . . = uk} and IR( .=k) := IdU
Of course, the relations we assign to .= and .=2 coincide. The mere diﬀerence
.=2 is treated like any other relation symbol, i.e.,
is that in EGs, the symbol
it well explicitely written in any diagrammatic representation of an EGI (this
will become clear immediately).
A star of arity n with center v in the context c is a ligature (W, F )
with W = {w, w1, . . . , wn} such that all w, w1, . . . , wn are pairwise distinct,
F = {f1, . . . , fn}, w f1 w1, w f2 w2, . . . ,w fn wn, c = ctx(w) = ctx(f1) = . . . =
ctx(fn), c ≤ ctx(w1), . . . , ctx(wn) and w is in the graph only incident with
f1, . . . , fn. If we omit the cut-lines from possibly existing cuts between c and
the contexts of the vertices wi, a star can graphically be depicted as follows:

SRQPOSRQPORQPOSRQPOS184

16 Improving the Handling of Ligatures

The basic idea to break up ligatures is to replace the center of an n-ary star
by an n-ary identity relation .=n. That is, we remove w0 and the identity
edges f1, . . . , fn from c, and we insert a new n − ary edge f into c with
ν(f ) := (w1, . . . , wn) and κ(f ) := .=n. The resulting graph can be depicted as
follows:

In the following, this transformation will be called separating a ligature
at the vertex v It may be carried out in the other direction as well: Then
we will say that we join ligatures at the edge f ’. The soundness of
these transformations is easy to see, formally it it proven analogously to the
soundness of the transformation rules for ligatures (see Lem. 13.9). Moreover,
with this transformation, it is possible to transform each graph over an alphabet A= into an semantically equivalent graph over A as follows: If an
edge f = (w1, . . . , wn) labeled with .=n is given, using the transformation rule
‘adding a vertex to a ligature’, we insert a new vertex and a new identity edge
between each vertex wi and the corresponding hook (f, i); then we can join
the ligatures at the edge f . For this reason, once we have proven the soundness
and completeness of the calculus for EGIs over A, the calculus together with
the transformation rules ‘separating a ligature at the vertex v’ and ‘joining
ligatures at the edge f ’ is sound and complete for EGIs over A=.
Introducing the relation-symbols .=n is a simple technical means to make
clear how a non-single-object ligature is separated into several single-object
ligatures. Particularly, this means helps to better understand the meaning
of Peirce’s graphs. This shall be exempliﬁed now. We start with the well
known graphs of Fig. 16.1, whose meanings have already been investigated in
Chpt. 11, p. 11.3 ﬀ.

We have already discussed in Chpt. 11 that the left EGI of the Fig. 16.2 is the
best readable formalization of the left Peirce graph in Fig. 16.1. Moreover, in
the investigation of the right graph of Fig. 16.2 (see p. 116,) I have written
.=3 for teridentity the graph could even simpler be
that ‘if we had a symbol
formalized as follows:’, and provided the right graph of Fig. 16.2.

w1w2w3w4wnww1w2w3w4wnn16.2 Improving the Reading of Ligatures

185

Fig. 16.1. Two Peirce graphs with non-single-object ligatures

Fig. 16.2. Two EGIs where the ligatures are split into single-object ligatures

The introduction of the new identity symbols .=3 is now a precise means for
expressing teridentity as a relation. This means can be used for the corresponding EGs as well, i.e., the Peirce graphs of Fig. 16.1 are equivalent to
the Peirce graphs of Fig. 16.3. In these graphs, all ligatures are single object
ligatures, thus they are probably easier to understand.

Fig. 16.3. Separating the ligatures of the graphs of Fig. 16.2

It should be noted that a separation of a non-single-object ligature into several
single-object ligatures is not uniquely determined. In order to see this, consider
the graph of Fig. 16.4.

Fig. 16.4. A further Peirce graph with a non-single-object ligature

The ligature of the graph of Fig. 16.4 can be separated in diﬀerent ways. Five
possible separations are provided in Fig. 16.5.

These diﬀerent separations yield the following diﬀerent readings of the graph
of Fig. 16.4:

33OPQ186

16 Improving the Handling of Ligatures

Fig. 16.5. Possible separations of the ligature of the graph of Fig. 16.4

1. There are objects O, P , Q such that Q is not (simultaneously) identical

to O and P .

2. There are objects O, P , Q such that P is not (simultaneously) identical

to O and Q.

3. There are objects O, P , Q such that O is not (simultaneously) identical

to P and Q.

4. There are objects O, P , Q such that there is no forth object which is

(simultaneously) identical to O, P and Q.

5. There are objects O, P , Q which are not all identical to each other.

We see that diﬀerent separations of a non-single-object ligature yield diﬀerent,
semantically equivalent readings of the graph.3

Let us consider a more complex example, provided in Fig. 16.6:

Fig. 16.6. A Peirce graph with the meaning ‘there are exactly three things’

The ligature in this graph traverses six cuts completely, thus it is to a large
extent a non-single-object ligature. If we separate this ligature in each cut it
traverses, we obtain the graph of Fig. 16.7.

3 So-called ‘multiple readings’ of a graph are extensively discussed by Shin in
[Shi02a], where she argues that this is one of the main features of diagrams humans beneﬁt from.

OPQOPQOPQOPQOPQ316.2 Improving the Reading of Ligatures

187

Fig. 16.7. Separating the ligature of the graph of Fig. 16.6

Now we see that the graph of Fig. 16.6 can be read as follows: There are three
pairwise distinct things, but there does not exists a fourth object which is
distinct to all of these three things. In short: There are exactly tree things.

The examples above show how Lem. 16.9 and the transformation rules ‘separating a ligature at the vertex v’ and ‘joining ligatures at the edge f ’ can be
used to read and understand complex ligatures in an EGI or in a Peirce graph
by separating them into several single-object ligatures.

Finally, with the results of this chapter, it is possible to link this treatise, esp.
the formalization of EGIs, to a diﬀerent kind of formalizations of diagrammatic
logic systems, which has carried out by some authors. We introduced new
relation symbols .=n which were used to separate ligatures. It is important
to note that in transformation rule ‘separating a ligature at the vertex v’, a
vertex is, roughly speaking, replaced by an edge. If we had added a relation
.=1 as well, we could even replace a vertex which is incident only with
symbol
one identity edge by an edge. This gives raise to the following observation:
It is possible to provide a diﬀerent formalization for EGIs which switches
the role of edges and vertices. That is, it is possible to provide a technical
deﬁnition for EGIs where vertices stand for the relations in a Peirce graph,
and the edges model only the heavily drawn lines of a Peirce graph. As it has
already been mentioned in 11, approaches of this kind have been undertaken
by Pollandt in [Pol02] or Hereth Correia and P¨oschel in [HCP04, HCP06],
where Peirce’s relation graphs are investigated, or by Chein and Mugnier for
conceptual graphs in [CM92, CM95], which are a diagrammatic logic system
based on Peirce’s beta graphs (but which do not include a means to express
negation).

17

Soundness of the Calculus

Like in the proof for the soundness of the calculus in the Alpha part of this
treatise, the main concept for this proof is the concept of an isomorphism
except a context (see Defs. 7.11 and 12.12).

Lemma 17.1 (Erasure and Insertion are Sound). If G and G0 are two
EGIs, M := (U, I) is a relational structure with M |= G and G0 is derived
from G by applying the rule ‘erasure’ or ‘insertion’, then M |= G0.

Proof: We only show the soundness of the erasure-rule; the proof for the
insertion-rule is done analogously.

Let G0 := (V0, E0, ν0, >0, Cut0, area0) be the subgraph which is erased. G0
is erased from the area of the positive context c := >0. Obviously, G and G0
are isomorphic except for the context c by the (trivial) identity mapping. Let
ref be a partial valuation for c such that M |=endo G[c, ref ]. It is easy to see
that we have M |=endo G0[f (c), ref ]. So the property P of Lemma 13.7 holds
2
for c, hence Lemma 13.7 can be applied. This yields the proposition.

Next, we show the soundness of the double-cut rule.

Lemma 17.2 (Double Cut is Sound). If G and G0 are two EGIs, M :=
(U, I) is a relational structure with M |= G and G0 is derived from G by
applying the rule ‘double cut’, then M |= G0.

Proof: Let G and G0 be two EGIs such that G is derived from G0 by erasing
two cuts c1, c2 with area(c1) = {c2}. We set c := ctx(c1). We want to apply
Lemma 13.8 and therefore have to show that property P of Lemma 13.8 is
valid for c ∈ G and c ∈ G0. We have

We have

area0(c) = (area(c) ∪ area(c2))\{c1}

(∗)

Let ref be a partial valuation for c. With (∗) we get

190

17 Soundness of the Calculus

M |= G[c, ref ]

Def. |=

⇔ ref can be extended to an extended partial valuation ref for c such that

ref fulﬁlls all edge- and cut-conditions of area(c)

⇔ ref can be extended to an extended partial valuation ref for c such that

ref fulﬁlls all edge- and cut-conditions of area(c)\{c1} and M 6|= G[c1, ref ]

⇔ ref can be extended to an extended partial valuation ref for c such that

ref fulﬁlls all edge- and cut-conditions of area(c)\{c1} and M |= G[c2, ref ]

⇔ ref can be extended to an extended partial valuation ref for c such that

ref fulﬁlls all edge- and cut-conditions of area(c)\{c1} and

ref can be extended to an extended partial valuation ref for c2 such that

ref fulﬁlls all edge- and cut-conditions of area(c2)

(∗)
⇔ ref can be extended to an extended partial valuation ref for c such that

M fulﬁlls all edge- and cut-conditions of area0(c)

Def. |=

⇔ M |= G0[c, ref ]

Now Lemma 13.8 yields that we have M |= G ⇐⇒ M |= G0.

2

Unfortunately, the proof for the soundness of the rules iteration and its counterpart deiteration is much more complex than in the Alpha-part of this treatise. The main reason is the following: Let G0 be a subgraph of a graph G
which is iterated into a context c. Particularly, new vertices are added to c.
When we now evaluate the graph in a model with the endoporeutic method
of Peirce, we have to assign objects to these vertices. The assignment of the
‘right’ objects will depend on which objects we have already assigned to vertices which are placed in the same or higher context as the new vertices. But
the new vertices are copies of already existing vertices (their origins of G0).
Each time when we reach the new vertices while performing the endoporeutic
method, we have already assigned objects to their origins. It turns out that
we should assign the same objects to the old and new vertices to gain that
the old and the new graph become equivalent. This idea is worked out in the
proof for the following lemma.

Lemma 17.3 (Iteration and Deiteration are Sound). If Ga and Gb are
two EGIs, M := (U, I) is a relational structure with M |= Ga and Gb is
derived from Ga by applying the rule ‘iteration’ or ‘deiteration’, then M |= Gb.

Proof: In this proof, we use the notation of the formal deﬁnition of the iteration/ deiteration-rule on page 166. Particularly, we assume that Gb is derived
from Ga by iterating the subgraph G0 from the cut c0 into the cut c.

17 Soundness of the Calculus

191

First of all, if we consider the canonical mapping f which is deﬁned by f (k) =
(k, 1) for k ∈ Ea ∪ Cuta, then Ga and Gb are isomorphic up to c0 := >0 and
(c0, 1) by f . They are even isomorphic up to c and (c, 1).
The proof of this lemma will be based on Lemma 13.8. We start with some
deﬁnitions which are needed in the proof.

1. Let refa : V 0

a → U be a partial valuation for Ga. Then refa can canonically
be transferred to a partial valuation refa→b for Gb as follows: We set
a→b := {(v, 1) ∈ Vb | v ∈ V 0
V 0
a}

a ∩ V0} and

.
∪ {(v, 2) ∈ Vb | v ∈ V 0
( V 0

a→b → U
(v, i) 7→ refa(v)

refa→b :

Please note that this can be considered to be an extension of Def. 13.6.
Particularly, if refa is a partial valuation for a context d with d (cid:2) c, we
have refa→b = f (refa).
Analogously, for a partial valuation refb : V 0
{v ∈ Va | (v, 1) ∈ V 0
b } and

b → U for Gb, we set V 0

b→a :=

refb→a :

( V 0

b→a → U

v 7→ refb((v, 1))

Again, if refb is a partial valuation for a context (d, 1) (with d ∈ Cuta,
hence (d, 1) ∈ Cutb) with (d, 1) (cid:2) (c, 1), we have refb→a = f −1(refb).
2. To ease the terminology in this proof, we will use the notation of entailment for extended partial valuations for a context c as well, i.e., if c is a
context and ref is an extended partial valuation for c, we write

M |=endo G[c, ref ] :⇐⇒

• ref (e) ∈ I(κ(e)) for each e ∈ E ∩ area(c) (edge condition))
• M 6|=endo G[d0, ref ] for each d0 ∈ Cut ∩ area(d) (cut condition))

Now we are prepared to start with the proof.

First we will show the following:

If refa is an extended partial valuation for c0 with
M |=endo Ga[refa, c0] , then M |=endo Gb[refa→b, (c0, 1)]
If refb is an extended partial valuation for (c0, 1) with
M |=endo Gb[refa, (c0, 1)] , then M |=endo Ga[refb→a, c0]

(17.1)

(17.2)

Assume that Eqn. (17.1) and Eqn. (17.2) hold. We want to apply Lemma 13.8
to Ga, c0 and Gb, (c0, 1), so let ref be a partial valuation for c0. If we
have M |=endo Ga[ref, c0], then ref can be extended to a extended partial valuation refa with M |=endo Ga[refa, c0]. Now Eqn. (17.1) yields

192

17 Soundness of the Calculus

M |=endo Gb[refa→b, (c0, 1)]. Furthermore we have that refa→b is an extension
of f (ref ). Thus we conclude M |=endo Gb[f (ref ), (c0, 1)]. Vice versa, using
Eqn. (17.2), we have the following: If we have M |=endo Gb[f (ref ), (c0, 1)],
we obtain M |=endo Ga[ref, c0]. Both cases together yield that property P of
Lemma 13.8 holds for c0. Now Lemma 13.8 yields

M |=endo G ⇐⇒ M |=endo G0

,

which shows the soundness of both the iteration- and deiteration-rule.

It remains to show that Eqn. (17.1) and Eqn. (17.2) hold. The proof for this
is carried out by distinguish two cases.

First case: c = c0
We start with the proof of Eqn. (17.1), so let refa be an extended partial
valuation for c0 with M |=endo Ga[refa, c0]. In the context (c0, 1) of Gb we
have

1. the edges (e, 1) and cuts (d, 1) which correspond to the edges and cuts in

the context c0 of Ga,

2. the edges (e, 2) and cuts (d, 2) which correspond to the edges and cuts in

the context c0 of G0, and

3. further identity edges ev,w = ((w, 1), (v, 2)) for vertices v ∈ V0, w ∈ area(c0)

with wΘv.

Let e = (v1, . . . , vn) ∈ areaa(c0) be an edge. Due to M |=endo Ga[refa, c0],
we have refa(e) = (refa(v1), . . . , refa(vn)) ∈ I(κa(e)). Then we have

refa→b((e, 1))

=
Def.refa→b=
∈
=

(refa→b((v1, 1)), . . . , refa→b((vn, 1)))

(refa(v1), . . . , refa(vn))
I(κa(e))
I(κb((e, 1)))

Thus we see that the edge-conditions for edges (e, 1) which correspond to the
edges in the context c0 of Ga are fulﬁlled. Analogously, it is easy to see that the
edge-conditions for edges (e, 2) which correspond to the edges in the context
c0 of G0 the cut-conditions for cuts (d, 1) which correspond to the cuts in the
context c0 of Ga, and the cut-conditions for cuts (d, 2) which correspond to
the cuts in the context c0 of G0, are fulﬁlled as well.
It remains to show that the edge-conditions for the further identity links ev,w
are satisﬁed, too. Let ev,w = ((w, 1), (v, 2)) with v ∈ V0, wΘv and w ∈ area(c)
be such a link. Then there are (in Ga) vertices v1, . . . , vn with w = v1, vn = v,
ctx(v1) = ctx(v2) = . . . ctx(vn) = c0, and for each 1 ≤ i ≤ n − 1, there is an
identity edge ei from vi to vi+1. Let 1 ≤ i ≤ n − 1. As ei ∈ area(c0), we have –
again due to M |=endo Ga[refa, c0]– refa(vi) = refa(vi+1). Analogously to the

17 Soundness of the Calculus

193

argumentation above, we conclude refa→b((v, 1)) = refa→b((w, 1)). Moreover,
we have refa→b((v, 1)) = refa→b((v, 2)) by deﬁnition of refa→b. Thus we
get refa→b((w, 1)) = refa→b((v, 2)), i.e., the edge-condition for the further
identity-link ev,w in Gb is satisﬁed as well, which ﬁnally proves Eqn. (17.1).
The proof of Eqn. (17.2) is now obvious: Let refb is an extended partial
valuation for (c0, 1) in Gb with M |=endo Gb[refa, (c0, 1)]. To each cut d and
edge e in areaa(c0) corresponds the edge (e, 1) and (c, 1) in areab((c0, 1)),
and it can analogously to the proof of Eqn. (17.1) shown that refb→a satisﬁes
the edge- and cut-conditions for these edges and cuts in areaa(c0). Roughly
speaking: Compared to areab((c0, 1)), in areaa(c0) are less edge- and cutconditions to check. This yields M |=endo Ga[refb→a, c0], hence Eqn. (17.2)
is fulﬁlled.

Second case: c < c0
In contrast to the case c = c0, the edges and cuts in areaa(c0) correspond
bijectively to the edges and cuts in areab((c0, 1)). Particularly, if refa is an
extended valuation for c0, we have (refa→b)→a = refa, and vice versa, if refa
is an extended valuation for (c0, 1), we have (refb→a)→b = refb. Thus, instead
of proving Eqn. (17.1) and Eqn. (17.2), it is suﬃcient to show that for each
extended partial valuation ref0a for c0 we have

M |=endo Ga[ref0a, c0] ⇐⇒ M |=endo Gb[ref0a→b, (c0, 1)]

(17.3)

So let ref0a be an extended partial valuation for c0. Let d0 ∈ areaa(c0) be the
cut with c ≤ d0. The following is easy to see: The valuation ref0a satisﬁes the
edge-conditions for all edges e ∈ areaa(c0) and the cut-conditions for all cuts
d ∈ area(a) with d 6= d0 if and only if ref0a→b satisﬁes the edge-conditions for
all (corresponding) edges (e, 1) ∈ areab((c0, 1)) and the cut-conditions for all
(corresponding) cuts (d, 1) ∈ area(a) with (d, 1) 6= (d0, 1). It remains to show
that ref0a satisﬁes the cut-condition for d0 if and only if ref0a→b satisﬁes the
cut-condition for (d0, 1). Moreover, we can assume that

ref0a satisﬁes the edge-conditions for all edges e ∈ areaa(c0)
and the cut-conditions for all cuts d ∈ area(a) with d 6= d0

(17.4)

(otherwise M 6|=endo Ga[ref0a, c0] and M 6|=endo Gb[ref0a→b, (c0, 1)], hence,
Eqn.17.3 is satisﬁed in this case).

We set D := {d ∈ Cuta ∪ {>a} | d ≤ d0 and d 6< c}. In Fig. 17.1 we have
sketched one possible situation.

Let Q(d) be the following property for contexts d ∈ D:

194

17 Soundness of the Calculus

Fig. 17.1. The situation when a subgraph is iterated from c0 into c

a → U with refa ⊇ ref0a is an extended partial valuation for

1. If refa : V 0
d, then
a) there is a context d0 with d < d0 ≤ c0 and an edge e ∈ areaa(d0)
such that refa(e) /∈ I(κa(e)), i.e., the edge-condition is not satisﬁed
for e, or
b) we have

M |=endo Ga[d, refa] =⇒ M |=endo Gb[(d, 1), refa→b]

2. If refb : V 0

b → U with refb ⊇ ref0a→b is an extended partial valuation

for (d, 1), then

M |=endo Gb[(d, 1), refb] =⇒ M |=endo Ga[d, refb→a]

Assume that we have already shown that Q(d) is satisﬁed for each cut
d ∈ area(c). Particularly, we have Q(d0). Note that, due to Eqn. 17.4, the
condition Q(d0)1.a) cannot be fulﬁlled. If ref0a satisﬁes the cut-condition
for d0, then ref0a cannot be extended to an extended partial valuation refa
for d0 with M |=endo Ga[d0, refa]. The contraposition of Q(d0).2 yields that
ref0a→b cannot be extended to an extended partial valuation refb for (d0, 1)
with M |=endo Gb[(d0, 1), refb], i.e., ref0a→b satisﬁes the cut-condition for
(d0, 1). Vice versa, using the contraposition of Q(d0).1, we obtain that, if
ref0a→b satisﬁes the cut-condition for (d0, 1), then ref0a satisﬁes the cutcondition for d0. Thus, we would be done. Hence, it is now suﬃcient to show
that Q(d) holds for each d ∈ D. This will be done in the remaining part of
the proof.

D is a forest such that for each d ∈ Cutc with d 6= c, then all cuts e ∈ area(d)
are elements of Cutc as well. Thus we can, similar to the proof of Lemma 13.7,
carry out the proof by induction over D. But now, we have to show separately

0c0d(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:2)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:3)(cid:4)(cid:4)(cid:4)(cid:4)(cid:5)(cid:5)(cid:5)(cid:5)Ddom(ref    )0acthat Q(c) holds. So, in order to prove Q(d), we distinguish between d = c and
d 6= c.

17 Soundness of the Calculus

195

• d = c

We start with the proof of 1.
Let refa : V 0
a → U be an extended partial valuation for c with refa ⊇
ref0a. We suppose that condition a) is not satisﬁed (otherwise we are
done), thus we have M |=endo Ga[c, refa].
First we show:

If w1 ∈ area(c0), w2 ∈ area(c) are two vertices with w1Θw2 ,
then refa(w1) = refa(w2) .

(17.5)

Let w1 ∈ area(c0) and w2 ∈ area(c) be two vertices with w1Θw2. Then
there are vertices v1, . . . , vn with w1 = v1, vn = w2, c = ctx(v1) ≥
ctx(v2) ≥ . . . ≥ ctx(vn) = c0, and for each 1 ≤ i ≤ n − 1, there is an
identity edge ei from vi to vi+1. Let 1 ≤ i ≤ n − 1. We have c0 ≥ ctx(vi) ≥
ctx(ei) = ctx(vi+1) ≥ c. For ctx(e) > c, then, as condition a) is not satisﬁed, we conclude refa(vi) = refa(vi+1). For ctx(e) = c, then, as ref0a
satisﬁes all edge-condition in c0, we conclude again refa(vi) = refa(vi+1).
So we have refa(w1) = refa(v1) = refa(v2) = . . . = refa(vn) = refa(w2),
which proves Eqn. (17.5).

We have to show M |=endo Gb[(c, 1), refa→b], i.e., we have to check the
edge- and vertex-conditions in areab((c, 1)). In areab((c, 1)) we have:
1. Edges (e, 1) and cuts (d, 1) which correspond to the edges and cuts
in the context c of Ga. Due to M |=endo Ga[c, refa], the edge- and
cut-conditions for these edges and cuts are fulﬁlled.

2. Edges (e, 2) and cuts (d, 2) which correspond to the edges and cuts in
the context c0 of G0. Due to Eqn.17.4. The edge- and cut-conditions
for these edges and cuts are fulﬁlled.

3. Further identity edges ev,w = ((w, 1), (v, 2)) with v ∈ V0, wΘv and
w ∈ area(c0). Due to Eqn. (17.5), the edge-conditions for these edges
are fulﬁlled.

We conclude M |=endo Gb[(d, 1), refa→b], hence we have shown that the
property Q(c).1 holds.

Similar to the case c = c0, it is easy to see that the property Q(c).2 holds
as well (again, we have to check less edge- and cut-conditions).

• d ∈ D, d 6= c.

We start with the proof of Q(d).1.

Let refa ⊇ ref0a be an extended partial valuation for d in Ga with
M |=endo Ga[d, refa]. Then refa→b is an extended partial valuation for

196

17 Soundness of the Calculus

(d, 1) in Ga. The edges e ∈ d correspond bijectively to the edges (e, 1)
in (d, 1), thus it is easy to see that the edge-conditions in areab((d, 1))
are satisﬁed by refa→b. It remains to show that the cut-conditions in
areab((d, 1)) hold as well. Each cut in areab((d, 1)) has the form (d0, 1)
with d0 ∈ areaa(d). So let (d0, 1) ∈ areab((d, 1)) be a cut.
We have to show M 6|=endo G[refa→b, (d0, 1)]. Assume that we have
M |=endo G[refa→b, (d0, 1)]. Then there is an extended partial valuation
refa→b for (d0, 1) with refa→b ⊇ refa→b and M |= Gb[refb, (d0, 1)]. Obviously, refa := refa→b→a is an extended partial valuation for d0 with refa ⊇
refa, and the induction hypothesis Q(d0), 2. yields M |=endo Ga[d0, refa],
hence M |=endo Ga[d0, refa], which contradicts M |=endo Ga[d, refa].
Thus 1. is shown.

The proof of of Q(d).2. is done analogously.

As we shown that Q(d) holds for each d ∈ area(c), we are done.

2

Like in the Alpha part, we obtain from the preceding lemmata (which show
that each rule of the calculus is sound) and Thm. 13.10 (which shows that the
transformation-rules are sound) the soundness of the Beta-calculus.

Theorem 17.4 (Soundness of the Beta-Calculus). For each set H ∪ {G}
of EGIs over A we have

H ‘ G =⇒ H |= G

Proof: Analogous to the proof of Thm. 9.5.

18

First Order Logic

In the next chapters, the correspondence between Beta graphs and the symbolic form of ﬁrst order predicate logic is elaborated. This will be done by
providing translations between Beta graphs and formulas of FO. There are
many calculi for FO from which it is well-known that they are sound and
complete. Proving that a logic system with the expressiveness of ﬁrst order
logic is complete is somewhat extensive. For this reason, in contrast to Alpha,
the completeness of Beta will not be shown directly. Instead of this, using the
translations between graphs and formulas, the completeness of FO can be
transferred to the system of existential graphs.

Showing the correspondence between Beta and FO and using the completeness of FO are two good reasons to employ translations between Beta and
FO. Nonetheless, there are many diﬀerent styles of FO. In this chapter, the
the style of FO we will use in the rest of this treatise is presented.

18.1 Syntax

We start with the deﬁnition of the well-formed formulas of FO.

Deﬁnition 18.1 (Formulas).
inﬁnite set of signs.1 The elements of Var are called variables.

Let Var := {x1, x2, x3, . . .} be a countably

The formulas of FO over A and the set FV(f ) of free variables of a formula
f , and the set Subf orm(f ) of subformulas of f are inductively deﬁned as
follows:2

1 We will use the letters x, y, u, v for variables, too. Furthermore we will use the

Greek letter ‘α’ to denote variables, i.e. ‘α’ is a metavariable.

2 Note that we do not have object names or function names, therefore we do not
need to deﬁne terms. But we will come back in Chpt. 23, where EGIs are augmented with object and function names, to this issue.

198

18 First Order Logic

1. If R ∈ R is a relation name with arity n and α1, . . . , αn are variables,

then f := R(α1, . . . ,αn) is a formula.3
- FV(f ) := FV(α1) ∪ . . . ∪ FV(αn), Subf orm(f ) := {f } .

2. If f 0 is a formula, then f := ¬f 0 is a formula.

- FV(f ) := FV(f 0), Subf orm(f ) := Subf orm(f 0) ∪ {f }.

3. If f1 and f2 are formulas, then f := (f1∧f2) is a formula.

- FV(f ) = FV(f1)∪FV(f2), Subf orm(f ) := Subf orm(f1)∪Subf orm(f2)∪
{f } .

4. If f 0 is a formula and α is a variable, then f := ∃α.f 0 is a formula.

- FV(f ) := FV(f 0)\{α}, Subf orm(f ) := Subf orm(f 0) ∪ {f } .

If f is a formula with FV(f ) = ∅, then f is said to be closed. A closed
formula is also called a sentence.

.= α2 or α1 = α2 instead of

For some dyadic relation names R, esp. for ‘R = .= ’, we will use the inﬁxnotation instead of the preﬁx-notation, i.e., we will write α1Rα2 instead of
.=
R(α1, α2) (in particular, we will write α1
(α1, α2)).
Keep in mind that we use an identity-relation in the formulas of FO as well
as in the metalanguage. We distinguish these two levels of identity by using
the symbol ‘ .=’ for the identity on the syntactical level (in formulas as well as
in graphs) and by using symbol ‘=’ to denote the identity on the meta-level.
In some cases we try to ease the reading by using diﬀerent spaces around ‘=’
.= x5’, the ﬁrst ‘=’ is a
.=. For example, in ‘f = x3
and by using the symbol
metalevel sign, and the second ‘ .=’ is a sign in FO. So the string ‘f = x3
.= x5’
.= x5’.
means that f is the formula ‘x3
The remaining junctors (i.e., ∨, → and ↔) and the remaining quantiﬁer ∀ are
deﬁned as usual: We set

• f1 ∨ f2 := ¬(¬f1 ∧ ¬f2) ,
• f1 → f2 := ¬(f1 ∧ ¬f2) ,
• f1 ↔ f2 := ¬(f1 ∧ ¬f2) ∧ ¬(f2 ∧ ¬f1) , and
• ∀α.f := ¬∃α.¬f .

3 In this deﬁnition, we have underlined the signs which have to be understood
literally. For example, when we write f := R(α1, . . . ,αn), this means that the
formula f is deﬁned to be the following sequence of signs: We start with the
relation name which is denoted by R. Please note that ‘R’ is not a relation name,
but it is a metavariable which stands for a relation name. After R, we proceed
with the sign ‘(’. After that, we write down the variable which is denoted by α1
(thus, α1 is a metavariable, too). We proceed with the sign ‘,’. After that, we
write down the variable which is denoted by α2, proceed with the sign ‘,’, and so
on until we write down the variable is denoted by αn. Finally, we write down the
sign ‘)’.

18.1 Syntax

199

This shall be read as an abbreviation: e.g. when we write f1 → f2, we can
replace this by ¬(f1 ∧ ¬f2) to get a formula in our language.
Brackets are omitted or added to improve the readability of formulas. To avoid
an overload of brackets, we agree that formulas which are composed with the
dyadic junctor → are bracket from the right, e.g. f1 → f2 → f3 has to read as
(f1 → (f2 → f3)). Furthermore we agree that quantiﬁers bind more strongly
than binary junctors.

It will turn out later (especially in Def. 18.4) that it is important to distinguish
between subformulas and subformula occurrences of a formula f . For
example, the formula f := >(x) ∧ >(x) has only two subformulas, namely
>(x) and f itself. But the subformula >(x) occurs twice in f , hence we have
three subformula occurrences in f (two times >(x) and f itself).

Deﬁning subformula occurrences is a rather technical problem, thus, we do
not provide a deﬁnition for them, but we want to point out that it can be
done (for a further discussion we refer to [vD96]). Of course, this is the same
for variables: A variable t can appear several times in a formula f , and all
these appearances are called occurrences of t in f .

Next we deﬁne substitutions.

Deﬁnition 18.2 (Substitutions).
Let α ∈ Var be a variable and let
xi ∈ Var be a variable. Furthermore, let α1, α2, . . . denote variables and
f, f 0, f1, f2, . . . denote formulas. We deﬁne the substitutions f [α/xi] inductively as follows:

1. For a variable xj ∈ Var, let xj[α/xi] := xj for j 6= i, and xi[α/xi] := α.
2. If f := R(α1, . . . , αn), then f [α/xi] := R(α1[α/xi], . . . , αn[α/xi]).
3. If f := ¬f 0, then f [α/xi] := ¬f 0[α/xi].
4. If f := f1 ∧ f2, then f [α/xi] := f1[α/xi] ∧ f2[α/xi].
5. If f := ∃xj.f 0, j 6= i, then f [α/xi] := ∃xj.f 0[α/xi].
6. If f := ∃xi.f 0, then f [α/xi] := ∃xi.f 0.

We say that f [α/xi] is obtained from f by substituting α for xi in f .

A main diﬀerence between FO and EGI are the syntactical elements which
are used to range over objects. In EGI, only one sign, namely the LoI, is used
for this purpose. In FO we have a whole set Var of variables instead. All
variables are tantamount. For this reason the next well-known deﬁnition is
needed.

Deﬁnition 18.3 (α-Conversion of Formulas). Let f be a formula and let
∃α.h be a subformula of f . Let β be a (so called fresh) variable (i.e. we have
β /∈ Var(f )). Let f 0 be the formula that we get when we replace the subformula

200

18 First Order Logic

∃α.h by ∃β.h[β/α]. Then we say that we get f 0 from f by renaming a bound
variable (this is in literature often called α-conversion of a formula).

Example: Consider the formula

R(x) ∧ ∃x.S(x) ∧ ∃x.(R(x) ∧ ∃x.T (x))

If we replaced the ﬁrst bound occurrence of x – i.e., we consider the subformula
∃x.S(x) – by the variable y, we get the formula

R(x) ∧ ∃y.S(y) ∧ ∃x.(R(x) ∧ ∃x.T (x))

In this formula, consider the subformula ∃x.(R(x) ∧ ∃x.T (x)). We replace x
by u and get

R(x) ∧ ∃y.S(y) ∧ ∃u.(R(u) ∧ ∃x.T (x))

Finally, we replace the remaining bound variables x in ∃x.T (x) by v and get

R(x) ∧ ∃y.S(y) ∧ ∃u.(R(u) ∧ ∃v.T (v))

In formulas of FO, the set of all occurences of the negation sign ‘¬’ can be
treated like the set of all cuts in an existential graph. This motivates the next
deﬁnition:

Deﬁnition 18.4 (Structure of Formulas). Let f ∈ FO be a formula. We
set

Negf := {g ∈ FO | ¬g is a subformula occurrence of f }

Furthermore we set >f := f . The set Negf ∪ {>f } is ordered by

g ≤ h :⇐⇒ g is a subformula occurrence of h

The set Negf of a formula f is the counterpart of the set Cut of a graph G :=
(V, E, ν, >, Cut, area, κ), and Negf ∪ {>f } is the counterpart of Cut ∪ {>}.
To give an example, look at the following formula:

f := ∃x.(CAT (x) ∧ ¬slim(x) ∧ ¬(∃y.LASAGN E(y) ∧ see(x, y) ∧ ¬eat(x, y)))

The ordered set (Negf ∪ {>f }, ≤) can be sketched as follows:

∃x.CAT (x) ∧ ¬slim(x) ∧ ¬(∃y.LASAGN E(y) ∧ see(x, y) ∧ ¬eat(x, y))

(cid:0)(cid:0)
slim(x)

@@
∃y.LASAGN E(y) ∧ see(x, y) ∧ ¬eat(x, y)

eat(x, y)

18.2 Semantics

201

Another example is

g := ¬(¬>(x) ∧ ¬>(x))

This example shows that is is important to discriminate between subformulas
and subformula occurrences. The ordered set (Negg ∪{>g}, ≤) can be sketched
as follows:

¬(¬>(x) ∧ ¬>(x))

¬>(x) ∧ ¬>(x)
@@
>(x)

(cid:0)(cid:0)

>(x)

18.2 Semantics

The semantics of FO relies on the well-known relational structures which
have already been presented in Def. 13.1. We have to deﬁne how formulas are
evaluated in relational structures.

Deﬁnition 18.5 (Evaluation of Formulas in Structures). Let f ∈ FO
be a formula and let M = (U, I) be a relational structure. A valuation val
is a mapping val : V ar → U which assigns to each variable an element of the
universe U . Inductively over the structure of formulas, we deﬁne M |=val f
as follows:

1. If R ∈ Rn and if α1, . . . , αn are variables, then let M |=val R(α1, . . . , αn)

iﬀ (val(α1), . . . , val(αn)) ∈ I(R).

2. If f 0 is a formula and f := ¬f 0, then we set M |=val f iﬀ M 6|=val f 0 .
3. If f1 and f2 are formulas and f := f1 ∧ f2, then we set M |=val f iﬀ

M |=val f1 and M |=val f2 .

4. If f 0 is a formula, xi is a variable and f := ∃xi.f 0, then we set M |=val f
iﬀ there is a valuation val0 with val0(xj) = val(xi) for each i 6= j and
M |=val0 f 0.

If f is a formula and M is a relational structure such that M |=val f holds
for all valuations val, we write M |= f . If F is a set of formulas and f is
a formula such that each relational structure M with M |= g for all g ∈ F
satisﬁes M |= f , we write F |= f . We abbreviate {g} |= f by g |= f . Two
formulas f, g with f |= g and g |= f are called semantically equivalent.

202

18 First Order Logic

18.3 Calculus

In literature we ﬁnd a huge amount of calculi for ﬁrst order logic. For our
purpose it makes no diﬀerence which calculus we use. We decided to choose
a (so-called Hilbert-style) calculus. Carrying out proofs in this calculus is
arduous (for this reason, usually so called sequent calculi or natural deduction
calculi are preferred), but we will not use this calculus for proofs in this
treatise. Vice versa: We will have to carry over the rules of the calculus to
proofs for EGIs, and this turns out to be somewhat easy for this calculus.

The chosen calculus is is a calculus for the fragment of FO which is based
on the junctors → and ¬ instead of ∧ and ¬. This causes no troubles, as the
following argumentation will show:

Remember that we can express the junctor → by means of the junctors ∧
and ¬: We set f1 → f2 := ¬(f1 ∧ ¬f2) (and conversely, we can express the
junctor ∧ with the junctors → and ¬: We set f1 ∧ f2 := ¬(f1 → ¬f2)). If we
denote the set of formulas which use the symbols ∃, ¬, ∧ by FO∃,¬,∧ and if
we denote the set of formulas which use the symbols ∃, ¬, → by FO∃,¬,→, we
can translate each formula f ∈ FO∃,¬,∧ to a formula f ∗ ∈ FO∃,¬,→, and vice
versa. Of course we can deﬁne canonically the relation |= between relational
structures and formulas of FO∃,¬,→ as well. It is easy to show that we have

M |= f ⇐⇒ M |= f ∗

for all relational structures M and all formulas f ∈ FO∃,¬,∧. So we can
immediately carry over results from FO∃,¬,→ to FO∃,¬,∧ and vice versa. In
particular we will argue that the calculus we present is sound and complete
in FO∃,¬,→, hence it is sound and complete in FO∃,¬,→.
In Fig. 18.1 we list all axioms and rules for the FO-calculus we use in this
treatise. With this rules, we deﬁne the relation ‘ as follows:

Deﬁnition 18.6 (Proofs). Let F be a set of formulas and let f be a formula. A sequence (f1, . . . , fn) is called proof for f from F or derivation
of f from F , if fn = f and for each i = 1, . . . , n, one of the following
conditions holds:

• fi ∈ F , or
• there are fj, fk with j, k < i and fi is derived from fj, fk using MP, or
• there is fj with j < i and fi is derived from fj using Ex4, or
• fi is one of the remaining axioms.

If there is a derivation of f from F , we write F ‘ f . We write g ‘ f instead
of {g} ‘ f for formulas g. Two formulas g with f ‘ g and g ‘ f are called
provably equivalent.

18.3 Calculus

203

The rules MP, P1, P2, P3 form a sound and complete calculus for propositional
logic (see [TW94]). Formulas f which can be derived from ∅ only with these
rules are called tautologous.

The rules Ex1, Ex2, Ex3, Id1, Id2, Id3, Cong form the step from propositional logic to ﬁrst order predicate logic. The rules Ex1-Ex3 are common
rules which are needed when the existential quantiﬁer is introduced (see for
example [Sho67]). The rules Id1, Id2, Id3, Cong are well-known rules which
capture the fact that the sign .= is interpreted in any model by the (extensional) identity. It is well known that these axioms and rules are sound and
complete, i.e., we have the following theorem:

Theorem 18.7 (Soundness and Completeness of FO). Each set F ∪{f }
of EGIs over of formulas over A satisﬁes

F ‘ f ⇐⇒ F |= f

Let α, α1, α2, α3, . . . be variables and let f, g, h be formulas. Then we
have the following axioms and rules in FO:

MP: f, f → g

‘

g

P1: ‘ f → (g → f )

P2: ‘ (¬f → ¬g) → (g → f )

P3: ‘ (f → (g → h)) → ((f → g) → (f → h))

Ex1: ‘ f → ∃α.f

Ex2: ‘ f → ∃α1.f [α1/α2]
Ex3: f → g ‘ ∃α.f → g

if α1 /∈ FV(f )

if α /∈ FV(g)

Id1: ‘ α0 = α0
Id2: ‘ α0 = α1 → α1 = α0
Id3: ‘ α0 = α1 → α1 = α2 → α0 = α2

Cong: ‘ α0 = αn → α1 = αn+1 → . . . → αn−1 = α2n−1

→ R(α0, . . . , αn−1) → R(αn, . . . , α2n)

Fig. 18.1. The F O-calculus we use in this treatise.

19

Syntactical Translations

At the beginning of Chpt. 13, it has already been mentioned that in literature,
often a semantics for existential graphs is established as a mapping -let us call
it Φ– of existential graphs to FO-formulas. In fact, as argued in this chapter,
this use of the term ’semantics’ is in my view not appropriate. Instead of this,
Φ should considered as a translation instead.

In this chapter, I will provide a mathematical deﬁnition for Φ which maps EGIs
to FO-formulas, and, vice versa, a mathematical deﬁnition for a mapping Ψ
which maps FO-formulas to EGIs. In a broader semantical understanding, it
will turn out that Φ and Ψ are mutually inverse to each other.

19.1 Deﬁnition of Φ and Ψ

In this section deﬁnitions for mappings Ψ and Φ and which can be understood
as translations between the two logical systems of ﬁrst order predicate logic
and EGIs, i.e., FO and EGI, are provided. According to the structures of
formulas resp. graphs, these mappings are deﬁned recursively.

Before we start with the deﬁnitions for Ψ and Φ, let us shortly discuss some
problems caused by structural diﬀerences between FO and the system of
EGIs. To go into details:

1. In EGIs, we have no syntactical devices which correspond to the free
variables of FO, but (as Ψ is deﬁned recursively), we need translations
from formulas with free variables to EGIs. For this reason, in this section,
we consider existential graph where the vertices may be labelled with
variables. But their introduction should be understood as a mere technical

206

19 Syntactical Translations

trick.1 It will turn out that existential graph without variables will be
translated to formulas without free variables, and vice versa.

2. In FO, we have an inﬁnite set of variables which are used to range over
objects. In EGIs, vertices are used for this purpose. Thus a formula Φ(G)
will be only given up to the names of the variables.

3. In FO, we can syntactically express diﬀerent orders of formulas in conjunctions. As conjunction is an assossiative and commutative operation,
in FO the calculus allows to change the order of formulas in conjunctions.
In EGIs, conjunction is expressed by the juxtaposition of graphs. Thus we
have no possibility to express diﬀerent orderings of graphs in conjunctions. For the mapping Φ this yields the following conclusion: A formula
Φ(G) of a existential graph G is moreover only given up the order of the
subformulas of conjunctions.

Particularly, it cannot be expected that Φ ◦ Ψ is the identity mapping.

We start with the deﬁnition of EGIs where the vertices can be labelled with
variables.

Deﬁnition 19.1 (Existential Graph Instances with Variables).
A structure G := (V, E, ν, >, Cut, area, κ, ρ) is called existential graph
instance with variables, iﬀ (V, E, ν, >, Cut, area, κ) is an EGI and if ρ :
.
∪ {∗} is a mapping. The sign ’∗’ is called generic marker.
V → Var
Furthermore, we set V ∗ := {v ∈ V | ρ(v) = ∗} and V Var := {v ∈ V | ρ(v) ∈
Var}. The vertices v ∈ V ∗ are called generic vertices, and the vertices
v ∈ V Var are called variable vertices.

EGIs with variables are a mere helper construction for the deﬁnitions of Φ
and Ψ (nonetheless, in Chpt. 24, we will come back to labelled vertices in
order to add object names to EGIs). The relationship between EGIs without and EGIs with variables correspond to the relationship between formulas
(with free variables) and sentences (formulas without free variables) in FO. In
their graphical notation, existential graph instance with variables are drawn
like EGIs, and above the vertex-spots of variable vertices, we write the corresponding variables.

Now we are prepared to provide the deﬁnitions of Ψ and Φ. We start with the
mapping Φ which maps an EGI to a formula of FO.

Deﬁnition of Ψ :

We deﬁne Ψ inductively over the composition of formulas (see Def. 18.1). To
each formula f , we assign an EGI with variables Ψ (f ). For each case, we
ﬁrst provide a diagram or an informal description before we state the explicit
mathematical deﬁnition.

1 But in Chpt. 24, so called vertex-based EGIs, which syntatically are deﬁned like

EGIs with variables, are investigated.

-

• R(α1, . . . , αn) for a n-ary relation name R and variables α1, . . . , αn:

19.1 Deﬁnition of Φ and Ψ

207

Ψ (R(α1, . . . , αn)) := sα1

sα2
@

sαn−1
(cid:0)
n−1

sαn

. . .
@
2
1
R

(cid:0)
n

That is, we set Ψ (R(α1, . . . , αn)) := G with
G := ({1, . . . , n}, {0}, {(0, (1, . . . , n))}, >, ∅, {(>, {0, 1, . . . , n})},
{(0, R), (1, >), . . . , (n, >)}, {(1, α1), . . . , (n, αn)})

• f1 ∧ f2 for two formulas f1 and f2:

Ψ (f1 ∧ f2) := Ψ (f1) Ψ (f2)

(i.e., Ψ (f1 ∧ f2) is the juxtaposition of Ψ (f1) and Ψ (f2)).

(cid:15)

(cid:12)

• ¬f for a formula f :

Ψ (¬f ) :=

Ψ (f )

(cid:14)

(cid:13)

For Ψ (f ) = (V, E, ν, >, Cut, area, κ, ρ) let c0 /∈ V ∪ E ∪ Cut ∪ {>} be a
new cut. Now we set Ψ (¬f ) := (V, E, ν, >, Cut0, area0, κ, ρ) with
Cut0 = Cut ∪ {c0} and
area0 = area\{(>, area(>))} ∪ {(c0, area(>)), (>, c0)}

• ∃α.f for a formula f and a variable α (this case is called existential

step):

If α /∈ FV(f ), we set Ψ (∃α.f ) := Ψ (f ) .

For α ∈ FV(f ), all vertices v with ρ(v) = α are replaced by a single,
generic vertex v0 on the sheet of assertion, i.e., the following steps have to
be carried out:

1. A new vertex v0 with ρ(v0) = α is juxtaposed to Ψ (f ) (i.e., we draw

∗
•

Ψ (f )

).

2. On each hook (e, i) such that a vertex v with ρ(v) = α is attached to

it, we replace v by v0.

3. All vertices v 6= v0 with ρ(v) = α are erased.
4. The label of v is changed from α to ∗.

The mathematically precise procedure is as follows:

Let Ψ (f ) := G := (V, E, ν, >, Cut, area, κ, ρ), and let Vα be the set of all
α-vertices, i.e., Vα := {w ∈ V | ρ(w) = α}. Let v0 be a fresh vertex.
Let sub : V → V 0 be the helper function deﬁned by sub(v) = v0, if
ρ(v) = α, and sub(v) = v, if ρ(v) 6= α. Now we can deﬁne Ψ (∃x.f ) :=
(V 0, E0, ν0, >0, Cut0, area0, κ0, ρ0) as follows:

208

19 Syntactical Translations

.
∪ {v0}

V 0 := V \Vα
E0 := E
ν0
>0 := >
Cut0 := Cut
area0

: ν0(v1, . . . , vn) := ν(sub(v1), . . . , sub(vn))

: area0(c) := area(c) for c 6= > , and area0(>) := area(>)

.
∪ {v0}

κ0 := κ
ρ0 := ρ

.
∪ {(v0, ∗)}

This completes the deﬁnition of Ψ . For formulas without free variables,
Ψ (f ) := (V, E, ν, >, Cut, area, κ, ρ) is formally an EGI with variables, but
we have ρ(v) = ∗ for each v ∈ V . For this reason, Ψ (f ) is identiﬁed with the
EGI (without variables) G.

In Sect. 12.1 we had shown that the ordered set of contexts (Cut ∪ {>}, ≤) is
a tree (see Cor. 12.3) and can be considered to be the ‘skeleton’ of a existential graph with cuts. In Chpt. 18, Def. 18.4 we had deﬁned a corresponding
structure for FO-formulas. Now the inductive deﬁnition of Ψ yields the following: If f is a formula and Ψ (f ) := G := (V, E, ν, >, Cut, area, κ) then it is
evident that (Negf , ≤) and (Cut ∪ {>}, ≤) are isomorphic orders. We denote
the canonically given isomorphism by ΨN eg : Negf → Cut ∪ {>}.
As implications are important (e.g. nearly all axioms and rules of the FOcalculus are build up from implications), we want to remark the following: If
f and g are sentences, then we have

Ψ (f → g) = Ψ (¬(f ∧ ¬g)) =

(cid:23)

(cid:15)

Ψ (f )
(cid:22)

Ψ (g)

(cid:14)

(cid:20)
(cid:12)

(cid:13)
(cid:21)

Remember that this device of two nested cuts is what Peirce called a scroll .
Scrolls are the kind how implications are written down in existential graphs.

As we have ﬁnished the deﬁnition of Ψ , we proceed with the deﬁnition of
Φ which maps EGIs to FO-formulas. The deﬁnition of Φ is nearly straight
forward, but we have to take care how empty cuts and isolated vertices are
translated: There is no ‘canonical’ translation of an empty cut or an isolated
vertex into a FO-formula. In the Alpha part, we had only to cope with the
problems of empty areas of a cut: They had been translated to ¬(P1 ∧ ¬P1).
For Beta, the approach is slightly diﬀerent: We ﬁrst transform a graph into
a graph having no isolated vertices or empty cuts. This graph is called a
standardization of the starting graph, and it can easily be translated to a
FO-formula.

Deﬁnition 19.2 (Standardization). Let G := (V, E, ν, >, Cut, area, κ) be
s= into each empty
an EGI. Let G0 be obtained from G as follows: Insert s
s= The resulting
context c of G, and replace each isolated vertex • of G by s

19.1 Deﬁnition of Φ and Ψ

209

graph G0 is called the standardization of G. If G contains neither empty
cuts, nor isolated vertices, then G is said to be in standard-form.

Lemma 19.3 (A Graph is Synt. Equivalent to its Standardization).
Let G be an EGI and G0 its standardization. Then G ‘ G0 and G0 ‘ G.

Proof: Due to the rules ‘erasing a vertex’ and ‘inserting a vertex’, isolated
vertices may be added to or removed from arbitrary contexts. Moreover, due to
s= ,
the iteration/deiteration-rule, an isolated vertex • can be replaced by s
2
and vice versa. This yield this lemma.
Note that, as the calculus is sound, we have that G and G0 are semantically
equivalent as well.

Now the formal deﬁnition of Φ can be provided.

Deﬁnition of Φ.

Let G := (V, E, ν, >, Cut, area, κ) be an EGI. We assume that G is in
standard-form, i.e., it neither contains empty cuts, nor isolated vertices.

To each vertex v ∈ V we assign a fresh variable αv (i.e., for v1 6= v2, we have
αv1 6= αv2). Let αempty /∈ FV(G) ∪ {αv | v ∈ V and ρ(v) = ∗} be a further
variable. Now, inductively over the tree Cut ∪ {>}, we assign to each context
c ∈ Cut ∪ {>} a formula Φ(G, c). So let c be a context such that Φ(G, d) is
already deﬁned for each cut d < c. First, we deﬁne a formula f which encodes
all edges which are directly enclosed by c. Hence, if c does not directly enclose
any edges or vertices, simply set f := (∃αempty.>(αempty)). Otherwise, let f
be the conjunction of the following atomic formulas:2

κ(e)(αw1, . . . ,αwj ) with e ∈ E ∩ area(c) and ν(e) = (w1, . . . , wj).

Let v1, . . . , vn be the vertices of G which are directly enclosed by c, and let
area(c) ∩ Cut = {c1, . . . , cl} (by induction, we already assigned formulas to
these cuts). If l = 0, set Φ(G, c) := ∃αv1. . . . ∃αvn.f , otherwise set

Φ(G, c) := ∃αv1. . . . ∃αvn.(f ∧ ¬Φ(G, c1)∧ . . . ∧ ¬Φ(G, cl))

.

Finally we set Φ(G) := Φ(G, >) and the deﬁnition of Φ(G) is ﬁnished for
graphs in standard-form. If G is an EGI which is not in standard-form, let G0
be its standardization, and set Φ(G) := Φ(G0). This completes the deﬁnition
of Φ.

Let G be a existential graph and f := Φ(G). Similar as for Ψ , it is evident
that (Cut ∪ {>}, ≤) and (Negf , ≤) are isomorphic quasiorders. We denote the
canonically given isomorphism by ΦCut : Cut ∪ {>} → Negf .

2 Like in Def. 18.1, the signs which have to be understood literally are underlined.
For example, the ﬁrst formula is the sequence of signs which consists of the result
of the evaluation of κ(w), a left bracket, the result of the evaluation of Φt(w) and
a right bracket.

210

19 Syntactical Translations

I want to point out that Φ is, strictly speaking, not a function. We have
assigned arbitrary variables to the generic nodes, and the order of quantiﬁers
or formulas in conjunctions is arbitrary as well. So Φ determines a formula
only up to the names of the variables, the order of quantiﬁers and the order
of the subformulas of conjunctions. To put it more formally: The image Φ(G)
of a existential graph G is only uniquely given up to the following equivalence
relation:

Let ∼= be the
Deﬁnition 19.4 (Equivalence Relation for Formulas).
smallest equivalence relation on FO such that the following conditions hold:

1. If f1, f2, f3 are formulas then we have f1 ∧f2

∼= f2 ∧f1 and (f1 ∧f2)∧f3

∼=

f1 ∧ (f2 ∧ f3),

2. if f1, f2 are formulas with f1

∼= f2 and if α, β are variables then ∃α.∃β.f1

∼=

∃β.∃α.f2,

3. if f and f 0 are equal up to renaming bound variables then f ∼= f 0, and
4. if f1, f2, g1, g2 are formulas with f1
∼= f2 ∧ g2 and ∃α.f1

∼= g2 then ¬f1

∼= f2 and g1

∼= ∃α.f2.

f1 ∧ g1

∼= ¬f2,

It is well known that the relation ∼= respects the meaning of a formula, i.e.,
for formulas f, g with f ∼= g we have f |= g and g |= f (and thus we have
f ‘ g and g ‘ f ). So all possible images Φ(G) of a existential graph G are
semantically and provably equivalent and can therefore be identiﬁed, and we
consider Φ a mapping which assigns a formula to each existential graph.

To illustrate the mappings Φ and Ψ , I give a small sample. A well-known
example (see [Sow97a], Fig. 12) for translating formulas to existential graphs
is the formula which expresses that a binary relation F is a (total) function.

f := ∀x.∃y.(xF y ∧ ∀z.(xF z → (y = z)))

This formula is written down only by using the ∃-quantiﬁer and the junctors
∧ and ¬. It is

f := ¬∃x.¬∃y.(xF y ∧ ¬∃z.(xF z ∧ ¬(y = z)))

In Fig. 19.1, the EGI Gf := Ψ (f ) is depicted. Each variable occurrence of f
generates a vertex in Ψ (f ). To make the translation more transparent, each
vertex is labeled with its generating variable occurrences of f .

The existential graph in Fig. 19.1 can be translated back to a ﬁrst order logic
formula by the mapping Φ. One possible result (up to the chosen variables
and to the order of the subformulas) is:

Φ(Ψ (f )) = ¬∃u.¬∃v.(uF v ∧ ¬∃w.(¬(v = w) ∧ uF w))

It is easy to see that Φ(Ψ (f ) ∼= f , i.e., f is another possible result of Φ(Ψ (f )).
As Φ(G) is be given only up to the relation ∼=, it is clear that we cannot prove

19.2 Semantical Equivalence between Graphs and Formulas

211

Ψ (f ) =

Fig. 19.1. The EGI Ψ (f )

that Φ ◦ Ψ is the identity mapping. Moreover, we usually will even not have
f ∼= Φ ◦ Ψ (f ). For example, consider the following formula:

g := ∃y.P (y) ∧ ∃x.∃x.R(x, y)

Then we have

Φ(Ψ (g)) = ∃y.∃x.P (y) ∧ R(x, y)

Roughly speaking, Φ ◦ Ψ removes superﬂuous quantiﬁers, and moreover, it
may move quantiﬁers outwards.

In contrast to Φ ◦ Ψ , Ψ ◦ Φ is a well-deﬁned mapping which maps graphs to
graphs. To exemplify the mapping Φ, consider

G :=

For G, we have

Φ(G) = ∃x.(P (x) ∧ ¬∃y.∃z.∃w.(R(x, y) ∧ y = z ∧ S(z) ∧ R(y, w) ∧ ¬Q(w)))

and Ψ (Φ(G)) = G. This equality holds for Gf as well: From Φ(Ψ (f ) ∼= f we
conclude Ψ (Φ(Gf )) = Gf . The examples suggest that Ψ (Φ(G)) = G holds
for each EGI G. In fact, we will prove this conjecture for each graph G in
standard-form (due to the deﬁnition of Φ, this is the best we can expect).
This will be done in the next chapter, in Sect. 20.2.

19.2 Semantical Equivalence between Graphs and
Formulas

In this section, we will show that the mappings Φ and Ψ preserve the meaning
of graphs resp. formulas.

We start our investigation with the mapping Φ.

FFQRSRPxywz212

19 Syntactical Translations

Theorem 19.5 (Main Semantical Theorem for Φ). Let an EGI G :=
(V, E, ν, >, Cut, area, κ) be given and let M be a relational structure over A.
Then we have the following equivalence:

M |= G ⇐⇒ M |= Φ(G)

Proof: Recall that Φ is deﬁned inductively over Cut ∪ {>} for graphs in
standard-form, but due to Lem. 19.3, we can assume w.l.o.g. that G is an
EGI in standard form. Let G := (V, E, ν, >, Cut, area, κ) be an EG. Like Φ,
the relation |=class between models and graphs is inductively deﬁned as well.
In the deﬁnition of |=class, we needed total valuations ref : V → U . In the
deﬁnition of Φ, we assigned to each vertex v ∈ V a variable αv ∈ Var. Thus,
we can canonically transform each valuation ref : V → U to a valuation
valref : Var → U on the set of variables by setting valref (αv) := ref (v) for
each variable in {αv | v ∈ V } (for all other variables α, the image valref (α) is
arbitrary). Using this deﬁnition, it is easy to show inductively over Cut ∪ {>}
that, for every total valuation ref : V → U and every context c ∈ Cut ∪ {>},
we have the following equivalence:

M |=class G[c, ref ] ⇐⇒ M |=valref Φ(G, c)

If we take now an arbitrary valuation ref , we have

M |=class G ⇔ M |=class G[>, ref ] ⇔ M |=valref Φ(G, >) ⇔ M |= Φ(G)

The last equivalence holds because Φ(G) = Φ(G, >) has no free variables. 2

Next we will have to show the corresponding result for Ψ . The idea of the proof
cannot directly be adopted for the following reason: In the deﬁnition of Ψ , we
considered EGIs with variables. These graphs are a mere helping construct. So
far, we have not deﬁned how EGIs with variables are evaluated in models. In
order to prove that Ψ respects the entailment-relation |= as well, we ﬁrst have
to extend our semantics to EGIs with variables. This will be done analogously
to FO, that is, we treat variable-vertices like free variables in FO.

For EGIs with variables, the assignment of objects to variable vertices will
be adopted from (FO-) valuations val : Var → U . For this reason, partial
and total valuations of EGIs with variables are deﬁned to be valuations which
assign objects only to the generic vertices. This yields the following deﬁnition:

Let G be an
Deﬁnition 19.6 (Valuations for EGIs with Variables).
EGI with variables, and let M = (U, I) be a relation structure. Each mapping
ref : V 0 → U with V 0 ⊆ V ∗ is called a partial valuation of G. If c ∈ Cut,
V 0 ⊇ {v ∈ V ∗ | v > c} and V 0 ∩ {v ∈ V ∗ | v ≤ c} = ∅, then ref is called
a partial valuation for the context c. If V 0 = V ∗, then ref is called (total)
valuation of G.
Let val : Var → U be a (FO-)valuation, and let ref : V 0 → U be a partial
valuation for G. Let ref

.
∪ V Var → U be the mapping with

.
∪ val : V 0

19.2 Semantical Equivalence between Graphs and Formulas

213

(ref

.
∪ val)(v) =

(cid:26) ref (v) v ∈ V 0

val(α) v ∈ V Var with ρ(v) = α

Now M |=endo G resp. M |=class G are deﬁned exactly like in Def. 13.4 resp.
in Def. 13.3 for combined valuations ref

.
∪ val.

Deﬁnition 19.7 (Endoporeutic Evaluation of EGIs with Variables).

Let G := (V, E, ν, >, Cut, area, κ, ρ) be an existential graph and let (U, I) be
a relational structure over A. Inductively over the tree Cut ∪ {>}, we deﬁne
.
(U, I) |=endo G[c, ref
∪ val] for each context c ∈ Cut ∪ {>} and every partial
valuation ref : V 0 ⊆ V → U for c:

(U, I) |=endo G[c, ref ] :⇐⇒

ref can be extended to a partial valuation ref : V 0 ∪ (V ∩ area(c)) → U
(i.e., ref (v) = ref (v) for all v ∈ V 0), such that the following conditions
hold:

• (ref
• (U, I) 6|=endo G[d, ref

.
∪ val)(e) ∈ I(κ(e)) for each e ∈ E ∩ area(c) (edge condition))

.
∪ val)] for each d ∈ Cut ∩ area(c) (cut condi-

tion and iteration over Cut ∪ {>}) )

If val : Var → U is a valuation with M |=endo G[>, ∅
M |=endo G[val] for short.

.
∪ val], we write

Lemma 19.8 (Replacing a Generic Marker by a Variable). Let G :=
(V, E, ν, >, Cut, area, κ, ρ) be an EGI with variables, let α ∈ Var be a variable
such that there is no vertex w ∈ V with ρ(v) = α. Let v ∈ area(>) be a
generic vertex. Let G[v7→α] be obtained from G be exchanging the label of v
from ’∗’ to α (i.e., we set G[v7→α] := (V, E, ν, >, Cut, area, κ, ρ[v7→α]), where
ρ[v7→α](v) = α, and ρ[v7→α](w) = ρ(w) for all w 6= v). Let M := (U, I) be a
model and let val : Var → U be a valuation. Then we have

M |=endo G[val] ⇐⇒ there is an u ∈ U with M |=endo G[v7→α][val[α→u]]

,

where val[α→u]
val[α→u](β) = val(β) for all variables β ∈ Var with β 6= α.

: Var → U is the valuation with val[α→u](α) = u and

Proof: Follows immediately from the deﬁnition of |=endo for EGIs and EGIs
2
with variables.

Theorem 19.9 (Main Semantical Theorem for Ψ ). Let f be a sentence
and let M be a relational structure over A. Then we have the following equivalence:

M |= f ⇐⇒ M |= Ψ (f )

Proof: Ψ is deﬁned inductively over the construction of formulas. The same
holds for the relation |= between models and formulas. In the deﬁnition of |=,

214

19 Syntactical Translations

we needed valuations val : Var → U . Let f be a formula, G := Ψ (f ), and
let val : Var → U a valuation for the variables. In the deﬁnition of Ψ , we
assigned to each occurrence of a variable α ∈ Var (including the occurrences
of α after an quantiﬁer ∃ a vertex vα). Now the valuation val can canonically
be transformed to a valuation refval : V → U by setting refval(vα) := val(α).
Then refval is a total valuation for the EGI with variables G.
Let M be a relational structure. We will show by induction over the construction of formulas that we have

M |=val f ⇐⇒ M |=endo G[val]

(19.1)

for arbitrary formulas f , G := (V, E, ν, >, Cut, area, κ, ρ) := Ψ (f ), and valuations ref : Var → U .

• For f = R(α1, . . . , αn) with R ∈ R and variables α1, . . . , αn, Eqn. (19.1)

is obviously satisﬁed.

• Let f = ¬g. For Gg := (Vg, Eg, νg, >g, Cutg, areag, κg, ρg) = Ψ (g) and

Gf := (Vf , Ef , νf , >f , Cutf , areaf , κf , ρf ) = Ψ (f ), we have:

M |=val f

⇐⇒
ind. hyp
⇐⇒

M 6|=val g

M 6|=endo Gg[val]

Def. Ψ and. |=endo
⇐⇒

M |=endo Gf [val]

• The case f = f1 ∧ f2 is done analogously to the last case.
• Let f = ∃α.g. Let Gg := (Vg, Eg, νg, >g, Cutg, areag, κg, ρg) = Ψ (g),
Gf := (Vf , Ef , νf , >f , Cutf , areaf , κf , ρf ) = Ψ (f ). If α /∈ FV(g), we have
Gf = Gg, and we are done. So let α ∈ FV(f ). In existential step of Ψ , the
following steps are carried out:

1. A new vertex v0 with ρ(v0) = α is juxtaposed to Ψ (f ). The resulting

graph is denoted by G1.

2. On each hook (e, i) such that a vertex v with ρ(v) = α is attached to

it, we replace v by v0. The resulting graph is denoted by G2.

3. All vertices v 6= v0 with ρ(v) = α are erased. The resulting graph is

denoted by G3.

4. The label of v is changed from α to ∗. We obtain Gf .
In order to prove this case, we start with the deﬁnition how f is evaluated
in M. We have:

M |=val ∃α.g

Def. |=
⇐⇒ there is an u ∈ U with M |=val[α→u] g

(19.2)

Our induction hypothesis yields that the right side of Eqn. (19.2) is equivalent to

19.2 Semantical Equivalence between Graphs and Formulas

215

there is an u ∈ U with M |=endo Gg[val[α→u]]

(19.3)

It is trivial that the or erasure insertion of a vertex v0, either labeled with
a generic marker, or with an variable, does not change the meaning of an
EGI with variables. Particularly, Eqn. (19.3) is equivalent to

there is an u ∈ U with M |=endo G1[val[α→u]]

(19.4)

In the evaluation of EGIs with variables, we have already assigned objects
to the variable vertices when we start the evaluation. For this reason,
replacing a vertex labeled with α by another vertex labeled with α as well
on a hook does not change the meaning of the graph. Thus, Eqn. (19.4) is
equivalent to

there is an u ∈ U with M |=endo G2[val[α→u]]

(19.5)

Analogously to the step from Eqn. (19.3) to Eqn. (19.4), we now get that
Eqn. (19.5) is equivalent to:

there is an u ∈ U with M |=endo G3[val[α→u]]

(19.6)

We have G3 = (Gf )[v0→α]. Now Lem. 19.8 yields that Eqn (19.6) is equivalent to M |=endo Gf [val], thus the existential step is ﬁnished.

Now let f be a sentence and let G := Ψ (f ). As f has no free variables, and
as Ψ (f ) has no variable-vertices, we have for each valuation val : Var → U
(which is simply irrelevant)

M |= f ⇐⇒ M |=val f ⇐⇒ M |=endo G[val] ⇐⇒ M |=endo G ,

and we are done.

2

From Thms. 19.5 and 19.9, we get analogously to Alpha (see Cor. 10.6) the
following corollary:

Corollary 19.10 (Φ and Ψ respect |=). Let H be a set of EGIs and let G
be an EGI, and let f be a formula and F be a set of formulas. Then we have:

F |= f ⇐⇒ Ψ (F ) |= Ψ (f )

, and H |= G ⇐⇒ Φ(H) |= Φ(G)

.

Moreover we have that G and Ψ (Φ(G)), as well as f and Φ(Ψ (f )), are semantically equivalent.

Proof: Analogously to the proof of Cor. 10.6.

2

20

Syntactical Equivalence to F O and
Completeness

In Chpt. 13 we provided two translations Φ and Ψ between the logical systems
of EGIs and FO. Both systems are equipped with a semantical entailment
relation |= and a derivability relation ‘. In Chpt. 13 we have already shown
that Φ and Ψ respect the entailment relation |=. Moreover, we know that ‘ is
sound and complete on the side of FO (i.e., for two formulas f1, f2, we have
f1 ‘ f2 ⇔ f1 |= f2), and ‘ is sound for EGIs (i.e., for two EGIs G1, G2, we
have G1 ‘ G2 ⇒ G1 |= G2). From this, we can conclude that Φ respects the
syntactical entailment relation ‘ as well. But so far, we neither can conclude
that ‘ is complete for EGIs, nor that Ψ respects ‘. In this chapter, this gap
will be closed.

In Sec. 20.1, we will show that Ψ respects ‘, i.e., f1 ‘ f2 ⇒ Ψ (f1) ‘ Ψ (f2).
Unfortunately, this result is not suﬃcient to show that ‘ is complete for EGIs:
For any graph G we know that G and Ψ (Φ(G)) have the same meaning, but
it cannot be proven that G and Ψ (Φ(G)) are provably equivalent. But as
the presented examples in the last chapter already indicated, in Sec. 20.2
an even better result is proven: For any graph G in standard-form, we have
G = Ψ (Φ(G)). These two results of this chapter will be suﬃcient to show
ﬁnally that ‘ is complete for EGIs.

20.1 Ψ respects ‘

In this section we want to show that Ψ respects the derivability relation ‘,
i.e., we want to show that we have f1 ‘ f2 =⇒ Ψ (f1) ‘ Ψ (f2) for formulas
f1, f2. The relations ‘ for formulas resp. for EGIs are based on the appropriate
calculi, so the idea of the proof is to show that Ψ respects every rule of the
calculus for FO. We want to point out that the calculus for FO is based on
formulas with free variables, in contrast to the calculus on EGI which is based
on EGIs without variables. For this reason we have to translate formulas with

218

20 Syntactical Equivalence to F O and Completeness

free variables to EGIs without variables. This can canonically be done by a
slight modiﬁcation of the mapping Ψ .

Deﬁnition 20.1 (Universal Closures of Formulas and Ψ∀). Let f be
a formula with FV(f ) = α1, . . . , αn. Then f∀ := ¬∃α1 . . . ∃αn¬f is called
universal closure of f . Now we set

Ψ∀ :=

(cid:26) FO → EGI
f 7→ Ψ (f∀)

For each formula, Ψ∀(f ) is an EGIs without variables. The deﬁnition of the
relation |= in FO yields that a formula f is valid in a relational structure if
and only if f∀ is valid in that structure. For this reason we have to focus on
the universal closure of f (instead of the corresponding existential closure)
and hence on the mapping Ψ∀.
Due to its deﬁnition, the mapping Ψ∀ shall be represented as follows:

Ψ∀(f ) :=

In this notation, f shall stand for the subgraph which is generated by f .
But this generated subgraph is not Ψ (f ), but the subgraph we get after the
existential steps are applied to Ψ (f ). For this reason we write f instead Ψ (f )
in this diagrams, although f shall denote a subgraph of the written graph.

Now we are prepared to prove that Ψ∀ respects ‘.

Lemma 20.2 (Ψ∀ Respects Syntactical Entailment). Let f1, . . . , fn ‘ g,
n ∈ N0 be a rule of the calculus for FO. Then we have Ψ∀(f1), . . . , Ψ∀(fn) ‘
Ψ∀(g) in the calculus for EGIs.

Proof: We have to show the lemma for each rule.

Modus Ponens: f, f → g

‘

g

Let f, g be two formulas. Without loss of generality let FV(f ) = {x1, . . . xm},
and FV(g) = {xi, . . . xn}.

f1n20.1 Ψ Respects ‘

219

The graph we start
with is the juxtaposition of the graphs
Ψ∀(f ), Ψ∀(f → g):

The double cut rule
yields:

We split each vertex
which has an index
from 1 to i − 1:

1i−1imf1i−1mnm+1igf1i−1imf1i−1mnm+1ifg1i−1imf1i−1mnm+1ig1mf220

20 Syntactical Equivalence to F O and Completeness

new identity

All
edges are erased:

All vertices with an
index between 1 and
i − 1 are now erased:

Deiteration yields:

Now erasure yields:

-

This is Ψ∀(g), hence we have Ψ∀(f ) , Ψ∀(f → g) ‘ Ψ∀(g).

1i−1imf1i−1mnm+1ig1mf1i−1imfmnm+1ig1mf1i−1imfmnm+1igmnm+1ig20.1 Ψ Respects ‘

221

P1: ‘ f → (g → f )

Let f , g be two formulas. Without loss of generality let FV(f ) := {x1, . . . xm}
and FV(g) := {xi, . . . xn}.
From the sheet of assertion, we can derive with double cut
and insertion:

We iterate each vertex which has an index from 1 to m into
the inner cut as follows:

Iteration of the subgraph which is generated by f yields:

appliAn m-fold
the rule
cation of
‘removing a vertex’
yields:

We merge the vertices in the inner cut
into the outer cut:

fgn11gfnm+1m1gfnm+1mf1gfnm+1mfffgn1222

20 Syntactical Equivalence to F O and Completeness

Double cut yields:

This is Ψ∀((f → (g → f ))).

P2: ‘ (¬f → ¬g) → (g → f )

The scheme for the proof of P2 is the same like in the proof for P1. Again let
f , g be two formulas with FV(f ) := {x1, . . . xm} and FV(g) := {xi, . . . xn}.
From the sheet of assertion, we can derive with double cut
and insertion:

We iterate each vertex which has an index from 1 to n into
the inner cut as follows:

Iteration of the inserted subgraph yields:

of

An n-fold application
rule
‘removing a vertex’
yields:

the

We merge the vertices in the inner cut
into the outer cut:

Double cut yields:

ffgn1fgn1fg1nfggf1nfggf1nffggn1fgfgn1This is Ψ∀((¬f → ¬g) → (g → f )).

P3: ‘ (f → (g → h)) → ((f → g) → (f → h))

20.1 Ψ Respects ‘

223

We have to show ‘ Ψ∀((f → (g → h)) → ((f → g) → (f → h))). The scheme
for the proof of P3 is the same like of the proofs for P1 and P2. From the
empty sheet of assertion, we apply the rules double cut, insertion, iteration,
removing vertices and double cut to get the desired graph. To simplify matters
we assume that f , g and h have no free variables (in case of free variables,
an additional application of the identity-erasure-rule is needed). The proof is
now done as follows:
On the empty sheet
of assertion we draw
a double cut and in-
(cid:7)
(cid:4)
(cid:7)
g
(cid:5)and h
sert f ,
(cid:6)
(cid:6)
into the outer cut:
(cid:4)
(cid:5)into

(cid:4)
(cid:5)

(cid:7)
g
We iterate
(cid:6)
the inner cut:

Now a twofold iteration of f and a itera-
(cid:4)
(cid:7)
(cid:5)yields:
tion of h
(cid:6)

Now a threefold application of the double cut rule yields:

This is Ψ∀((f → (g → h)) → ((f → g) → (f → h))).

The rules MP, P1, P2 and P3 form a complete set of rules for propositional
logic, hence they are in FO suﬃcient to derive all tautologous formulas f .
Hence we now have Ψ∀(f ) for all tautologous formulas f . This will be used in
the rest of the proof.

Ex1: ‘ f → ∃α.f

Let α be the variable xn. We have to show ‘ Ψ∀(f → ∃xn.f ). To do this, we
distinguish two cases.

hfghfggfhfghgfgffghhf224

20 Syntactical Equivalence to F O and Completeness

First, let xn /∈ F reeFV(f ). Then we have Ψ∀(f → ∃xn.f ) = Ψ∀(f → f ). As
f → f is tautologous, we can derive Ψ∀(f → f ), i.e., we can derive the graph
Ψ∀(f → ∃xn.f ).
Now let xn ∈ FV(f ). Then Ψ∀(f → ∃xn.f ) is derived as follows:
As f → f is tautologous, we can derive

The n-th vertex n is
split:

Now the new identity
edge is erased:

This is Ψ∀(f → ∃xn.f ).

Ex2: ‘ f → ∃α1.f [α1/α2], if α1 /∈ FV(f )
Let f be an formula. We want to show ‘ Ψ∀(f → ∃α1.f [α1/α2]), if α1 /∈
FV(f ).

First we consider the case α2 /∈ FV(f ). Then we have f → ∃α1.f [α2/α1] =
f → ∃α1.f , and furthermore we have Ψ∀(f → ∃α1.f ) = Ψ∀(f → f ). As f → f
is tautologous, we conclude ‘ Ψ∀(f → f ), thus ‘ Ψ∀(f → ∃α1.f [α2/α1]).
Now let α2 ∈ FV(f ). It is easy to see that Ψ (∃α2.f ) = Ψ (∃α1.f [α2/α1]) holds,
thus we have Ψ∀(f → ∃α1.f [α2/α1]) = Ψ∀(f → ∃α2.f ). So this case can be
reduced to the proof of Ex1.

Ex3: f → g ‘ ∃α.f → g, if α /∈ FV(g)

Let α be the variable xn, and without loss of generality let FV(f → g) :=
{x1, . . . xn}. Suppose we have ‘ Ψ∀(f → g) with xn /∈ FV(g). We have to
derive the graph Ψ∀(∃xn.f → g). The graphs we have to consider are:

n−1f1nfn−1f1nnfnn−1f1nf20.1 Ψ Respects ‘

225

Ψ∀(f → g) =

and

Ψ∀(∃xn.f → g) =

.

Now xn /∈ FV(g) yields that we have no identity edge between the n-th vertex
(cid:4)
(cid:5). Hence, using double cut, both graphs are equivalent

(cid:7)
n and any vertex of g
(cid:6)

to:1

This yields that both graphs are equivalent, too, and the proof for Ex4 is
ﬁnished.

Id1 (reﬂexivity of identity): ‘ α0 = α0
Ψ∀(α0 = α0) can be derived as follows:

dc and ins
‘

it
‘

∼

Id2 (symmetry of identity): ‘ α0 = α1 → α1 = α0
Ψ∀(α0 = α1 → α1 = α0) can be derived as follows:

Id1
‘

∼

dc
‘

Id3 (transitivity of identity): ‘ α0 = α1 → α1 = α2 → α0 = α2
Ψ∀(α0 = α1 → α1 = α2 → α0 = α2) can be derived as follows (where we
have (we have labeled the vertices, so that it is easier to realize which vertex
belongs to which variable):

1 In fact ∀xn.(f → g) and ∃xn.f → g are equivalent, too.

1gfnn−11n−1gfn1n−1gfn12211221226

20 Syntactical Equivalence to F O and Completeness

Id1
‘

∼

dc
‘

Cong2: ‘ α0 = αn → . . . → αn−1 = α2n−1 → R(α0, . . . , αn−1) →
R(αn, . . . , α2n)
We perform this proof only for relation names with the arity 2, i.e., we consider
Ψ∀(α0 = α2 → α1 = α3 → R(α0, α1) → R(α2, α3)).
This proof can be performed as well for higher (or lower) arities, but then the
graphs we need have a poor readability. So let R ∈ R2. We have:

dc, ins
‘

it
‘

∼

A threefold application of the double-cut rule yields

which is the desired EGI (again we have labeled the vertices, so that it is
2
easier to realize which vertex belongs to which variable).

We have shown that each axiom and rule of the FO-calculus is respected by
the mapping Ψ : FO → EGI. Thus the last lemma yields immediately that
Ψ : FO → EGI respects the syntactical entailment relation ‘, i.e., we have
the following theorem.

Theorem 20.3 (Main Syntactical Theorem for Ψ ). Let F be a set of
FO-formulas and f be a FO-formula (all possibly with free variables). Then
we have

F ‘ f =⇒ {Ψ∀(g) | g ∈ F } ‘ Ψ∀(f )
In particular we have f1 ‘ f2 =⇒ Ψ (f1) ‘ Ψ (f2) for formulas f1, f2 without
free variables.

120RRRRRRR2103Identity of G and Ψ (Φ(G)) and Completeness of ‘

227

Proof: A canonical proof based on using Lem. 20.2, carried out by induction
over the length of the proofs, yields immediately:

If f1, f2 are two FO-formulas with f1 ‘ f2, then Ψ∀(f1) ‘ Ψ∀(f2) .

(20.1)

Let F be a set of formulas and f be a formula with F ‘ f , i.e. we have
g1, . . . , gn ∈ F with g1, . . . , gn ‘ f . We set F∀ := {g∀ | g ∈ F }, Ψ∀(f )=Ψ (f∀),
and fi := (gi)∀ for 1 ≤ i ≤ n. We get f1, . . . fn ‘ f∀. thus f1 ∧ . . . ∧ fn ‘ f∀.
Now Eqn. 20.1 yields Ψ (f1 ∧ . . . ∧ fn) ‘ Ψ (f∀). From the deﬁnition of Ψ and Ψ∀
we obtain Ψ (f1 ∧ . . . ∧ fn) = Ψ (f1) . . . Ψ (fn) = Ψ∀(g1) . . . Ψ∀(gn), which yields
2
the main proposition of theorem.

20.2 Identity of G and Ψ (Φ(G)) and Completeness of ‘

At the end of Sect. 19.1, after the Deﬁnitions of Φ and Ψ , we have already
investigated some examples for the mapping Φ and Ψ . In this section, we will
prove the conjecture we had claimed after these examples, that is, we will
show that each for G = Ψ (Φ(G)) holds for each EGI G in standard-form.

Theorem 20.4 (G = Ψ (Φ(G)) for Graphs in Standard-Form). For
each EGI G in standard-form, we have G = Ψ (Φ(G)).

Proof: Let G be an arbitrary EGI, let f := Φ(G). We already know that the
mapping ΦCut is a bijection (more precisely: an isomorphism) between the
contexts of G, i.e. Cut ∪ {>}, and f and the subformula occurrences of f
which start with an ‘¬’, i.e. Negf ∪ {>f } (see the remark after the deﬁnition
of Φ, p. 209. It should be noted that the notation ΦCut is a little bit sloppy:
Each graph G induces a separate mapping ΦCut on the contexts of that graph).
Analogously, due to the deﬁnition of Φ, we have

• a bijection ΦV between the vertices of G and the subformula occurrences

which starts with an ‘∃α’ (with α ∈ Var) of f , and

• a bijection ΦE between the edges of G and the atomar subformula occur-

rences of f ,

and these bijections satisfy that

• for v ∈ V , ΦV (v) is a subformula of ΦCut(ctx(v)) if and only if v ≤ c, and
• for e ∈ E, ΦE(e) is a subformula of ΦCut(ctx(e)) if and only if e ≤ c.

This can easily be shown with an inductive proof over the inductive construction of Φ.

228

20 Syntactical Equivalence to F O and Completeness

Now we consider formulas g which do not have any two diﬀerent subformula
occurrences of the form ∃α.h with α /∈ FV(h) (this restriction is necessary
because in the deﬁnition of Ψ , in the existential step, we treated this case
separately). First of all, similar to Ψ , we have a mapping ΨN eg which is an
isomorphism) between Negh ∪ {>h} and the contexts of Ψ (g) (see the remark
after the deﬁnition of Ψ , p. 208). Analogously, due to the deﬁnition of Ψ , we
have

• a bijection Ψ∃ between the subformula occurrences which starts with an

‘∃α’ (with α ∈ Var) of g and the generic vertices of Ψ (g),

• a bijection ΨR between the atomar subformula occurrences of g and the

edges of Ψ (g),

and these bijections satisfy that

• a subformula occurrence h1 which starts with an ‘∃α’ is a subformula of a
subformula occurrence h2 ∈ Negf if and only if Ψexists(h1) ≤ ΨN eg(h2),
and

• an atomar subformula occurrence h1 is a subformula of a subformula oc-

currence h2 ∈ Negf if and only if ΨR(h1) ≤ ΨN eg(h2).

Note that the range of mapping Ψ∃ is not the set of all vertices in Ψ (f ), but
the set of all generic vertices.
Now let G be an arbitrary EGI. We set f := Φ(G) and G0
:= Ψ (f ) :=
(V 0, E0, ν0, >0, Cut0, area0, κ0, ρ0). As G0 does not contain any variable-vertices,
Ψ∃ ◦ ΦV is a bijection from V to V 0. As ΨR ◦ ΦE and ΨN eg ◦ ΦCut are bijections between E and E resp. Cut ∪ {>} and Cut0 ∪ {>0} as well, and due
.
to our discussion above, we see that Ψ∃ ◦ ΦV
∪ ΨN eg ◦ ΦCut is an
2
isomorphism between G and G0.

.
∪ ΨR ◦ ΦE

With this lemma, we can ﬁnally prove that the calculus for EGIs is complete.

Theorem 20.5 (Completeness of the Beta-Calculus). Each set H∪{G}
of EGIs over A satisﬁes

H |= G =⇒ H ‘ G

Proof: Let H |= G. From Cor. 19.10 we conclude Φ[H]
|= Φ[G]. Theorem 18.7 yields Φ[H] ‘ Φ[G]. By deﬁnition of ‘ we have G1, . . . , Gn ∈ H with
Φ(G1), . . . , Φ(Gn) ‘ Φ(G). By Thm. 20.3 we get Ψ (Φ(G1)), . . . , Ψ (Φ(Gn)) ‘
Ψ (Φ(G)). For 1 ≤ i ≤ n, Thm. 20.4 and Lem. 19.3 yield Gi ‘ Ψ (Φ(Gi)) and
2
Ψ (Φ(G)) ‘ G. Hence we get G1, . . . , Gn ‘ G, thus H ‘ G.

21

Working with Diagrams of Peirce’s Graphs

In the preceeding chapters, we have developed a mathematical theory of
Peirce’s graphs. Our starting point have been the original manuscripts of
Peirce in which he describes his graph system. We had to cope with two problems: First of all, Peirce did not provide a comprehensive, self-contained treatise on his graphs. Instead, his description of existential graphs is scattered
throughout diﬀerent manuscript. What is more important is that Peirce’s
original manuscripts do by no means satisfy the needs of contemporary mathematics.

Recall that Peirce distinguished between existential graphs and existential
graph replicas. Existential graphs can be understood as abstract structures,
and their diagrammatic representations are existential graph replicas. In order
to develop a mathematical theory of existential graphs, we introduced abstract
mathematical structures called existential graph candidates, and we deﬁned
formal existential graphs as classes of existential graph instances.

Before we start this chapter, let us clarify some notations to ease the discussion. Actually, we have ﬁve diﬀerent, but closely related items to deal with:

1. EGIs as abstract mathematical structures. The are usually denoted by the

letter G.

2. Diagrams of EGIs.

3. Formal existential graphs as classes of EGIs. In the following, I will abbreviate formal existential graphs by EGs. EGs are usually denoted by
the letter E.

4. Diagrams of EGs.

5. Finally, the term ‘Peirce graphs’ will be used to refer to Peirce’s original

system, which has been formalized by EGs and their diagrams.

In the preceeding chapters, we elaborated EGs as mathematical logic system,
i.e., we developed a mathematical syntax, semantics and the calculus for this

230

21 Working with Diagrams of Peirce’s Graphs

system. In order to grasp as best as possible Peirce’s understanding of his
system, we investigated extensively the informal given syntax and semantics
of Peirce’s graphs in Chpt. 11, before the mathematical syntax and semantics
for EGIs and EGs have been introduced, and we investigated the informal
given transformation rules of Peirce in Chpt. 14, before we introduced mathematically a calculus for EGIs and and EGs. To summarize: The mathematical
elaboration of EGs has carried out as close as possible to Peirce’s understanding. But Peirce’s graphs and EGs are not the same: Formal existential graphs
are a possible mathematical formalizations of Peirce’s original system, which
is only informally given.

Deﬁning EGIs and EGs was necessary to elaborate a precise mathematical
theory. With this theory, we can now get back to Peirce’s original system: The
goal of this chapter is to develop a better understanding of Peirce’s original
system and to provide a purely graphical logic system.

This goal has already partly been fulﬁlled. First of all, we have already argued that EGs reﬂect Peirce’s understanding of his graphs as best as possible.
We provided and discussed how EGIs graphically can be depicted. From this
we have obtained a graphical representation of EGs as well, and the graphical representations of EGs correspond to the Peirce’s non-degenerated graph
replicas.
In this understanding, we have ﬁxed the syntax of Peirce’s graphs
as well of his graph replicas. Particularly, this deﬁnition of the syntax of
Peirce’s graph replicas should not be understood as a mathematical syntax,
as the representations of EGIs, thus of EGs, are not mathematically deﬁned.
Nonetheless, this syntax is precise enough for an unambiguous understanding
of Peirce’s graph replicas.

Similarly, we have elaborated a mathematical semantics for EGIs and EGs,
which yields a mathematical semantics for Peirce’s graph replicas as well.
In Chpt. 16, we have moreover provided methods which ease the reading of
diagrams of EGIs and EGs, based on mathematical investigations of EGIs. The
calculus of Peirce’s graphs has been captured as a formal calculus on these
structures. Nonetheless, this calculus should be understood as a diagrammatic
calculus, i.e. the rules should be understood as diagrammatic manipulations
of the diagrams of EGI. Now it remains to investigate how the calculus for
EGIs can be transferred to a purely graphical calculus for diagrams of EGs.

Except the double cut rule, the remaining rules — erasure, insertion, iteration, deiteration — rely on the notation of a subgraph. Thus we have ﬁrst to
investigate how subgraphs can graphically be represented. We start this investigation with the subgraphs of EGIs, before the results of the investigation
will be transferred to formal EGs.

The basic observation is that a subgraph behaves similarly to the enclosure of
a cut, i.e., it can be understood as a subset of vertices, edges, and cuts, such
that

21 Working with Diagrams of Peirce’s Graphs

231

• If a cut c belongs to the subgraph, then all elements which are enclosed

by c belong to the subgraph as well, and

• The subgraph itself is placed in the area of a context.

This will give us the possibility to represent a subgraph similarly to the representation of a cut, that is, by a closed, doublepoint-free and smooth curve
such that in the diagram of the graph, all elements of the diagram which
denote an element of the subgraph are enclosed by the subgraph-line.1

Starting on page 128, it has been described how EGIs are graphically depicted.
Recall the basic idea of the representation: We deﬁned a quasiorder ≤ on the
elements of the graph such with the following properties:

• we had x (cid:12) c for an arbitrary element x and a context c iﬀ x is enclosed

by c, and

• (Cut ∪ {>}, ≤) is a tree.

Due to the second condition, we can represent the cuts as closed, doublepointfree and smooth curves which do not intersect or overlap, such that the cut-line
of a cut c is enclosed by the cutline of a context d iﬀ c is enclosed by d.

We adopt this idea to represent a subgraph of an EGI similarly to the
representation of cuts by cut-lines. In order to do that, the mapping area
of an EGI will be slightly extended such that it captures the subgraph as
well. So let G0 := (V 0, E0, ν0, >0, Cut0, area0, κ0, ρ0) be a subgraph of the EGI
G := (V, E, ν, >, Cut, area, κ) in the context >0. Let s /∈ Cut∪{>} denote the
subgraph. We deﬁne a mapping area : Cut∪{>}∪{s} → P(V ∪E ∪Cut∪{s})
as follows:

area(c) :=






{s} ∪ area(>0) ∩ (V 0 ∪ E0 ∪ Cut0) for c = s
area(>0)\(V 0 ∪ E0 ∪ Cut0) for c = >

area(c) else

This mapping fulﬁlls the same conditions we had for the mapping area for
EGIs, i.e., we have:

a) c1 6= c2 ⇒ area(c1) ∩ area(c2) = ∅ ,
b) V ∪ E ∪ Cut ∪ {s} = S
c) c /∈ arean(c) for each c ∈ Cut ∪ {>} ∪ {s} and n ∈ N

d∈Cut∪{>}∪{s} area(d),

1 Recall that we use the term ‘enclose’ in two diﬀerent meanings: On the mathematical level of EGIs, we had deﬁned an enclosing-relation which had been derived
from the mapping area in subgraphs, on the diagrammatic level of the representations, we said that an item of the diagram is enclosed by a cut-line if and only if
it is placed in the inner region of this cut-line. The latter notation was introduced
right after Def. 7.8, p. 69.

232

21 Working with Diagrams of Peirce’s Graphs

Analogously to Def. 7.3 for formal Alpha graphs resp. Def. 12.2 for EGIs, we
.
can deduce from the mapping area a quasiorder on V
∪ {s} which
.
∪ {s}, a tree. In order to avoid confusion with the already
is, reduced to >
deﬁned order ≤ on V

.
∪ >, we will denote this new order with v.

.
∪ >

.
∪ E

.
∪ E

Now, analogously to the representation of EGIs based on the order ≤, we
can now represent the EGI G with the subgraph G0, based on the order v.
The only diﬀerence to a usual representation for G is that we now have a
further element s, indicating the subgraph, which is drawn similar to cuts
as a smooth, doublepoint-free line. This line is called the subgraph-line of
the subgraph G0. To distinguish it from the cut-lines, we agree to draw the
subgraph-line a dotted manner. As we have area(d) = area(d) for each cut
c 6= >0, and as we have area(>0) = area(>) ∪ area(s), the representation of
G based on v is obtained from an representation of G based on ≤, where the
subgraph-line of s is added to the area-space of >0. Finally, due to he third
and fourth condition of subgraphs (see Def. 12.10), we have:

x ∈ V 0 ∪ E0 ∪ Cut0 ⇐⇒ x ∈ v[s] and x 6= s

(21.1)

Thus the elements of the diagram which are enclosed by the subgraph-line
denote exactly the elements of G which belong to the subgraph.

To exemplify subgraph-lines, we consider again the examples for subgraphs
given on page 135. To ease the comparison, in the ﬁrst row, the representations
of subgraphs from page 135 are repeated; in the second row, the subgraphs are
indicated by subgraph-lines. It should be noted that in the second example,
when the subgraph is indicated by a subgraph-line, it is necessary to represent
the identity-link due to the usual convention for edges to make clear that the
vertices incident to the edge belong to the subgraph, whilst the identity-edge
does not.

Starting on page 132, it has shortly been investigated which diagrams occur as
diagrams of EGIs. It turned out that, as EGIs are based on relational graphs
with dominating nodes, cut-lines have to satisfy the following condition: If
a vertex-spot is enclosed by a cut-line, and if this spot is is connected to

RQQPPRQQPRQQRQQPPRQQPRQQ21 Working with Diagrams of Peirce’s Graphs

233

a relation-sign with an edge-line, then the relation-sign is enclosed by this
cut-line, as well. In short: If a vertex spot is placed within a cut-line, then all
incident relation signs are as well. For subgraphs, we have a similar restriction:
If an edge belongs to a subgraph, then all incident vertices belong to the
subgraph as well (otherwise a subgraph would not be an EGI). Thus we see
that a properly drawn subgraph-line satisﬁes, roughly speaking, the following
condition: If a relation sign as placed within a subgraph line, then all incident
vertices are as well. Moreover, a properly drawn subgraph-line has to fulﬁll
the usual conditions for entities in a diagram. So we can reﬁne our (informal)
deﬁnition of subgraph-lines as follows:

Informal Deﬁnition 21.1 (Subgraph-Lines for Diagrams of EGIs) A
subgraph-line (in the diagram of an EGI) is a closed, doublepoint-free and
smooth curve, which does not touch or cross cut-lines, vertex-spots, or relation signs, which crosses no edge-line more than once, and which satisﬁes: If a
relation-sign is enclosed by the subgraph-line, and if a vertex-spot is connected
to the relation-sign with an edge-line, then the vertex-spot (and the edge-line)
are enclosed by the subgraph-line as well. To distinguish subgraph-lines from
cut-lines, they are drawn in a dotted manner.

We have argued that each subgraph of an EGI can be indicated by a subgraph
line. One the other hand, it is easy to see that if a subgraph-line is added to the
diagram of an EGI, than the elements which are enclosed by the subgraph-line
(more precisely: The elements of the EGI such that their representations are
enclosed by the subgraph line) form a subgraph. To summarize our discussion:

If a diagram of an EGI G is given, and we add to the diagram a
subgraph-line, then this subgraph-line indicates a (uniquely determined) subgraph of G. On the other hand, if G0 is a subgraph of
G, then there exists a diagram of G where G0 can be indicated by a
subgraph-line in this diagram.

It is important to grasp the impact of the phrase ’[. . .] then there exists a
diagram of G[. . .]’. A subgraph G0 of G can be indicated by a subgraph line in
an appropriately chosen diagram. That is, if a diagram of G is already given,
it may happen the subgraph can not be indicated by a subgraph-line which
is added to the diagram. Thus sometimes the graph G has to represented in
a diﬀerent way, i.e., the diagram has to be redrawn, in order to indicate the
subgraph by a subgraph-line. In order to see this, consider the following EGI:

QQR234

21 Working with Diagrams of Peirce’s Graphs

The substructure containing both inner cuts and all what they contain is a
subgraph. But in this representation, this subgraph cannot be indicated by a
subgraph-line. We have to redraw the whole graph in a diﬀerent way in order
indicate the subgraph by a subgraph-line. This is done in the representation
below.

EGs are classes of EGIs. For EGs, we have no notation of a subgraph. This is
due to the fact that diﬀerent EGIs representing the same EGs have diﬀerent
subgraphs. Nonetheless, for the graphical representation of EGs, we can adopt
the notation of subgraph-lines. As we do not have vertex spots in diagrams of
EGs, we set:

Informal Deﬁnition 21.2 (Subgraph-Lines for Diagrams of EGs) A subgraphline in the diagram of a formal existential graph is a closed, doublepoint-free
and smooth curve, which does not touch or cross cut-lines, nor relation signs,
and which does not touch heavily drawn lines (but it is allowed that heavily
drawn lines are crossed). To distinguish subgraph-lines from cut-lines, they
are drawn in a dotted manner. The part of the graph inside the subgraph-line
is called a subgraph of the existential graph.

Of course, there each subgraph-line is directly enclosed either by the sheet of
assertion of by a uniquely given cut-line. Analogously to the formal deﬁnition
for EGIs, we will say that this is the context of the subgraph.

The deﬁnition of subgraphs in diagrams is not a mathematical deﬁnition, as
already the diagrams are not mathematically deﬁned. On the other hand,
this informal deﬁnition is tightly connected to the (still informal) notation of
subgraph-lines in diagrams of EGIs, and we have thoroughly investigated that
these subgraph-lines correspond to the (formally deﬁned) subgraphs in EGIs,
so this informal deﬁnition is reasonable. Nonetheless, this deserves a deeper
discussion. To be more precisely: As all rules of the calculus for EGIs (except
double cut) depend on the notation of a subgraph, we have to investigate
how the rules for EGIs carry over to diagrammatic rules in the diagrammatic
representations of EGs.

Let us, before we start this investigation, ﬁrst collect some simple facts about
subgraphs in diagrams of EGs.

Recall how diagrams of EGIs are converted to diagrams of EGs. First of all,
it is easy to see that if we have a diagram of an EGI G with a subgraph
line s, then this line is a subgraph line in the corresponding diagram of the
corresponding EG [G]∼.

QQR21 Working with Diagrams of Peirce’s Graphs

235

On the other hand, if a diagram of an EG E with subgraph-line in is given, then
we can ﬁnd an EGI G0 ∈ E with a (not necessarily unique) given subgraph G0,
such that there is a diagram of G0 with a subgraph-line denoting G0 which can
be converted –including the subgraph-line– into the given diagram of E. This
shall be discussed with a small example. Consider the following diagram of an
EG (stating that there is a minimal natural number) with a subgraph-line.

Below, you ﬁnd a two diagrams of an EGI representing the given EG.

Please note that in the left diagram, the dotted line is not a subgraph-line for
the EGI. Recall that if a relation-sign is enclosed by the subgraph-line, and
if a vertex-spot is connected to the relation-sign with an edge-line, then the
vertex-spot has to be enclosed by the subgraph-line as well. This does not hold
for none of the two vertices in the left diagram. The right diagram is better
drawn for our purpose, thus this condition is respected for the right vertex.
But there is no way to redraw the right diagram such that the condition can
be fulﬁlled for the left vertex as well. But the transformation rules for ligatures
allows to insert additional vertices. By doing so, we can obtain a graph G0 as
described above. Below, an example is given.

To summarize: If the diagram of an EGI with a subgraph-line is given, then
in the corresponding diagram of the corresponding EG, this subgraph-line is
still a subgraph line. Vice versa, if the diagram of an EG with a subgraph-line
is given, there exists an EGI representing that EG such that this EGI has
an diagram –including a subgraph-line– which corresponds to the diagram of
the EG. The existence of an EGI which represents the EG is suﬃcient for
the intended investigation how the calculus for EGIs can be transferred to
a purely graphical calculus for the diagrams of EGs: Recall that an EG Ea
entails an EG Eb if there exist EGIs Ga, Gb, with Ea = [Ga]∼, Eb = [Gb]∼
and Ga ‘ Gb.
Now we can ﬁnally investigate how this calculus for EGIs can be transferred
to a purely graphical calculus for diagrams of EGs. In fact, due to the discussion so far, we could simply adopt the rules for EGIs as rules for the diagrams

236

21 Working with Diagrams of Peirce’s Graphs

of EGs. But recall that in the rules for EGIs, we had to distinguish between
subgraphs and closed subgraphs. The iteration and deiteration rule work ﬁne
with subgraphs, but as erasing or inserting a non-closed subgraph from resp.
into an EGI would lead to a non well-formed EGI, thus it is only allowed to
erase or insert closed] subgraphs. For diagrams of EGs, this distinction is not
needed. For this reason, the erasure and insertion rule are, given as graphical transformation rules for the diagrams of EGs, simpliﬁed. The graphical
transformation rules can be described as follows:

• Erasure: Let a diagram of an EG be given with a subgraph line s in a
positive context. Then s and all what is scribed inside s can be erased.
This operation includes the right to cut heavily drawn lines, where they
cross s. Moreover, this operation includes the right to erase parts of a
heavily drawn line in a positive context.

• Insertion: Let a diagram of an EG be given with a cut-line cl of a negative
cut c. Then the diagram D0 of an arbitrary graph may be scribed inside
the area-space of cl. This operation includes the right to connect points
on heavily drawn lines of the inserted graph, which are directly placed on
the sheet of assertion of Go, with points on heavily drawn lines placed in
the area-space of cl.

• iteration:

– Let a diagram of an EG be given with a subgraph G0 (indicated by a
subgraph line) in a context c (the sheet of assertion; or a cut, indicated
by a cut-line) and let d be a context which is identical to c or enclosed
by c, and which does not belong to G0. Then a copy of G0 may be
scribed on the area-space of d. In this transformation, the following is
allowed: If we have a heavily drawn point p of G0 from which a heavily
drawn line inwardly (particularly, it crosses no cut-line more than once)
to a point in d, then this point in d may be connected with the copy
of p.

– It is allowed to add new branches to a ligature, or to extend any line

of identity inwardly through cuts.

• deiteration: If G0 is a subgraph of G which could have been inserted by

rule of iteration, then it may be erased.

• double cuts: Double cuts, i.e. two cut-lines c1, c2 such that there is nothing between them, except lines of identity (heavily drawn lines with no
branches and which do not cross and cuts) which start on c1 and end on
c2, may be inserted into or erased from any diagram of an EG.

• erasing a vertex: An isolated vertex spot may be erased from arbitrary

contexts.

• inserting a vertex An isolated vertex spot may be inserted in arbitrary

contexts.

21 Working with Diagrams of Peirce’s Graphs

237

All rules –except erasure and insertion– are informally descriptions of the formally deﬁned rules for EGIs, adopted for diagrams of EGs. For this reason,
each application of a formal rule corresponds to an application of the corresponding graphical rule, and vice versa. Thus it remains to discuss how the
graphical erasure rule and insertion rule are related to the formal erasure rule
and insertion rule for EGIs. To be more precisely: We have to show that each
application of a formal rule for EGIs is reﬂected by the diagrammatic rules,
and vice versa.

As the rules are dual to each other, it is suﬃcient to discuss the erasure-rule.
Let us recall this rule for EGIs: In positive contexts, any directly enclosed
edge, isolated vertex, and closed subgraph may be erased.

Let us ﬁrst assume that we have an EGI G := (V, E, ν, >, Cut, area, κ) with
a closed subgraph G0, which is erased from a positive cut c. There exists a
diagram of G, where G0 is indicated by a subgraph line s. This subgraph
line does not cross any other graphical items of diagram. Obviously, s is a
subgraph line in the corresponding diagram of the corresponding EG [G]∼,
and erasing G0 corresponds to erasing the part of the diagram of [G]∼ what is
written inside s. Thus we see that this application of the formal erasure-rule
is reﬂected by the diagrammatic erasure rule for diagrams of EGs.

As an isolated vertex is a closed subgraph, this argument holds for the erasure
of an isolated vertex from G as well.

Let us ﬁnally assume that an edge e in c is erased from G. This case is a little
bit tricky, so let us ﬁrst ease the discussion of this case, we assume that e is
an 1-ary edge, i.e. we have ν(e) = v for a v ∈ V . We have to distinguish the
cases ctx(e) = ctx(v) and ctx(e) < ctx(v). The latter case is not reﬂected by
the diagrammatic erasure rule for diagrams of EGs: We need furthermore an
application of the graphical deiteration rule. This shall be exempliﬁed with
a simple example. We consider two diﬀerent EGIs which represent the same
EG. In both EGS, the edge labeled with R is erased.

Consider ﬁrst the following EGIs, where the second EGI is obtained from the
ﬁrst EGI by erasing the edge e labeled with R.

‘

This application of the rule on EGIs has the following graphical counterpart
for the corresponding EGs:

‘

This works ﬁne as the vertex v connected to e is placed in the same cut, i.e.,
we had ctx(e) = ctx(v). Let us now consider an example where this condition

QRQQRQ238

21 Working with Diagrams of Peirce’s Graphs

is violated.

‘

Note that this application of the erasure rule on EGIs is not directly reﬂected
by the graphical erasure rule. Instead, we need an additional application of the
graphical deiteration rule, which allows to retract heavily draw lines outwards
through cuts. Thus, on the level of diagrams of EGs, erasing the edge is carried
out in two steps as follows:

erasure
‘

deit.
‘

The idea behind this example can easily be lifted to the erasure of an nary edge e = (v1, . . . , vn) from an EGI G: On the level on the diagrams of
EGs, this erasure is reﬂected by an application of the graphical erasure rule,
followed by an application of the graphical deiteration rule for each i with
ctx(vi) > ctx(e).2
So far we have seen that an application of the erasure rule for a formal EGI G
is reﬂected by an application of the graphical erasure rule, possibly followed
by some application of the graphical deiteration rule, for the diagram of the
corresponding EG [G]∼.
Let us now discuss the inverse direction, i.e., we have two diagrams of EGs
Ea, Eb where the diagram of Eb is obtained from the diagram of Ea by an
application of the graphical erasure rule. That is, in the diagram of Ea, we have
a subgraph-line s indicating a subgraph, and the diagram of Gb is obtained
from the diagram of Gb by erasing s and what is scribed inside s.
In the erasure rule for EGIs, only closed subgraphs can be erased. If the
subgraph line s in the diagram of Ea does not cross any heavily drawn line,
then it corresponds to a subgraph line of a closed subgraph G0 of an EGI Ga
with [Ga]∼ = Ea, thus in this case, the application of the graphical erasure
rule corresponds to an application of the formal erasure rule for EGIs. So we
have to discuss the case where s might cross heavily drawn lines. The basic
idea for this case has already been discussed on the end of Sec. 14.1, page 151:
Each time s crosses a heavily drawn line, the line is broken in this place with
the erasure rule. This shall be exempliﬁed with the EG from above. Consider
the following application of the graphical erasure rule

‘

(21.2)

We have to ﬁnd EGIs Ga, Gb such that the left diagram is a diagram of [Ga]∼,
the right diagram is a diagram of [Gb]∼, and we have Ga ‘ Gb.

2 This holds even if we have a vertex v which is attached more than once to e.

QRQQRQQ21 Working with Diagrams of Peirce’s Graphs

239

The heavily drawn lines in the diagrams of EGs correspond to vertex-spots
and edge-lines in EGIs. Due to the transformation rules for ligatures, we can
assume that we have an EGI Ga such that if s crosses an edge-line in its graphical representation (which can be transformed into a graphical representation
for [Ga]∼ ), then this edge-line is the edge-line of an identity edge between
two vertices such that both vertices are placed in the context of the subgraph
and such that in the graphical representation of the EGI, one vertex-spot is
placed inside and the other vertex is placed outside the subgraph-line. For our
example, we can choose Ga as follows:

(In the diagram, I omitted to label the identity edges with the relation name
‘ .=’). Now we can erase the edges of which the edge-lines in the diagram cross
the subgraph-line with the erasure rule for EGIs. We obtain:

Now the subgraph-line indicates a closed subgraph, which can be erased with
the formal erasure rule. We get:

This is the desired EGI Gb, as the diagram of [Gb]∼ is the right diagram of
Eqn. (21.2).

The idea of this example applies to arbitrary diagrams of EGs. That is: If we
have two diagrams of two EGs Ea, Eb where the diagram of Eb is obtained
from the diagram of Ea by an application of the graphical erasure rule, then
we can ﬁnd EGIs Ga, Gb with [Ga]∼ = Ea, Eb = [Gb]∼, and we can derive
Gb from Ga by ﬁrst erasing some identity edges and then a closed subgraph
with the formal erasure rule. Moreover, it shows that the graphical erasure of
a part of a heavily drawn line in a positive context corresponds to the formal
erasure of an identity edge in an accordingly chosen EGI.

So far we have elaborated how the formal erasure rule for EGIs and the
graphical erasure rule are related to each other. The insertion rule is simply
the inverse direction of the erasure rule, restricted to negative contexts (in
contrast to the restriction to a positive context in the erasure rule). For this
reason, the discussion can be applied for the insertion-rule as well. That is: An
application of the formal insertion-rule for EGIs corresponds to an an application of the graphical insertion rule, in the case of inserting an edge possibly

240

21 Working with Diagrams of Peirce’s Graphs

preceeded by some applications of the graphical iteration rule. Vice versa, an
application of the graphical insertion rule corresponds to an application of
the formal insertion rule (for closed subgraphs), possibly followed by inserting
some identity edges.

As already mentioned, the graphical rules iteration, deiteration and double
cut for the diagrams of existential graphs correspond directly to the formally
deﬁned rules for EGIs. As we now have worked out all rules, including the
important notation of a subgraph, in a graphical manner, we ﬁnally have
developed a purely diagrammatic logic system.

21 Working with Diagrams of Peirce’s Graphs

241

Extending the System

22

Overview

In the last chapters, Peirce’s system of existential graphs has been intensively
investigated, and they have been developed as a diagrammatic version of ﬁrst
order logic.

In the common symbolic formalizations of ﬁrst order logic, the formulas formalize statements about objects, relations, and functions. But as mentioned,
Peirce did not incorporate objects names or function names into EGs, i.e., he
treated all names in EGs as names for predicates (see Sect. 11.2). The next
two chapters show how the syntax, semantics, and calculus for EGIs have to
be extended in order to have names for objects and functions as well. As functions are special relations, the approach for function names is on the side of
the syntax straight forward: Besides relation names, edges can be labeled with
function names as well. names, two diﬀerent accounts are possible: We can
assign object names to edges or to vertices. In Chpt. 24, we investigate how
the systems of EGIs has to be extended when we assign all types of names to
edges. In Chpt. 23, edges are labeled with relation- function names, but the
object names are assigned to vertices. The graphs of of this chapter will be
therefore called vertex-based EGIs.

Even if we incorporate object- and function names, EGIs and vertex-based
EGIs are still formalizations of judgments. That is, in a given relational structure M, a graph G evaluates to true (tt), which was denoted as usual M |= G,
or to false (ff). In Chpts. 25, the system of EGIs is extended by a syntactical
device which corresponds to free variables of FO. The resulting graphs are
not evaluated to formulas, but to relations instead, and are therefore called
relation graph instances (RGIs). We will consider 0-ary relations as well, and
as there are exactly two 0-ary-relations, which can naturally identiﬁed with
the truth values tt and ff, RGIs are an extension of EGIs.

It is well-known that Peirce’s extensively investigated a logic of relations
(which he called ‘relatives’). Much of the third volume of the collected papers is dedicated to this topic (see for example “Description of a Notation for

244

22 Overview

the Logic of Relatives, Resulting From an Ampliﬁcation of the Conceptions
of Boole’s Calculus of Logic” (3.45–3.149, 1870) “On the Algebra of Logic”
(3.154–3.251, 1880), “Brief Description of the Algebra of Relatives” (3.306–
3.322, 1882), and “the Logic of Relatives” (3.456–3.552, 1897)). As Burch
writes, in Peirce’s thinking ’reasoning is primarily, most elementary, reasoning about relations’ ([Bur91a], p. 2, emphasis by Burch). Burch elaborated
in his book ‘A Peircean Reduction Thesis’ ([Bur91a]) a prototypic version
of Peirce’s algebra of relations, termed Peircean Algebraic Logic (PAL). The
development of PAL is driven to a large extent by the form of EGs. Thus, in
contrast to EGIs with object- and function names, RGIs are still in the line
of reconstructing Peirce’s historical diagrammatic logic.

Finally, in Chpt. 26, a version of Peirce’s famous reduction thesis for relation
graphs is provided. Roughly speaking, for relations the reduction thesis says
that ternary relations suﬃce to construct arbitrary relations, but that not all
relations can be constructed from unary and binary relations alone. A strong
version of this claim has recently be proven by Hereth-Correia and P¨oschel in
[HCP06]. This result will be transfered in Chpt. 26 to relation graphs.

In the formal development of existential graphs, we ﬁrst deﬁned existential
graph instances (EGIs), and then deﬁned formal existential graphs as classes
of EGIs. Two EGIs are in the same class if they can be transformed into each
other with the four transformation rules for ligatures. The introduction so
far indicates that we follow the same path in the next chapters. Indeed, all
investigations in the following chapters are carried out on diﬀerent form of
graph instances (EGIs, vertex-based EGIs and RGIs over an alphabet with
object-, function- and relation-names). For all of these classes, we have a
sound and complete calculus which particularly contains the transformation
rules for ligatures. Thus for all of these classes, we can canonically deﬁne the
corresponding formal graphs (formal existential graphs, formal vertex-based
existential graphs, and formal relation graphs over an extended alphabet). For
this reason, we omit to explicitely deﬁne the diﬀerent forms of formal graphs.

Particularly, the conventions for the diagrammatic representations of formal
existential graphs are adopted for the other classes of formal graphs. For
formal vertex-based existential graphs, an additional discussion is needed. In
vertex-based EGIs, vertices are additionally labeled. For representing these
vertices, two possible conventions are provided. But it turns out that only
one of these conventions is suited for diagrammatically representing formal
vertex-based existential graphs.

23

Adding Constants and Functions

In this (and the next) chapter, it shall be shown how constants and function
names can be added to the system of existential graphs.

An n-ary function F is an n-ary relation which satisﬁes a speciﬁc property,
namely: For each n objects o1, . . . , on−1 exists exactly one object on with
F (o1, o2, . . . , on−1, on). So, functions can be understood as special relations.
But Please note that we adopt the arity of relations for functions. That is, in
our terminology, an n-ary function assigns a value to n − 1 arguments. This
understanding of the arity of a function is not the common one, but it will
ease the forthcoming notation.

Analogously, even an object o can be understood as a special relation, namely
the relation {(o)}. That is: objects correspond to unary relations which contain
exactly one element (or as functions with zero arguments).

For these reasons, it is self-suggesting to employ constants and function names
as special relation names. So far, we had considered EGIs and EGs which are
based on an alphabet as deﬁned in Def. 12.6. In this deﬁnition, only names
for relations are introduced. We ﬁrst extend the deﬁnition of an alphabet:

Deﬁnition 23.1 (Alphabet with Constants, Functions and Relations).
An alphabet is a structure (C, F, R, ar) of constant names, function names and relation names, resp., together with an arity-function
ar : F ∪ R → N which assigns to each function name and relation name its
arity. To ease the notation, we set ar(C) = 1 for each C ∈ C. We assume
.
that the sets C, F, R are pairwise disjoint. The elements of C
∪ R are the
names of the alphabet. Let .= ∈ R2 be a special name which is called identity.

.
∪ F

In EGIs, thus in EGs, the edges had so far been labeled with relation names
(see Def. 12.7). Now, we allow constants and function names as labels for
edges as well. That is, in the deﬁnition of existential graph instances, we have
to modify the condition for the labeling function κ. This is done as follows:

246

23 Adding Constants and Functions

Deﬁnition 23.2 (Existential Graph Instance over (C, F , R, ar)). An
existential graph instance (EGI) over an alphabet A = (C, F, R, ar)
is a structure G := (V, E, ν, >, Cut, area, κ) where

• (V, E, ν, >, Cut, area) is a relational graph with cuts and dom. nodes, and

• κ : E → C

.
∪ F

.
∪ R is a mapping such that |e| = ar(κ(e)) for each e ∈ E.

Similar to Def. 12.7, the system of all (extended) EGIs over A will be denoted
by EGI A (it will be clear from the used alphabet whether we consider EGIs as
deﬁned in Def. 12.7 or in this deﬁnition).

Of course, we have to modify the semantics for EGIs as well: n-ary function
names have to interpreted as n-ary functions over the universe of discourse,
and constants have to be interpreted as objects in the universe of discourse.
That is, the models for the herein deﬁned EGIs are as follows:

A reDeﬁnition 23.3 (Relational Structures over (C, F , R, ar)).
lational structure or relational model over an alphabet A =
(C, F, R, ar) is a pair M := (U, I) consisting of a nonempty universe U and
a function I := IC ∪ IF ∪ IR with

1. IC : C → U ,
2. IF : F → S

k∈N P(U k) is a mapping such that for each F ∈ F with

ar(F ) = k, I(F ) ∈ U k is (total) function I(F ) : U k−1 → U , and

3. IR : R → S

k∈N P(U k) is a mapping such that for each R ∈ F with
ar(R) = k, I(R) ∈ U k is a relation. The name ’ .=’ is mapped to the
identity relation on U .

With the understanding that objects u (by implicitly identifying an object
u ∈ U with the unary relation {(u)}) and functions are special relations, the
models we have just deﬁned are a restriction of the models of Def. 13.1, where
each name of arity n is mapped to an arbitrary n-ary relation.

Of course, when considering constants and function names, we have new entailments between graphs. For example, if C is a constant, the empty sheet of
C . Thus it must be possible
assertion (semantically) entails the graph
to derive this graph from the empty sheet of assertion.

s

The new entailments must be reﬂected by the calculus, thus the calculus has
to be extended in order to capture the speciﬁc properties of constants and
functions. There are basically two approaches: Firstly, we can add axioms,
secondly, we can add new rules to the calculus. Besides the empty sheet of
assertion, Peirce’s calculus for existential graphs has no axioms. To preserve
this property, we will adopt he second approach.

23.1 General Logical Background

23.1 General Logical Background

247

Before the new rules for constants and function names are introduced, this
sections aims to describe the methodology how this shall be done.

As already mentioned, constants and function names can be understood as
relation names which are mapped to relations with speciﬁc properties. If we
have an alphabet A0 = (C, F, R, ar) with constants and function names, we
.
can then consider the alphabet A := (C
∪ R, ar), where each name is
now understood as relation name. In this understanding, each EGI over A0 is
an EGI over A as well. Moreover, if M0 := (U, I) with I 0 := I 0
R is
relational structure over the alphabet A0, then M := (U, I) with

F ∪ I 0

C ∪ I 0

.
∪ F

1. I(F ) := I 0
2. I(C) := {(I 0

C(C)}

F (F ) and I(R) := I 0

R(R) for each F ∈ F and each R ∈ R, and

is the corresponding model (model with respect to Def. 13.1) over the alphabet
A. We implicitly identify M and M0. Due to this convention, each model over
A0 is an model over A as well. But the models for A0 form a subclass of the
models for A. That is, if we denote the models for A0 with M2 and the models
for A with M1, we have M2 ( M1.
We therefore have to deal with two classes of models. This yields two entailment relations as well. In the following, if H is a set of EGIs and if G is an
EGI such that M |= G for each relational structure M ∈ Mi with M |= G0
for each G0 ∈ H, we write H |=i G.
In the Beta part of this treatise, EGs have been evaluated in M1, and we had
obtained a sound and complete calculus. In the following, this calculus shall
be denoted by ‘1. (This use of the symbol ‘‘’ is a little bit sloppy: Usually,
the symbol denotes the syntactical entailment relation between formulas of a
given logic, which is obtained from a set of rules. We will use ‘‘’ in this sense
as well, but the set of rules shall also be denoted with ‘‘’. It will be clear from
the context which use of ‘‘’ is intended.) The soundness and completeness of
‘1 can be now restated as follows: If H ∪ {G} is a set of EGIs over A, we have

H ‘1 G ⇐⇒ H |=1 G

(23.1)

We seek a calculus ‘2 which extends ‘1 (that is, ‘2 has new rules, which
will informally be denoted by ‘2 ⊇ ‘1) and which is sound and complete with
respect to M2.
The calculus ‘1, and hence ‘2 as well, encompasses the 5 basic-rules of Peirce.
Thus for both calculi, the deduction theorem (see Thm. 8.7) holds, i.e., for
i = 1, 2, we have

Ga ‘i Gb ⇐⇒ ‘i

(cid:19)

(cid:11)
Ga Gb
(cid:10)

(cid:18)

(cid:8)
(cid:9)

(cid:16)

(cid:17)

(23.2)

248

23 Adding Constants and Functions

We will extend ‘1 to ‘2 as follows: First of all, the new rules in ‘2 have to
be sound. Then for a set of graphs H and an EGI G we have

H ‘2 G =⇒ H |=2 G

(23.3)

On the other hand, let us assume that for each M ∈ M1\M2, there exists a
graph GM with

‘2 GM and M 6|= GM
If the last two assumptions (23.3) and (23.4) hold, we obtain that ‘2 is an
adequate calculus, as the following theorem shows.

(23.4)

Theorem 23.4 (Completeness of ‘2). A set H ∪ {G} of EGIs over an
alphabet A := (C, F, R, ar) satisﬁes

H |=2 G =⇒ H ‘2 G

Proof: Let H2 := {GM | M ∈ M1\M2}. From (23.3) we conclude: |=2 GM
for all GM ∈ H2. Now (23.4) yields:

M2 = {M ∈ M1 | M |= G for all G ∈ H2}

(23.5)

Now let H ∪ {G} be an arbitrary set of graphs. We get:
H |=2 G Def⇐⇒ f.a. M ∈ M2 : if M |= G0 for all G0 ∈ H, then M |= G

(23.5)
⇐⇒ f.a. M ∈ M1 : if M |= G0 for all G ∈ H2 ∪ H, then M |= G
⇐⇒ H ∪ H2 |=1 G

(23.1)
⇐⇒ H ∪ H2 ‘1 G
⇐⇒ there are G1, . . . , Gn ∈ H and G0

G1 G2

. . . Gn G0

1 G0
2

m ∈ H2 with

1, . . . , G0
. . . G0

m ‘1 G

‘2 ⊇ ‘1 , (23.4)

(23.2)
⇐⇒ there are G1, . . . , Gn ∈ H and G0

(cid:19)
G1 G2 . . . Gn G0
(cid:18)

‘1

1 G0

2 . . . G0

1, . . . , G0
(cid:11)
(cid:8)
m Gb
(cid:9)
(cid:10)

=⇒ there are G1, . . . , Gn ∈ H and G0

1, . . . , G0

(cid:19)
G1 G2 . . . Gn G0
(cid:18)

‘2 G0

1 . . . G0
m

1 G0
deit.⇐⇒ there are G1, . . . , Gn ∈ H and G0
(cid:19)
(cid:11)
G1 G2 . . . Gn Gb
(cid:10)
(cid:18)

1 . . . G0
m

2 . . . G0
1, . . . , G0
(cid:16)
(cid:8)
(cid:9)

‘2 G0

era.=⇒ there are G1, . . . , Gn ∈ H with ‘2

m ∈ H2 with
(cid:16)

(cid:17)
m ∈ H2 with
(cid:11)
(cid:8)
m Gb
(cid:9)
(cid:10)

(cid:16)

(cid:17)

m ∈ H2 with

(cid:17)
(cid:19)
(cid:11)
G1 . . . Gn Gb
(cid:10)
(cid:18)

(cid:8)
(cid:9)

(cid:16)

(cid:17)

(23.2)
⇐⇒ there are G1, . . . , Gn ∈ H with G1, . . . , Gn ‘2 G
Def.=⇒ H ‘2 G

2

23.2 Extending the Calculus

23.2 Extending the Calculus

249

In this section, the calculus is extended in order to capture the speciﬁc properties of constants and functions. We start the scrutiny with functions.

The following EGI holds in a model (U, I) exactly if F is interpreted as an
n-ary (total) function I(F ) : U n−1 → U :

GF :=

More precisely: The left subgraph is satisﬁed if F is interpreted as partial function (that is, to objects o1, . . . , on−1 exist at most one on with
I(F )(o1, . . . , on)), the right subgraph is satisﬁed if for objects o1, . . . , on−1
exist at least one on with I(F )(o1, . . . , on). In other words: The left subgraph
guarantees the uniqueness, the right subgraph the existence of function values.

According to the last subsection, we have to ﬁnd rules which are sound and
which enable us to derive each graph GF with F ∈ F.

Deﬁnition 23.5 (New Rules for Function Names). The calculus for
.
existential graph instances over the alphabet C
∪ R consists of all rules
of Defs. 12.14 and 15.2. Moreover, if F ∈ F is an n-ary function name, then
the following additional transformations may be performed:

.
∪ F

• Functional Property Rule (uniqueness of values)

Let e and f be two n-ary edges with ν(e) = (v1, . . . , vn−1, ve), ν(f ) =
(v1, . . . , vn−1, vf ),1 ctx(e) = ctx(ve), ctx(f ) = ctx(vf ),2 and κ(e) =
κ(f ) = F . Let c be a context with c ≤ ctx(e) and c ≤ ctx(f ). Then
arbitrary identity-links id with ν(id) = (ve, vf ) may be inserted into c or
erased from c.

• Total Function Rule (existence of values)

Let v1, . . . , vn−1 be vertices, let c be a context with c ≤ ctx(v1), . . . , ctx(vn−1).
Then we can add a vertex vn and an edge e to c with ν(e) = (v1, . . . , vn)
and κ(e) = F . Vice versa, if vn and e are a vertex and an edge in c with
ν(e) = (v1, . . . , vn) and κ(e) = F such that vn is not incident with any
other edge, e and vn may be erased.

1 In Def. 12.1, we deﬁned ve := v for edges e with ν(e) = {(v)}. The notation ve

and vf can be understood to be a generalization of Def. 12.1.

2 The conditions ctx(e) = ctx(ve), ctx(f ) = ctx(vf ) had been added for sake of
convenience, and to keep this calculus closely related to the forthcoming calculus
in the next chapter. But the proof of the soundness of this rule does not need this
conditions, i.e., they could be dismissed. This applies to the forthcoming ’constant
identity rule’ as well.

nn1FFn−1n−111n−1Fn250

23 Adding Constants and Functions

We have to show that these rules are sound are complete. We start with the
soundness of the rules.

If G and G0 are
Lemma 23.6 (The Total Function Rule is Sound).
two EGIs over A := (C, F, R, ar), M := (U, I) is a relational structure with
M |= G and G0 is derived from G with the total function rule, then M |= G0.

Proof: Let G0 be obtained from G by adding a vertex vn and an edge e to c
according to the total function rule. We want to apply Lemma 13.8 to c, so
let ref be a valuation for the context c.

Let us ﬁrst assume that we M |= G[c, ref ]. That is, there is an extension ref
of ref to V ∩area(c) with M |= G[c, ref ]. Let o := I(F )(ref (v1, . . . , ref (vn)).
Then ref 0 := ref ∪ {(vn, o)} is a extended partial valuation for c in G0 which
obviously satisﬁes M |= G[c, ref 0], as the additional edge condition for e in
the context c of G0 holds due to the deﬁnition of ref 0. Particularly, we obtain
M |= G0[c, ref ].
Now let us assume M |= G0[c, ref ]. That is, there is an extension ref 0 of ref
to V ∩ area(c) with M |= G0[c, ref 0]. Let ref := ref 0\{(vn, ref 0(vn))} we
obviously have M |= G[c, ref ], thus we conclude M |= G[c, ref ].

Now Lemma 13.8 yields the lemma.

2

Lemma 23.7 (The Functional Property Rule is Sound). If G and G0
are two EGIs over A := (C, F, R, ar), M := (U, I) is a relational structure
with M |= G and G0 is derived from G with the functional property rule, then
M |= G0.

Proof: Let G0 be obtained from G0 by inserting an identity-link id with ν(id) =
(ve, vf ) into c. We set ce := ctx(e) and cf := ctx(f ). The EGIs G and G0 are
isomorphic except for the context c. First note that the contexts ce and cf
must be comparable. W.l.o.g. we assume ce ≥ cf ≥ c.
We ﬁrst consider the case ce = cf = c. We want to apply Lemma 13.8 to c, so
let refc be a partial valuation for c. In G0 in the context c, we have added the
edge id, thus for c, there is one more edge condition to check. So it is suﬃcient
to show that

(U, I) |= G[c, refc] =⇒ (U, I) |= G0[c, refc]

(23.6)

holds. So let (U, I) |= G[c, refc]. That is, there is an extension refc of refc to
V ∩area(c) with G |= G[c, refc], i.e., refc satisﬁes all edge- and cut-conditions
in c. Particularly, it satisﬁes the edge-conditions for e and f , that is:

(refc(v1), . . . ref (vn−1), refc(ve)) ∈ I(κ(e))
(refc(v1), . . . ref (vn−1), refc(vf )) ∈ I(κ(f ))

and

23.2 Extending the Calculus

251

i.e.,

refc(ve) = I(F ) (refc(v1), . . . refc(vn−1)) = refc(vf )
From this we conclude that the additional edge condition for id in G0 is
satisﬁed by refc. We obtain G0
|= G[c, refc], thus
Eqn. (23.6) holds. Now Lemma 13.8 yields M |= G ⇐⇒ M |= G0.

|= G[c, refc], hence G0

Next we consider the case ce = cf > c. We want to apply Lemma 13.8 to ce,
so let refce be a partial valuation for ce. In order to apply Lemma 13.8, it is
suﬃcient to show that

G |= G[ce, refce ] ⇐⇒ G0 |= G[ce, refce]

(23.7)

holds for each extension refce of refce to area(ce) ∩ V . So let refce be such an
extension, If refce does not satisfy the edge-conditions for e and f , we have
G 6|= G[c, refce] and G0
6|= G[c, refce], thus Eqn. (23.7) holds. So let refce
satisfy the edge-conditions for e and f . Analogously to the case ce = cf = c
we obtain refce (ve) = refce(vf ). Moreover, for each extension refc of refce
to a partial valuation of c, we obtain

G |= G[c, refc] ⇐⇒ G0 |= G[c, refc]

This can be seen analogously to the case ce = cf = c, as G and G0 diﬀer only
by adding the edge edge id in c, but for each extension of refc to area(c) ∩ V ,
the edge-condition for id is due to refce (ve) = refce(vf ) fulﬁlled. Now it can
easily be shown by induction that for each context d with ce > d ≥ c and each
extension refd of refce to area(d) ∩ V , we have

G |= G[d, refd] ⇐⇒ G0 |= G[d, refd]

.

From this we obtain G |= G[ce, refce] ⇐⇒ G0
Eqn. (23.7) holds again.

|= G[ce, refce ],

i.e.,

Next we consider the case ce > cf > c. The basic idea of the proof is analogous
to the last cases, but we have two nested inductions. Again we want to apply
Lemma 13.8 to ce, so let refe be a partial valuation for ce. Again we show that
Eqn. (23.7) holds for each extension refe of refe to area(ce) ∩ V . Similarly
to the last case, we assume that refe satisﬁes the edge-condition for e. It is
suﬃcient to show that

G |= G[cf , reff ] ⇐⇒ G0 |= G[cf , reff ]

(23.8)

holds for each each extension reff of refe to area(cf ) ∩ V : Then similarly
to the last case, an inductive argument yields that for each context d with
ce > d ≥ cf and each extension refd of refce to area(d) ∩ V , we have

G |= G[d, refd] ⇐⇒ G0 |= G[d, refd]

.

From this we obtain G |= G[ce, refe] ⇐⇒ G0
Eqn. (23.7) holds.

|= G[ce, refe] that is,

252

23 Adding Constants and Functions

It remains to show that Eqn. (23.8) holds. Let us consider an extension reff
of refe to area(cf ) ∩ V . To prove Eqn. (23.8), it is suﬃcient to show that

G |= G[cf , reff ] ⇐⇒ G0 |= G[cf , reff ]

(23.9)

holds for each extension reff of reff to area(cf ) ∩ V . Now can perform the
same inductive argument like in the last case. If reff does not satisfy the
edge-condition for f , we are done. If reff satisﬁes the edge-condition, we
have reff (ve) = reff (vf ). Now for each extension refc of reff to area(c) ∩ V ,
we again obtain

G |= G[c, refc] ⇐⇒ G0 |= G[c, refc]

Now from the usual inductive argument we obtain that for each context d
with cf > d ≥ c and each extension refd of reff to area(d) ∩ V , we have

G |= G[d, refd] ⇐⇒ G0 |= G[d, refd]

.

From this we conclude that Eqn. (23.9), thus Eqn. (23.8), holds. This ﬁnishes
the proof for the case ce > cf > c.
Finally, the cases ce > cf = c and cf > ce = c can be handled analogously. 2
Next, the new rules for constants are introduced. As already been mentioned
in the introduction of this chapter, it is well-known that functions f with zero
arguments correspond to objects in the universe of discourse. For this reason,
a distinction between constants and function names is, strictly speaking, not
necessary. So the rules for object names correspond to rules for 1-ary functions
(i.e. functions f with dom(f ) = ∅). Their soundness and completeness can be
proven analogously to the last section: It is suﬃcient to provide the rules.

Deﬁnition 23.8 (New Rules for Constant Names). The calculus for
.
existential graph instances over the alphabet C
∪ R consists of all rules
of Defs. 12.14, 15.2 and 23.5. Moreover, if C ∈ C is a constant name, the
following additional transformations may be performed:

.
∪ F

• Constant Identity Rule

Let e, f be two unary edges with ν(e) = (ve), ν(f ) = (vf ), ctx(ve) = ctx(e),
ctx(vf ) = ctx(f ),and κ(e) = κ(f ) = C. Let c be a context with c ≤ ctx(e)
and c ≤ ctx(f ). Then arbitrary identity-links id with ν(id) = (ve, vf ) may
be inserted into c or erased from c.

• Existence of Constants Rule

In each context c, we may add a fresh vertex v and an fresh unary edge e
with ν(e) = (v) and κ(e) = C. Vice versa, if v and e are a vertex and an
edge in c with ν(e) = (v) and κ(e) = F such that v is not incident with
any other edge, e and v may be erased from c.
That is: Devices u C may be inserted into or erased from c.

23.3 Examples for EGIs with Constants and Functions

253

As objects are handled like 1-ary functions, we immediately obtain the soundness of the rules from Lem. 23.6 and Lem. 23.7. It remains to prove the completeness of the extended calculus.

Theorem 23.9 (Extended Calculus is Complete). Each set H ∪ {G} of
EGIs over A := (C, F, R, ar) satisﬁes

H |= G =⇒ H ‘ G

Due to the remark before Def. 23.8 and Thm. 23.4, it is suﬃcient to show that
for each F ∈ F, the graph GF can be derived with the new rules. The functional property rule (abbreviated by fp) enables us to derive the left subgraph
of GF as follows:

dc.
‘

ins.
‘

fp.
‘

The right subgraph of GF can be derived with the total function rule (tf):

dc.
‘

ins.
‘

tf.
‘

So we can derive GF as well, thus we are done.

2

23.3 Examples for EGIs with Constants and Functions

In this section, a few examples for graphs with constant and function names
are provided. This will be EGIs as well as formal existential graphs (recall that
we said in Chpt. 22 that formal existential graphs over an extended alphabet
are canonically deﬁned).

In the symbolic notation of logic, if we have constant names and function
names, the notation of terms is usually introduced. For example, if C, D are
constant names, x is a variable and F , G are function names with two arguments, then F (G(C, x), D) is a term. Before the examples are provided,
it shall brieﬂy discussed how terms can be represented within the system of
EGIs.

In the symbolic notation of logic, terms can be used as arguments for other
terms as well. In the syntax of EGIs, constant names and function names
are exactly treated like relation names, thus in this system, we can not use
terms as arguments of other terms. Particularly, the mapping Ψ (see page 206)

1FFn−1n−11nn1FFn−1n−11nn1n−1Fn254

23 Adding Constants and Functions

cannot be applied to formulas with functions, and there is no obvious direct
counterpart of terms in EGIs. So there are two possibilities to translate a
formula f with terms to an EGIs:

1. f is replaced by a semantically equivalent formula f 0, where the object
names and function names are syntactically handled like relation names.
Then f 0 can be translated via Ψ to an EGI.

2. The deﬁnition of Ψ is extended in order to encompass terms.

The ﬁrst possibility can be formalized by a mapping Π, which transforms a
formula with terms into a equivalent formula without terms. It is deﬁned as
follows:

• To each subterm occurrence t of a term which is not a variable, we assign

a fresh variable αt.

• If t is an atomar term which is a constant name C, let Π(t) be the formula

C(αC).

• Let t := F (t1, . . . , tn), where F be a function name with n arguments and

let t1, . . . , tn are terms. Then

Π(t) := Π(t1) ∧ . . . Π(tn) ∧ F (αt1, . . . , αtn, αt)

• For a subformula f := R(t1, . . . , tn), let

Π(f ) := ∃~α(Π(t1) ∧ . . . Π(tn) ∧ R(αt1, . . . , αtn))

Here ~α is the set of all fresh variables αt, where t is a subformula occurrence
of one of the terms ti.

• We set Π(f1 ∧ f2) := Π(f1) ∧ Π(f2), We set Π(¬f ) := ¬Π(f ) and Π(∃α :

f ) := ∃α : Π(f ).

For example, for f := y = F (G(C, x), D), we have

Π(f ) := ∃xC∃XD∃xF ∃xG :

(C(xC) ∧ D(xD) ∧ G(xC, x, xG) ∧ F (xG, xD, xF ) ∧ y = xF )

This formula can be translated with Ψ to an EGI with variables. We have:

Ψ (Π(f ))

:=

123GCxD123Gy23.3 Examples for EGIs with Constants and Functions

255

Instead of ﬁrst converting f , we can alternatively extend the deﬁnition of Ψ ,
as it was provided on page 206). The extended version of Ψ will be denoted
by Ψext. The original deﬁnition of Ψ starts with the translation of atomar
subformulas R(α1, . . . , αn). This start is replaced by the following deﬁnition
of Ψext. In addition to Ψ , we introduce a mapping ΨV which assigns to each
term t a vertex ΨV (t) of Ψ (t) (these vertices so-to-speak correspond to the
new variables αt we used in the deﬁnition of Π. Now Ψext and ΨV are deﬁned
for EGIs over extended alphabets as follows:

Deﬁnition of Ψext and ΨV

• If t is an atomar term which is a variable α, let Ψext(t) be EGI with
variables which contains only one vertex v, labeled with α. Let ΨV (t) := v.
• If t is an atomar term which is a constant name C, let Ψext(t) be EGI with
variables which contains only one generic vertex v and an edge e, where e
which is incident with v and labeled with C. Let ΨV (t) := v.

• Let t := F (t1, . . . , tn), where F be a function name with n arguments
and let t1, . . . , tn are terms. To t1, . . . , tn, we have already assigned graphs
Ψext(t1), . . . , Ψext(tn), which contain dedicated vertices ΨV (t1), . . . , ΨV (tn),
resp. Then let Ψext(t) be the graph which is obtained as follows:
We take the juxtaposition of the graphs Ψext(t1), . . . , Ψext(tn). To the sheet
of assertion, we add a fresh vertex v and an (n + 1)-ary edge e such that e
is labeled with F and we have e = (ΨV (t1), . . . , ΨV (tn), v). Let ΨV (t) := v.
• Now let f := R(t1, . . . , tn), where R is an n-ary relation name and t1, . . . , tn
are terms. Similarly to the last case, let Ψext(f ) be the graph which is
obtained as follows:

We take the juxtaposition of the graphs Ψext(t1), . . . , Ψext(tn). To the sheet
of assertion, we add a fresh n-ary edge e such that e is labeled with R and
we have e = (ΨV (t1), . . . , ΨV (tn)).

• The remaining cases, (f1 ∧ f2, ¬f , ∃α.f ) are handled exactly like in the

original deﬁnition of Ψ .

It can easily shown by induction over the construction of terms that both
approaches yield the same graphs, i.e. for each formula f with terms, we have
Ψ (Π(f )) = Ψext(f ). Moreover, this deﬁnition strictly extends the deﬁnition of
Ψ , i.e. if f does not contain any constant names or function names, we have
Ψext(f ) = Ψ (f ).
To provide an example, let us express that each polynomial of degree 3 has
a root. The formula in FO is as follows: ∀a, b, c, d∃x : ax3 + b2 + cx + d = 0.
Below, the corresponding EGI is depicted. On the right, the mapping ΨV is
visualized by labeling for each the subterm t of ax3 + b2 + cx + d the vertex
ΨV (t) with t.

256

23 Adding Constants and Functions

To provide an example, let us express that each polynomial of degree 3 has
a root. The formula in FO is as follows: ∀a, b, c, d∃x : ax3 + b2 + cx + d = 0.
Below, the corresponding EGI and EG are depicted.

Below, the corresponding formal EG is depicted.

The next example is a formal proof with EGIs for a trivial fact in group theory,
namely the uniqueness of neutral elements. Assume that e1 and e2 are neutral
elements. In FO, this can be expressed as follows:

∀x.x · e1 = e1 = e1 · x

and

∀x.x · e2 = e2 = e2 · x

From this we can conclude e1 = e2. In the following, a formal proof with EGIs
for this fact is provided. We assume that e1, e2 are employed as constant names
and · as function name.
We start with the assumption that e1, e2 are neutral elements, i.e.

......2332132131231231+132+132+322110dcba...2...2321312133132231231+132+1+1323130x2x2x3ax2bx3ax2b+xcx3xc+x3ax2bdcbaxc++dx3ax2b+x+.++....123321321.13213213202+11323123abcd.123.3211e.123.321e223.3 Examples for EGIs with Constants and Functions

257

Erasure yields:

In the ’classical’ proof, the universal quantiﬁed variable x is replaced by e2
resp. e1 in the formulas above. This idea is adopted for EGIs.
First, we insert e1 and e2 (i.e.,
edges which are labeled with
e1 and e2) as follows:

The edges are iterated:

Now we can remove the identity edges with the constant
identity rule.

The next graph is derived with
the existence of constants rule.

Next, we remove the double
cuts and redraw the graph.

We can insert identity edges
with the
identity
constant
rule.

The functional property rule
now allows to add another
identity edge.

With the erasure rule, we can
ﬁnally obtain:

As this graph expresses that e1 and e2 are identical, we are done.
As a ﬁnal, simple example, a proof for formal EGs with constants is provided.
We come back to Peirce’s example about Aristotle which was given in Fig. 11.1
on page 102. Let us assume now that ’Aristotle’ is a name for a constant. If
the graph

1e.123.e2321.1231ee2.e21e321.1231ee2e2.2132ee1e1.1231ee2e2.2132ee1e1.1231ee2.2132ee1e2.1ee21e.231213e2.1ee21e.231213e2.1ee21e.231213e21e258

23 Adding Constants and Functions

is given, we can now add a LoI as follows:

Now we can erase one instance of ’Aristotle’, thus we obtain

which is the graph of Fig. 11.1, drawn slightly diﬀerent.

conqueror of the worldAlexandergreater philosopher thanother thanany disciple ofPlatoAristotlefather of logicrecognized as the prince of philosophersa great naturalista wretched physicistAristotlean asclepiadteacher ofconqueror of the worldAlexandergreater philosopher thanother thanany disciple ofPlatoAristotlefather of logicrecognized as the prince of philosophersa great naturalista wretched physicistAristotlean asclepiadteacher ofconqueror of the worldAlexandergreater philosopher thanother thanany disciple ofPlatoAristotlefather of logicrecognized as the prince of philosophersa great naturalista wretched physicistan asclepiadteacher of24

Vertices with Constants

In the last chapter, we have introduced constants and function names to the
alphabet. Both kinds of names have been employed as special relation names.
For function names, as functions are relations with special properties, this
approach is self-suggesting. For constants, the situation is diﬀerent.

In symbolic notations of logic, when deﬁning the well-formed formulas, constants are syntactically treated like variables. The counterparts of variables in
EGIs1 are vertices, which can roughly be understood as existentially quantiﬁed variables. So another approach to implement constants in EGIs is to label
the vertices with them. This approach shall be discussed and carried out in
this chapter. In order to distinguish the EGIs from the last chapter where constant names are assigned to edges to the EGIs in this chapter where constant
names are assigned to vertices, we call the EGIs in this chapter vertex-based
EGIs.

In the last chapter, we extended the alphabet we consider. Now we extend
slightly the syntax of graphs, thus we need a diﬀerent approach. In the next
section 24.1, the syntax and semantics for EGIs is modiﬁed to vertex-based
EGIs. The correspondence between EGIs and vertex-based EGIs is elaborated in Sec. 24.2, and based on this section, an adequate (i.e., a sound and
complete) calculus for vertex-based EGIs is provided in Sec. 24.3. Finally, in
Sec. 24.4, it is investigated how ligatures are handled in vertex-based EGIs.

24.1 Syntax and Semantics

We start with the syntax for vertex-based EGIs. They are based on an alphabet with constants and function names, as it is deﬁned in Def. 23.1. Moreover,
we have to introduce a new sign ’∗’, called the generic marker.

1 In this chapter, when the terms EGIs and EGs are used, we refer to EGIs and
EGs over extended alphabets, as they have been deﬁned in the last chapter.

260

24 Vertices with Constants

Deﬁnition 24.1 (Vertex-Based Existential Graph Instances).
A
structure G := (V, E, ν, >, Cut, area, κ, ρ) is called a vertex-based existential graph instance (vertex-based EGI) over an alphabet
A = (C, F, R, ar), iﬀ

• (V, E, ν, >, Cut, area) is a relational graph with cuts and dom. nodes,

• κ : E → F

.
∪ R is a mapping such that |e| = ar(κ(e)) for each e ∈ E, and

• ρ : V → {∗}

.
∪ C is a mapping.

We set V ∗ := {v ∈ V | ρ(v) = ∗} and V C := {v ∈ V | ρ(v) ∈ C}. The vertices
v ∈ V ∗ are called generic vertices, and the vertices v ∈ V C are called
constant or object vertices.

Similar to Defs. 12.7 and 23.2, the system of all vertex-based EGIs over A
will be denoted by VEGI A.

Although syntactically (slightly) diﬀerent, there is a close relationship between
the system EGI A, as is has been been elaborated in the last chapter, and
VEGI A. This relationship will be investigated and used in the next sections.
But ﬁrst, the syntactical diﬀerence between EGIs and vertex-based EGIs and
possible diagrammatic representation of the latter shall be discussed.

Beginning on page 128, the conventions for diagrammatically depicting EGIs
have been provided. In these representations, each vertex v has been represented as a bold spot, the vertex-spot of v. Now in vertex-based EGIs, vertices
are additionally labeled. Thus we have mainly two possibilities to represent
vertex-based EGIs:

1. Each vertex v is still drawn as bold spot, but now additionally labeled
with ρ(v) (this representation was used for EGIs with variables as well).
For sake of convenience, we can omit the labeling of generic spots.

2. For a constant vertex v, we use its label ρ(v) instead of the vertex-spot.

In the following, we will use both methods to represent vertex-based EGIs.
These two approaches shall be now discussed with an small example.

Let us consider the sentence ’Socrates is the teacher of Plato, Plato is the
teacher of Aristotle, and Aristotle is the teacher of somebody’. Let us assume
that we have an alphabet A with ’Socrates’, ’Plato’ and ’Aristotle’ as constants
and ’teacher of’ as 2-ary relation name. We ﬁrst formalize the sentence as EGI
G1 := (V1, E1, ν1, >1, ∅, ∅, κ1). We set:

V1 = {v1, v2, v3, v4}
E1 = {e1, e2, e3, e4, e5, e6}
ν1 = {(e1, (v1)), (e2, (v1, v2)), (e3, (v2)), (e4, (v2, v3)), (e5, (v3)), (e4, (v3, v4))}
κ1 = {(e1, Socrates), (e2, teacher of), (e3, Plato),

(e4, teacher of), (e5, (Aristotle)), (e6, (teacher of))}

The graphical representation of G1 is as follows:

24.1 Syntax and Semantics

261

Next, the vertex-based EGI G2 := (V2, E2, ν2, >2, ∅, ∅, κ2, ρ2) formalizes the
sentence as well:

V2 = {v1, v2, v3, v4}
E2 = {e1, e2, e3}
ν2 = {(e1, (v1, v2)), (e2, (v2, v3)), (e3, (v3, v4))}
κ2 = {(e1, teacher of), (e2, teacher of), (e3, teacher of)}
ρ2 = {(v1, Socrates), (v2, Plato), (v3, Aristotle), (v4, ∗)}

Next, the two graphical representations of G2 are provided. Due to the ﬁrst
convention, G2 can be represented as follows:

The second convention yields:

Analogously to the deﬁnition of formal EGs as classes of EGIs, we can introduce formal vertex-based EGs as classes of vertex-based EGIs. When doing so,
the second convention is appropriate. The corresponding formal vertex-based
EG will then depicted as follows:

In Sec. 12.3, further notions like subgraph, (partial) isomorphism, juxtaposition
for EGIs have been formally introduced (see Defs. 12.10, 12.11, 12.12, 12.13).
Strictly speaking, as we have extended the syntax of EGIs, these notions have
to be deﬁned for vertex-based EGIs as well. But recall that all deﬁnitions
had ﬁrst been carried out for relational graphs with cuts, then they had been
canonically lifted to EGIs by additionally demanding that the structures (like
subgraphs or juxtapositions) or mappings (like isomorphisms or partial isomorphisms) respect the labeling κ. Analogously, we can for example deﬁne
subgraphs of vertex-based EGIs as substructures which are subgraphs for the
underlying relational graphs with cuts and which now respect κ and ρ. For this
reason, we will use the terms ’subgraph’, ’isomorphism’ etc for vertex-based
EGIs as well.

For ligatures, it is not that obvious how they should be deﬁned for vertexbased EGIs, as it is not clear whether ligatures must contain only generic
vertices, or not. Thus ligatures will be re-deﬁned in this chapter. On the other
hand, the notation of hooks remains.

11211Socratesteacher ofPlatoteacher ofAristotleteacher of211212teacher of12teacher of12teacher ofPlatoAristotle*Socrates12teacher of12teacher of12teacher ofSocratesPlatoAristotle12teacher ofSocratesPlatoAristotle12teacher of12teacher of262

24 Vertices with Constants

Next, we turn to the semantics for vertex-based EGIs. The semantics for EGIs
was deﬁned in Chpt. 13 and was based on the notion of (partial) valuations
for EGIs, as they had been deﬁned in Def. 13.2. For vertex-based EGIs, any
valuation on the vertices has on the constant vertices to coincide with the
interpretation of the constant names. Thus we have to (slightly) extend the
notions of valuations as follows:

Deﬁnition 24.2 (Partial and Total Valuations). Let a vertex-based EGI
G := (V, E, ν, >, Cut, area, κ) be given and let (U, I) be a relational structure
over A. Each mapping ref : V 0 → U with V C ⊆ V 0 ⊆ V and ref (v) = I(ρ(v))
for all v ∈ V C is called a partial valuation of G. If V 0 = V , then ref is
called (total) valuation of G.
Let c ∈ Cut ∪ {>}. If V 0 ⊇ {v ∈ V ∗ | v > c} and V 0 ∩ {v ∈ V ∗ | v ≤ c} = ∅,
then ref is called partial valuation for c. If V 0 ⊇ {v ∈ V ∗ | v ≥ c} and
V 0 ∩ {v ∈ V ∗ | v < c} = ∅, then ref is called extended partial valuation
for c.

All remaining deﬁnition of Chpt. 13 can now be adopted for vertex-based
EGIs, which yields the formal semantics for vertex-based EGIs. Note that we
can adopt the lemmata and theorems of Chpt. 13 for vertex-based EGIs as
well. Particularly, we will use Thms. 13.7 and 13.8 for vertex-based EGIs.

24.2 Correspondence between vertex-based EGIs and
EGIs

For extended EGIs over an alphabet A := (C, F, R, ar), i.e. for the system
EGI A, we have developed in the last chapter a sound and complete calculus.
The ﬁrst step to adopt this calculus for vertex-based EGIs over A, i.e. for the
system VEGI A is to ﬁnd a reasonable ‘translation’ Ξ : EGI A → VEGI A.

Let us consider two simple EGIs. The ﬁrst one is an EGI we have already
discussed:

G1 :=

.

In order to consider an example where edge labeled with an element C ∈ C
is enclosed by cut, we consider as second example the following EGI with the
meaning ’Socrates is the teacher of someone who is not Plato’.

G2 :=

In EGIs, an edge e labeled with a constant C ∈ C is incident with exactly
one vertex ve. In order to translate extended EGIs to vertex-based EGIs, such

11211Socratesteacher ofPlatoteacher ofAristotleteacher of211211Socratesteacher of2Plato124.2 Correspondence between vertex-based EGIs and EGIs

263

edges have to be converted to labeled vertices. One might think that we simply
ﬁnd a corresponding vertex-based EGI by erasing e and labeling ve with C.
For the ﬁrst graph, this yields the graph

GR

1 :=

which is indeed a reasonable translation of G1. But for G2, this translation
yields

GR

2 :=

thus a graph with a diﬀerent meaning (this graph is, in contrast to G2, not
satisﬁable). Thus this idea for a translation does not work.

We see if we want to convert the edge e to a labeled vertex, this vertex has
to be placed in the same cut as e, thus we cannot use the vertex ve for this
purpose. Instead, we will place a fresh vertex in the cut of e, labeled with C,
and which is linked with an identity edge to ve. Informally depicted, we will
replace an device like

by

(the edge-lines left from ve shall indicate that ve may be incident with other
edges as well, and the segments of cut-lines shall indicate that for an edge
e = (v) with κ(e) = C, it might happen that ctx(e) < ctx(v) holds).
This idea will be captured by the mapping Ξ : EGI A → VEGI A. For our
examples, we will have

Ξ(G1) =

and

Ξ(G2) =

After these examples, the formal deﬁnition of Ξ can be provided.

Deﬁnition 24.3 (Translation from EGIs to Vertex-Based EGIs). Let
G := (V, E, ν, >, Cut, area, κ) be an EGI over the alphabet (C, F, R, ar). Let
EC := {e ∈ e | κ(e) ∈ C}. For each e ∈ EC, let ve be that vertex which
is incident with e, and let v0
e be fresh vertex and ide an fresh edge. Now let
Ξ(G) := (V 0, E0, ν0, >0, Cut0, area0, κ0) be the following vertex-based EGI:

• V 0 := V

.
∪ {v0

e | e ∈ EC},

12teacher of12teacher of12teacher ofSocratesPlatoAristotle2teacher of1PlatoSocratesCC*teacher ofteacher of21221PlatoAristotle**Socratesteacher of*1*2teacher of*1*SocratesPlato264

24 Vertices with Constants

• E0 := E\EC
• ν := ν(cid:12)

(cid:12)E\EC

.
∪ {ide | e ∈ EC},
.
∪ {(ide, (ve, v0

e)) | e ∈ EC}

• >0 := >
• Cut0 := Cut
• area0(c) := area(c)\(EC ∩ area(c))

c ∈ Cut0 ∪ {>0}
.

∪ {(ide, .=) | e ∈ EC}, and

• κ0 := κ
• ρ0 := {(v, ∗) | v ∈ V }

.
∪ {(v0

e, κ(e)) | e ∈ EC}.

.
∪ {v0

e, ide | e ∈ EC ∩ area(c)} for each

For any element k of G which is not an edge labeled with a constant name, k
is an element of Ξ(G) as well. We will write Ξ(k) to refer there is a corresponding element in Ξ(G). Analogously, for any subgraph G0 of G, there exists
a corresponding subgraph in Ξ(G) which will be denoted by Ξ(G0) (for any
edge e ∈ G0 labeled with a constant name, v0
e and ide are the corresponding
elements in Ξ(G0)).

Obviously, if Ξ is applied to an EGI G, each constant vertex in Ξ(G) is induced
by an edge in G, thus it is incident with exactly edge, which is an identity
edge. But in vertex-based EGIs, a constant vertex is allowed to be incident
with an arbitrary number of edges (it can even be isolated). For this reason,
Ξ is not surjective. The range of Ξ is captured by the following deﬁnition.

Deﬁnition 24.4 (Vertex-Based EGIs with Separated Constant Ver-
. Let G := (V, E, ν, >, Cut, area, κ) be an vertex-based EGI such that
tices).
for each vertex v ∈ V C, we have that v is incident with exactly one edge
e, and e has the form e = (w, v) and satisﬁes ctx(e) = ctx(v), κ(e) = .= and
ρ(w) = ∗. Then G is said to have Separated Constant Vertices The system of all vertex-based EGIs with separated constant vertices will be denoted
by VEGI sp,A.

The following lemma clariﬁes the relationship between EGI A and VEGI sp,A
and will be the basis for the forthcoming calculus for vertex-based EGIs. It is
easily be shown, thus the proof is omitted.

Lemma 24.5 (Ξ is Meaning-Preserving). The mapping Ξ : EGI A →
VEGI sp,A is a bijection, and it is meaning-preserving, i.e. for each model M
and each EGI G we have

M |= G ⇐⇒ M |= Ξ(G)

.

Particularly, for H ∪ {G} ⊆ EGI A we have

H |= G ⇐⇒ Ξ[H] |= Ξ(G)

.

24.3 Calculus for vertex-based EGIs

24.3 Calculus for vertex-based EGIs

265

In this section, we will develop a sound and complete calculus for vertex-based
EGIs.

In the last chapter, we extended the calculus of EGIs to EGIs over extended
alphabets, which now include constants and function names. For developing
a sound and complete calculus for these extended EGIs, we beneﬁtted of
interpreting constants and function names as special relations. Thus is was
more easily to understand the addition of constants and function names as
a restriction of the class of models, not as syntactical extension of the class
of EGIs. And due to this understanding, it was easy to develop an adequate
calculus for extended EGIs by simply adding some rules.

Now the situation is diﬀerent: We have extended the syntax of EGIs by adding
the additional function ρ. Moreover, we have seen in the last section that
there is no a-priori correspondence between extended EGIs and vertex-based
EGIs, but only between extended EGIs and vertex-based EGIs with separated
constant vertices. But it is this correspondence which will give rise to an
adequate calculus for (arbitrary) vertex-based EGIs.

Of course, we want to take beneﬁt of the adequate calculus for extended EGIs.
So let us ﬁrst consider some simple syntactical problems we have cope with
when we want to adopt this calculus.

1. May the insertion- or erasure-rule be applied to subgraphs which contain

vertices with constants?

2. In the deﬁnition of the iteration/deiteration-rule, we hade to use the relation Θ on vertices (for Θ, see Def 15.1 on page 163), and we need a similar
relation for vertex-based EGIs as well. We have to investigate whether this
relation acts only on generic vertices, or on constant vertices as well.
3. How do we cope with the fact that Ξ does not map onto (VEGI sp)A, but

only onto VEGI sp,A ?

We start with the last problem. Via the mapping Ξ, it is easy to ﬁnd an
adequate calculus for VEGI sp,A, but not for VEGI A. So if we had a rule
which allows to transform each graph of VEGI A into a graph of VEGI sp,A
(and vice versa), then this calculus can be extended to VEGI A. This rule shall
be provided now.

Deﬁnition 24.6 (Separating a Constant Vertex). Let a vertex-based
EGI G := (V, E, ν, >, Cut, area, κ) be given. Let v ∈ V C be a vertex. Let v0
be a fresh vertex and e0 be a fresh edge. Furthermore let c := ctx(v). Now let
G0 := (V 0, E0, ν0, >, Cut, area0, κ0, ρ0) be the graph with

266

24 Vertices with Constants

.
∪ {v0},
.
∪ {e0},

• V 0 := V
• E0 := E
.
∪ {(e0, (v, v0))}
.
∪ {v0, e0}, and for d ∈ Cut0 ∪ {>0} with d 6= c we set

• ν := ν
• area0(c) := area(c)
area0(d) := area(d),

.
∪ {(e0, .=)}, and

• κ0 := κ
• ρ0 := ρ\{(v, ρ(v))} ∪ {(v, ∗), (v0, ρ(v))}.

Then we say that G0 is obtained from G by separating the constant
vertex v (into v and v0) and G is obtained from G0 by deseparating
the constant vertex v0.

Informally depicted, the device

is replaced by

.

For example, if the vertex labeled with ’Plato’ is separated, from

we obtain

First we have to show that this rule is meaning-preserving.

Lemma 24.7 ((De)Separating a Constant Vertex is Sound). If G and
G0 are two vertex-based EGIs such that G0 is obtained from G by separating the
constant vertex v (into v and v0), and if M := (U, I) is a relational structure,
we have

M |= G

⇐⇒ M |= G0

Proof: Let G0 be obtained from G by by separating the object vertex v into
v and v0. Let C := ρ(v) and c := ctx(v). We want to apply Lemma 13.8 to c,
so let ref be a closed partial valuation for the context c.

Let us ﬁrst assume that we M |= G[c, ref ]. That is, there is an extension ref of
ref to V ∩area(c) with M |= G[c, ref ]. Then ref 0 with ref 0 := ref ∪{(v0, C)}
is an extended valuation for c in G0 with M |= G0[c, ref 0].
If we have on the other hand M |= G0[c, ref ], then there is an extension ref 0
of ref to V 0 ∩ area(c) with M |= G[c, ref 0]. Then ref := ref 0\{(v0, C} is an
extended valuation for c in G with M |= G[c, ref ].

Now Lemma 13.8 yields the lemma.

2

C*C12teacher of12teacher of12teacher ofSocratesPlatoAristotleteacher of12teacher ofSocratesAristotleteacher of121212Plato24.3 Calculus for vertex-based EGIs

267

As we have just shown that the separating a constant vertex rule is meaningpreserving, we now know that we can transform with this rule each vertexbased EGI G := (V, E, ν, >, Cut, area, κ) ∈ VEGI A into a vertex-based EGI
Gs ∈ VEGI sp,A by separating each constant vertex v ∈ V C which is not
already separated (and vice versa, we can transform Gs into G). Particularly,
for G ∈ VEGI sp,A we have Gs = G. As (de)separating vertices is sound, for
each vertex-based EGI G := (V, E, ν, >, Cut, area, κ) ∈ VEGI A and for each
model M, we have M |= G ⇔ M |= Gs. Moreover, we have a meaningpreserving bijection mapping Ξ : EGI A → VEGI sp,A. With these facts, we
can now deﬁne an adequate calculus for VEGI A.

To avoid confusion, we use a subscript ’v’ for any calculus for VEGI, i.e. we
write ‘v (’v’ for vertex-based EGI). Similarly, we use a subscript ’e’ for the
calculus for EGI (as in the graphs of EGI, edges are used to denote constants,
we could call them edge-based EGIs, and now ’e’ stands for ’edge-based’).
Moreover, for each rule r of the respective calculus, we use r as superscript to
v G0 iﬀ the vertex-based
refer to this speciﬁc rule. For example, we write G ‘r
EGI G0 can be obtained from the vertex-based EGIG with the rule r.

In the following, let A := (C, F, R, ar) be a ﬁxed alphabet. Now a canonical
idea to deﬁne a calculus (cid:13)v for VEGI A is as follows (we use the sign ’(cid:13)v’
instead of ’‘v’, as it will turn out that this calculus will not be used, and the
sign ’‘v’ is reserved for the calculus which will be employed):

First approach for a calculus for VEGI A:
1. (cid:13)v contains the rules ’separating a constant vertex’ and ’deseparating

a constant vertex’, and

2. for all Ga, Gb ∈ VEGI sp,A and each rule (cid:13)r
v by setting

deﬁne an corresponding rule (cid:13)r

e of the calculus for EGIs we

Ga (cid:13)r

v Gb

:⇐⇒ Ξ −1(Ga) ‘r

e Ξ −1(Gb)

The calculus (cid:13)v is sound and complete: First of all, the rules ’(de)separating
a constant vertex’ are sound due to Lem. 24.7, and all other rules are sound,
as Ξ is due Lem. 24.5 meaning-preserving and as the rules of ‘e are sound.
Secondly, the rules of ‘e are complete on EGI A, and Ξ is a bijective mapping
from EGI A to VEGI sp,A. So, for Gv, G0
v, we can
ﬁnd a proof for Gv (cid:13)v G0
v as follows: First, we derive (Gv)s from Gv, then
we can ﬁnd a proof for (Gv)s (cid:13)v (G0
v is
v)s by deseparating constant vertices. Thus (cid:13)v is sound and
derived from (G0
complete, hence we would be done.

v)s within VEGI sp,A, and ﬁnally, G0

v ∈ VEGI A with Gv |= G0

But this calculus is somehow not convenient to be used for vertex-based EGIs,
as all rules except the rule ’separating a constant vertex’ act only on vertexbased EGIs with separated constant vertices. To see an example, consider the
following vertex-based EGIs.

268

24 Vertices with Constants

G1 :=

G2 :=

The general understanding of the erasure-rule is that in positive contexts, we
can erase parts of a given graph. So we aim that G1 (cid:13)era
v G2 is a application
of the erasure-rule (more precisely: A composition of two applications of the
erasure-rule, namely the erasure of an edge, followed by an erasure of a closed
subgraph). But so far, this derivation is not allowed, as neither G1 nor G2 has
separated constant vertices.

Moreover, we have a speciﬁc peculiarity with the erasure and insertion rule.
The erasure rule for EGIs allows to erase edges labeled with a constant name
(and vice versa, the insertion rule allows to insert an edge with a constant
name). So we would have

as we have

(cid:13)era
v

‘era
e

So now with the erasure rule, it is possible to ’generalize’ the labels of constant
vertices to generic markers in positive context (and vice versa, to ’specialize’
generic vertices to constant vertices in negative contexts). Of course, generalizing the labels of vertices in positive contexts must be possible in any complete
calculus for vertex-based EGIs, but it is not intended that this is a derivation
with a single application of the erasure-rule.
We have an approach for a sound and complete calculus for VEGI A, but in
the light of the purpose of the rules, its rules are too weak, and we have an
unwanted peculiarity in the erasure- and insertion rule. So we need a diﬀerent
approach which (roughly) extends our ﬁrst idea and which copes with the
before mentioned peculiarity.

The essential methodology for appropriately handling vertex-based EGIs will
be: Generic and constant vertices are generally not distinguished, except for
special rules for constants. For example, the erasure-rule simply still allows to
erase arbitrary subgraphs, no matter whether they contain constant vertices
or not. The discussion so far will be made fruitful to show that this calculus
is sound and complete.

In order to make the idea clear, all rules will be provided for vertex-based
EGIs as (slightly) reformulated rules for EGIs. As a ﬁrst step, we redeﬁne ligatures and Θ for vertex-based EGIs. The core of the following two deﬁnitions
directly correspond to Def. 12.8 for ligatures and Def. 15.1 for Θ, but for sake
of convenience and comprehensibility, and as some notations are added, the
deﬁnitions of ligatures and Θ for vertex-based EGIs are completely provided.

12teacher of12teacher of12teacher ofPlatoAristotle*Socrates12teacher ofPlatoSocratesPlatoSocrates12teacher ofSocrates12teacher of*11Socratesteacher of21Plato11Socratesteacher of224.3 Calculus for vertex-based EGIs

269

For an EGI (V, E, ν, >, Cut, area, κ), its ligatures had been introduced as subgraphs of (V, Eid) (strictly speaking, of (V, Eid, ν(cid:12)
(cid:12)Eid), but the mapping ν was
for sake of convenience omitted. See page 126). Now for vertex-based EGIs,
we formally do the same. A ligature may both contain generic and constant
vertices, and the mapping ρ is not part of a ligature. Thus we do not distinguish between generic and constant vertices. Nonetheless, we assign now to
each ligature the set of labels which occur in it.

Deﬁnition 24.8 (Ligature). Let G := (V, E, ν, >, Cut, area, κ) be an EGI.
Then we set Lig(G) := (V, Eid), and Lig(G) is called the ligature-graph
induced by G. Each connected subgraph of (W, F ) of Lig(G) is called a
ligature of G.

If (W, F ) is a ligature, we set ρ(W, F ) := ρ(W ) := {ρ(w) | w ∈ W }. The set
ρ(W, F ) is called the a set of labels of (W, F ). If we have ρ(W ) = {∗},
then (W, F ) is called a generic ligature.

Next we deﬁne the relation Θ for vertex-based EGIs. Again, we do not distinguish between constant and generic vertices.

Deﬁnition 24.9 (Θ). Let G := (V, E, ν, >, Cut, area, κ) be an vertex-based
EGI. On V , a relation Θ is deﬁned as follows: Let v, w ∈ V be two vertices.
We set vΘw iﬀ there exist vertices v1, . . . , vn (n ∈ N) with

1. either v = v1 and vn = w, or w = v1 and vn = v,
2. ctx(v1) ≥ ctx(v2) ≥ . . . ≥ ctx(vn), and
3. for each i = 1, . . . , n − 1, there exists an identity edge ei = {vi, vi+1}

between vi and vi+1 with ctx(ei) = ctx(vi+1).

If we have moreover vi ∈ V ∗ for i = 1, . . . , n, we write vΘ∗w.

a, v0

Please note the following: If G := (V, E, ν, >, Cut, area, κ) ∈ VEGI A, if
b are the corresponding vertices in Gs, then
va, vb ∈ V are vertices, and if v0
we have vaΘvb ⇔ v0
b . This shows that extending Θ to non-generic vertices is not necessary. For example, Θ will be used in the iteration/deiteration
rule, but it will turn out that it would be suﬃcient to consider Θ∗ instead.
Nonetheless, Θ is extended as the overall idea of the forthcoming calculus is
to avoid a too strong distinction between generic and constant vertices.

aΘ∗v0

On the following two pages, the calculus for vertex-based EGIs is provided. All
rules are basically the original rules for EGIs (for the transformation rules for
ligatures and Peirce’s rules for EGIs) resp. the counterparts of the new rules
(for constants and functions) for extended EGIs, reformulated for vertex-based
EGIs. Nonetheless, as mentioned above, the calculus is completely listed in
the well-known semiformal manner. As all rules have already been provided in
diﬀerent previous chapters of this treatise, their formal deﬁnitions are omitted
now.

270

24 Vertices with Constants

Deﬁnition 24.10 (Calculus for vertex-based EGIs). Let an vertexbased EGI G := (V, E, ν, >, Cut, area, κ) over the alphabet A := (C, F, R, ar)
be given. Then the following transformations may be carried out:

• Transformation Rules for Ligatures

– isomorphism G may be substituted by an isomorphic copy of itself.

– changing the orientation of an identity edge

Let e ∈ Eid. Then we may change the orientation of e.

– adding a generic vertex to a ligature

Let v ∈ V be a vertex which is attached to a hook (e, i). Furthermore
let c be a context with ctx(v) ≥ c ≥ ctx(e). Then the following may be
done: In c, a new generic vertex v0 and a new identity-edge between v
and v0 is inserted. On (e, i), v is replaced by v0.

– removing a generic vertex from a ligature

The rule ‘adding a vertex to a ligature’ may be reversed.

• Peirce’s Rules for Existential Graphs

– erasure

In positive contexts, any directly enclosed edge, isolated vertex, and
closed subgraph may be erased.

– insertion

In negative contexts, any directly enclosed edge, isolated vertex, and
closed subgraph may be inserted.

– iteration

· Let G0 := (V0, E0, ν0, >0, Cut0, area0, κ0) be a (not necessarily
closed) subgraph of G and let c ≤ ctx(G0) be a context such that
c /∈ Cut0. Then a copy of G0 may be inserted into c.
Moreover, if v ∈ V0 with ctx(v) = ctx(U) is a vertex, and if w ∈ V0
with ctx(w) = c is a vertex with vΘw, then an identity edge between
v and w may be inserted into c.

·

If v ∈ V is a vertex and c ≤ ctx(v) a cut, then a new vertex w and
an identity edge between v and w may be inserted into c.

– deiteration

If G0 is a subgraph of G which could have been inserted by rule of
iteration, then it may be erased.

– double cuts

Double cuts may be inserted or erased.

24.3 Calculus for vertex-based EGIs

271

– erasing a vertex

An isolated vertex may be erased from arbitrary contexts.

– inserting a vertex

An isolated vertex may be inserted in arbitrary contexts.

• Rules for Functions

– Functional Property Rule (uniqueness of values)

Let e and f be two n-ary edges such that ν(e) = (v1, . . . , vn−1, ve),
ν(f ) = (v1, . . . , vn−1, vf ), ctx(e) = ctx(ve), ctx(f ) = ctx(vf ), and
κ(e) = κ(f ) = F . Let c be a context with c ≤ ctx(e) and c ≤ ctx(f ).
Then arbitrary identity-links id with ν(id) = (ve, vf ) may be inserted
into c or erased from c.

– Total Function Rule (existence of values)

Let v1, . . . , vn−1 be vertices, let c ≤ ctx(v1), . . . , ctx(vn−1) be a context.
Then we can add a generic2 vertex vn and an edge e to c with ν(e) =
(v1, . . . , vn) and κ(e) = F . Vice versa, if vn and e are a vertex and an
edge in c with ν(e) = (v1, . . . , vn) and κ(e) = F such that vn is not
incident with any other edge, e and vn may be erased.

• Rules for Constants

– Constant Identity Rule

Let C ∈ C be a constant name. Let v, w be vertices with ρ(v) = ρ(w) =
C. Let c be a context with c ≤ ctx(v) and c ≤ ctx(w). Then arbitrary
identity-links id with ν(id) = (ve, vf ) may be inserted into d or erased
from c.

– Existence of Constants Rule

Let C be a constant name. In each context c, we may add a fresh vertex
v with ρ(v) = C. Vice versa, if v is an isolated vertex with ρ(v) = C v
may be erased from c.

– Separating a constant vertex

If v ∈ V C is a constant vertex, then v may be separated (see Def. 24.6).

– Deseparating a constant vertex

If G could be obtained from G0 by separating a constant vertex v then
G0 may be obtained from G by deseparating v.

Similar to the last chapters, for two vertex-based EGIs Ga, Gb, we set Ga ∼ Gb
if Ga can be transformed into G−b with the transformation rules for ligatures,
and formal vertex-based EGs are the classes of vertex-based EGIs with respect
to ∼. For this reason, it was important that in the rules ’adding a generic

2 Of course, we usually cannot add constant or query vertices with this rule.

272

24 Vertices with Constants

vertex to a ligature’ and ’removing a generic vertex from a ligature’, only
generic vertices are considered.

We have eventually deﬁned a calculus for vertex-based EGIs which is convenient, i.e. the general ideas behind the rules for EGIs is adopted for vertexbased EGIs. We now have to show that this calculus is adequate.

Theorem 24.11 (‘v is Sound and Complete for VEGI A). For H ∪
{G} ⊆ VEGI A we have

H |= G

⇐⇒

H ‘v G

Proof: The soundness of the rules can be proven analogously to the soundness
of their counterparts for EGIs. For the only new rule for vertex-based EGIs,
i.e. for the rule ’(de)separating a constant vertex’, its soundness was proven
in Lem. 24.7.
So it remains to show that ‘v is complete. Due to the discussion for (cid:13)v, it is
suﬃcient to show that for vertex-based EGIs with separated constant vertices
Ga, Gb and each rule r of (cid:13)r

v, we have

Ga (cid:13)r

v Gb

=⇒

Ga ‘v Gb

That is, as we deﬁned Ga (cid:13)r
for extended EGIs, we have to show

v Gb :⇔ Ξ −1(Ga) ‘r

e Ξ −1(Gb), for each rule ‘r
e

Ξ −1(Ga) ‘r

e Ξ −1(Gb)

=⇒

Ga ‘v Gb

Recall that Ξ : EGI A → VEGI A is bijective (and meaning-preserving). Thus
is is suﬃcient to show that for two extended EGIs G1, G2, we have

G1 ‘r

e G2

=⇒

Ξ(G1) ‘v Ξ(G2)

(24.1)

In the following, we will show Eqn. (24.1) for each rule. In most (but not in
all) cases, a derivational step can be canonically carried over from EGIs to
vertex-based EGIs, i.e., we actually prove the stronger implication

G1 ‘r

e G2 ⇒ Ξ(G1) ‘r

v Ξ(G2)

(24.2)

• isomorphism, changing the orientation of an identity edge, adding

a vertex to a ligature, removing a vertex from a ligature

For these rules, it is easy to see that Eqn. (24.2) holds.

• erasure/insertion

Due to symmetry reasons, it is suﬃcient to consider the erasure rule. erasure. We have three cases to distinguish: The erasure of a subgraph of G1,
the erasure of an edge of G1, and the erasure of an isolated vertex of G1.

24.3 Calculus for vertex-based EGIs

273

Let G0 be a closed subgraph of G1 in a positive context, and G2 is derived
from G1 by erasing G0. Then there is a corresponding subgraph Ξ(G0) in
Ξ(G1), the erasure rule of ‘v allows to erase Ξ(G0) from Ξ(GR
1 ), which
yields Ξ(GR
2 ). Thus Eqn. (24.2) is shown. As isolated vertices are closed
subgraphs, the erasure of an isolated vertex in G1 can be transferred to
the erasure of the corresponding isolated vertex in Ξ(G1) as well.
Now let e be an edge in G1 in an isolated vertex. If e is not labeled with
a constant name, then there exists a corresponding edge Ξ(e) in Ξ(G1),
which can be erased with the erasure rule of ‘v, i.e. Eqn. (24.2) holds.
So it remains to consider the edges e labeled with an C ∈ C. Let e be
incident with ve, let v0
e and ide be the fresh vertex and fresh identity edge
which correspond to e in Ξ(G1) (see Def. 24.3). Then we can ﬁrst erase ide
in Ξ(G1), then we can erase the (now) isolated vertex v0
e, and we obtain
Ξ(G2). So Eqn. (24.1) (but not Eqn. (24.2)) holds.
Informally depicted, this procedure can be represented as follows:

Ξ−→

‘era
v

‘era
v

|

{z
G1

}

|

{z
Ξ(G1)

}

|

{z
Ξ(G2)

}

• iteration/deiteration

Let G0 := (V,E,ν,>,Cut,area,κ)0 be a subgraph of G1 and let c ≤ ctx(G0)
be a context such that c /∈ Cut0, and G2 is obtained from G1 by iterating G0 into c. Then there is a corresponding subgraph Ξ(G0) in Ξ(G1).
Moreover, if If v ∈ V0 with ctx(v) = ctx(U) is a vertex, and if w ∈ V0 with
ctx(w) = c is a vertex with vΘw, then we have Ξ(v)ΘΞ(w) as well (we
even have Ξ(v)Θ∗Ξ(w), i.e., as already mentioned, it would have been sufﬁcient to consider Θ∗ instead of Θ). So we see that Ξ(G2) can be obtained
from Ξ(G1) with the iteration rule of ‘v, i.e., Eqn. (24.2) holds.
Analogously, if v ∈ V is a vertex, if c ≤ ctx(v) is a cut, and if G2 is
obtained from G1 by inserting a new vertex w and an identity edge between
v and w into c with the second clause of the iteration-rule, then Ξ(G2)
can be obtained from Ξ(G1) by iterating a copy of Ξ(v) into Ξ(c). Thus
Eqn. (24.2) holds again.

• double cut, erasing a vertex, inserting a vertex, Functional Prop-

erty Rule, total function rule

For these rules it is straightforward to see that Eqn. (24.1) holds.

• Constant Identity Rule

Let G1 be an EGI, let C be a constant name, let e, f be two unary edges
with ν(e) = (ve), ν(f ) = (vf ), ctx(ve) = ctx(e), ctx(vf ) = ctx(f ), and

CC*C**274

24 Vertices with Constants

κ(e) = κ(f ) = C, let c be a context with c ≤ ctx(e) and c ≤ ctx(f ), and
let G2 be obtained from G1 by inserting an identity edge id into c.
Using the notation from Def. 24.3, let v0
let ide be the identity edge between ve and v0
ve, and let v0
identity rule allows to add an identity edge id0 = (v0
f in Xi(G1) to c. Now we separate the vertices v0
v0
by ve on the hook (id0, 1) and replace v0
Lem. 16.1, and ﬁnally we deseparate the vertices v0
obtain is Ξ(G2).
Informally depicted with an example, the derivation

e, ide be the vertex labeled with C
e in Xi(G1) which substitute
f , idf be the corresponding elements for vf . The constant
e, v0
e and
f , replace v0
e and v0
e
f by vf on the hook (id0, 2) with
f . The graph we

f ) between v0

e and v0

‘e

with EGIs is replaced by the following derivation with vertex-based EGIs:

|

{z
Ξ(G1)

}

‘v

‘v

‘v

‘v

|

{z
Ξ(G2)

}

The erasure of an identity edge is done analogously.

• Existence of Constants Rule:

If G2 is obtained from G1 by inserting into a context c a fresh vertex v
and an fresh unary edge e with ν(e) = (v) and κ(e) = C, we can derive
Ξ(G2) from Ξ(G1) by ﬁrst inserting a constant vertex v with ρ(v) = C
into c and then by separating v.

The erasure of a vertex labeled with C is proven analogously.

2

24.4 Ligatures in vertex-based EGIs

In Sec. 16.1, several lemmata had been provided which improved the handling
of ligatures. These lemmata had been derived rules, as they have been proven
with the iteration- and deiteration-rules of the calculus. Now the question

CCCC*C*C**C**C****CC**C**C*C*C24.4 Ligatures in vertex-based EGIs

275

arises how the results of Sec. 16.1 can be transferred to vertex-based EGIs,
where ligatures may contain constant vertices as well.

All rules of the calculus for vertex-based EGIs, particularly the iteration- and
deiteration-rule, are extensions of the corresponding rules for EGIs. That is,
each rule which can be applied to EGIs over an alphabet without constant- or
function names can be applied to vertex-based EGIs as well. Thus it is easy
to see that the lemmata of Sec. 16.1 can be applied to generic ligatures. Moreover, iﬀ we have a ligature with constant vertices, we can separate all these
vertices, and in the resulting graph, the resulting ligature (i.e. the ligature
which contains exactly the same vertices and edges, without the fresh vertices
and edges we added) is then a generic ligature. In this respect, we can adopt
the results of Sec. 16.1 for arbitrary ligatures.

On the other hand, the iteration and deiteration rule rely on the relation Θ.
In Def. 24.9 of Θ for vertex-based EGIs, which extends Def. 15.1 of Θ for
EGIs, generic and constant vertices are not distinguished, thus we can adopt
the proofs of Sec. 16.1 for arbitrary ligatures in vertex-based EGIs. But in
these proofs, no application of the iteration or deiteration rule changes the set
of labels of the ligature. So, roughly speaking, we can change a ligature with
the results of Sec. 16.1, as long as we do not change the set of its labels.

For the sake of convenience, for each lemma of Sec. 16.1, a corresponding
lemma for vertex-based EGIs is given. But before we do so, a few new results
for ligatures in vertex-based EGIs are provided.

On page 268, when we discussed the ﬁrst approach for a calculus for vertexbased EGIs, we have seen that it must be possible to ’generalize’ the labels
of constant vertices to generic markers in positive context (and vice versa,
to ’specialize’ generic vertices to constant vertices in negative contexts). This
can now easily be proven with the calculus for vertex-based EGIs.

Lemma 24.12 (Generalizing and Specializing the Labels of Vertices).
Let G := (V, E, ν, >, Cut, area, κ) be an vertex-based EGI. If v ∈ V C is a
positively enclosed vertex, then the label from v may be changed to ∗. Vice
versa, if v ∈ V ∗ is a negatively enclosed vertex, then the label of v may be
changed to a constant name c ∈ C.

Proof: Let G0 be obtained from G by generalizing the label of the positively
enclosed v ∈ V C. Then G0 can be derived from G by ﬁrst separating v, and then
by erasing the fresh edge e0 and the fresh vertex v0. The proof for specializing
2
a label for a negatively enclosed vertex is done analogously.

Secondly, it is possible to ’(de)iterate constant labels’.

Lemma 24.13 ((De)Iterating Constant Labels). Let a vertex-based EGI
G := (V, E, ν, >, Cut, area, κ) be given, let v ∈ V C with C := ρ(v), let w ∈ V
with ctx(v) ≥ ctx(w) and vΘw. If ρ(w) = C, then we can change the label of
w to ∗. Vice versa, if ρ(w) = ∗, then we can change the label of w to C.

276

24 Vertices with Constants

Proof: Let G0 be obtained from G by changing the label from w from C to ∗.
Then G0 can be derived from G as follows: First, v is iterated into ctx(w). As
we have vΘw, we can add an with an identity edge e0 to between v0 and w.
Now G0 can be derived from this graph by deseparating v0.

The second proposition of the lemma is proven analogously.

2

Next, an example for the last two lemmata is provided. We assume that C, D
are constant names and P, Q, R, S, T are relation names.

Lm.24.12
‘

Lm.24.13
‘

From the last lemma, we immediately obtain the following corollary.

Corollary 24.14 (Rearranging Labels of a Ligature in a Context). Let
G := (V, E, ν, >, Cut, area, κ) be an vertex-based EGI. Let (W, F ) be a ligature
which is placed in a context c, i.e., ctx(w) = c = ctx(f ) for all w ∈ W and
f ∈ F . Let G0 be obtained from G by rearranging the labels of (W, F ), i.e. we
have G := (V, E, ν, >, Cut, area, κ, ρ0) with ρ0(cid:12)
(cid:12)V \W = ρ and ρ0(W ) = ρ(W ).
Then G and G0 are equivalent.

Next, the results of Sec. 16.1 (Lem. 16.1, Lem. 16.2, Lem. 16.3 and Def. 16.4)
are revised for vertex-based EGIs. The diﬀerences of the ongoing lemmata
to their counterparts in Sec. 16.1 are, if any, only minor and emphasized by
underlining them. For sake of convenience, the lemmata as such are given,
but the formal deﬁnitions for the transformations, as well as the proofs, are
omitted, as they are canonical extensions of the deﬁnitions and proofs in
Sec. 16.1.

We start with Lemma 16.1. In this lemma, the set of vertices ρ(W ) of the
considered ligature (W, F ) does not change, thus this lemma can be directly
adopted for vertex-based EGIs. That is, we obtain:

Lemma 24.15 (Moving Branches along a Ligature in a Context). Let
G := (V, E, ν, >, Cut, area, κ) be a vertex-based EGI, let va, vb be two vertices
with c := ctx(va) = ctx(vb) and vaΘvb, and let e be an edge such that the hook
(e, i) is attached to va. Let G0 := (V, E, ν0, >, Cut, area, κ) be obtained from
G by replacing va by vb on the hook (e, i). Then G and G0 are syntactically
equivalent.

Lemma 16.2 allowed to extend or restrict ligatures. More precisely: To a given
vertex v of a ligature, new vertices can be attached with identity links, and
this transformation can be reversed. For EGIVs, we have to take care that
the new vertices are labeled the same as v.

RSP11221Q11TDCRSP11221Q11TDCDQ11TDCRSP11221DD24.4 Ligatures in vertex-based EGIs

277

Lemma 24.16 (Extending or Restricting a Ligature in a Context).
Let a vertex-based EGI G := (V, E, ν, >, Cut, area, κ) be given with a vertex
v ∈ V . Let V 0 be a set of fresh vertices and E0 be be a set of fresh edges.
Let G0 := (V 0, E0, ν0, >0, Cut0, area0, κ0) be obtained from G such that all fresh
vertices and edges are placed in the context ctx(v), all fresh edges are iden-
.
∪ V 0 such that we have vΘv0 for each
tity edges between the vertices of {v}
v0 ∈ V 0, and we have ρ(v0) = ρ(v) for all fresh vertices. Then G and G0 are
syntactically equivalent.

Lemma 16.1 and Lemma 16.2 allowed retract a ligature in a context to a single
vertex (and vice versa). This is for vertex-based EGIs not possible any more:
A ligature (W, F ) such that ρ(W ) contains more than one constant name
cannot be retracted to a single vertex. But if all vertices of W are labeled the
same, retracting to a single vertex is still allowed.

Lemma 24.17 (Retracting a Ligature in a Context). Let a vertex-based
EGI G := (V, E, ν, >, Cut, area, κ) be given, let (W, F ) be a ligature which is
placed in a context c and which satisﬁes |ρ(W )| = 1. Let G0 be obtained from
G by retracting (W, F ) to w0. Then G and G0 are syntactically equivalent.

In Def. 16.4, we have summarized the diﬀerent possibilities to rearrange a
ligature in a context, and we concluded from the preceeding lemmata that
rearranging a ligature in a context yields equivalent graphs.

For vertex-based EGIs, we ﬁrst redeﬁne the rearranging of ligatures in the
well-known semi-formal manner. The formal elaboration of this deﬁnition is
a canonical extension of Def. 16.4.

Deﬁnition 24.18 (Rearranging Ligatures in a Context). Let a vertexbased EGI G := (V, E, ν, >, Cut, area, κ) over an alphabet A := (C, F, R, ar)
be given, let (W, F ) be a ligature which is placed in a context c. Let G0 be
obtained from G as follows: The ligature (W, F ) is replaced by a new ligature
(W 0, F 0) with ρ(W ) ∩ C = ρ(W 0) ∩ C, i.e., all vertices of W and all edges of f
are removed from c, the vertices of W 0 and edges of E0 are inserted into c, if
an edge e ∈ E\F was incident with a vertex w ∈ W of the ligature, it is now
connected to a vertex w0 ∈ W 0 of the new ligature. We say that G0 is obtained
from G by rearranging the ligature (W, F ) (to (W 0, F 0)).

For EGIs, is was a direct conclusion from Lem. 16.1–16.3 that rearranging a
ligature in a context is a meaning-preserving transformation. For vertex-based
EGIs, we have to spend a little further eﬀort to prove a corresponding result.

Theorem 24.19 (Rearranging Ligatures in a Context). Let G0 be obtained from G by rearranging the ligature (W, F ) to (W 0, F 0). Then G and G0
are equivalent.

278

24 Vertices with Constants

Proof: Note that ρ(W ) ∩ C = ρ(W 0) ∩ C is equivalent to ρ(W )\{∗} =
ρ(W 0)\{∗}. Let us assume ∗ /∈ ρ(W ). Then by separating w into w and w0
and by setting W 0 := W ∪ {w0}, F 0 := F ∪ {(w, w0)}, we obtain an equivalent
.
graph with a new ligature (W 0, F 0) which now satisﬁes ρ(W 0) = ρ(W )
∪ {∗}.
So w.l.o.g. we assume ∗ ∈ ρ(W ).

For ρ(W ) = {∗}, we can directly adopt the argumentation after Def. 16.4 to
show that G and G0 are equivalent: First retract (W, F ) to a single vertex
w0 ∈ W and then extend w0 to the new ligature (W 0, F 0). But generally, for
ρ(W ) ) {∗}, we cannot retract (W, F ) to a single vertex. Instead, we retract
(W, F ) to the following ’minimal’ ligature:

Here, C1, . . . , Cn is an enumeration of the constant names in ρ(W ), and the
edges below the vertex spot shall be the (former) edges between vertices of
W and vertices of V \W . More formally, we assign to G a vertex-based EGI
Gr as follows: First, for each C ∈ ρ(W )\{∗}, let wC be a fresh vertex, and
let w∗ ∈ W be an arbitrary generic vertex (the reason not to choose a fresh
vertex w∗ is a simple matter of convenience: It eases the ongoing proof). For
each C ∈ ρ(W )\{∗}, let fC be a fresh edge. Let Wr := {wr | C ∈ ρ(W )} and
Fr := {fr | C ∈ ρ(W )}. Now Gr is deﬁned as follows:

• Vr := V \W ∪ Wr
• Er := E\F ∪ Fr
• For νr is deﬁned as follows:

– For e ∈ E\F , ν(e) = (v1, . . . , vn), let νr(e) := (v0

1, . . . , v0

n), where

i := vi, if vi /∈ W , and v0
v0

i = w∗, if vi ∈ W .

– For fr ∈ Fr, let νr(fr) := (w∗, wr).

• >r := > and Cutr := Cut

• arear(d) :=

(cid:26)

area(d) for d 6= c
area(c)\(W ∪ F ) ∪ (Wr ∪ Fr) for d = c

.

• κr := κ(cid:12)
• ρ := ρ(cid:12)

(cid:12)E\F ∪ Fr × { .=}
(cid:12)V \W ∪ {(wr, C) | C ∈ ρ(W })

We can transform Gr into G with the following steps:

1. With L. 24.13, we can transform G into G1 := (V, E, ν, >, Cut, area, κ, ρ1)
such that for each C ∈ ρ1(W ), there is exactly one vertex w ∈ W with
ρ1(w) = C.

2. Let w∗ be an arbitrary vertex w ∈ W with ρ1(w) = ∗. Now for each
C ∈ ρ1(W )\{∗}, the vertex w ∈ W with ρ1(w) = C is separated into

C1Cn24.4 Ligatures in vertex-based EGIs

279

w and wC. The identity-link added by the separation shall be denoted
fC. For Wr := {wC | C ∈ ρ(W )} and Fr := {fC | C ∈ ρ(W )}, we
obtain a vertex-based EGI G2 := (V2, E2, ν2, >, Cut, area2, κ2, ρ2) with
V2 = V ∪ Wr and E2 = E ∪ Fr. In this graph, (W ∪ Wr, F ∪ Fr) is a
ligature, having (W, F ) as sub-ligature which satisﬁes ρ1(W ) = {∗}.

3. Finally, (W, F ) is retracted to w∗ with Lemma 24.17.

The resulting graph is Gr, and as all steps can be carried out in both directions, we obtain that G and Gr are equivalent.
We can similarly obtain a graph G0
(W 0, F 0). Thus the graphs Gr and G0
G and G0 are equivalent.

r from G0 by retracting the ligature
r are isomorphic, thus we obtain that
2

25

Relation Graphs

In the last two chapters, we added object- and function-names as new syntactical elements to Peirce’s existential graphs. Object- and function-names
belong to each standard symbolic form of FO, and the purpose of the last two
chapters was to show how Peirce’s system has be extended in order to encompass these new elements. But Peirce’s himself considered only relations (not
objects or functions) as the constituting elements of existential graphs. This
is no accident or gap: As already been mentioned in the introduction, Peirce
was convinced that relations are the most elementary elements of reasoning.
In this chapter, EGIs are extended so that they describe relations. Thus the
resulting graphs – relation graph instances (RGIs) – can still be understood
as a formal elaborations of Peirce’s diagrammatic logic.

Burch elaborates in [Bur91a] a formal algebraic system from which he claims
that it is an ’either accurate or at least approximate representation of Peirce’s
thinking’ (page viii). This system is called Peircean Algebraic Logic (PAL).
But although the elaboration of PAL is driven by the diagrammatic representation of relations, Burch develops a linear and algebraic notation for PAL.
Not until the last chapter of his book it is roughly discussed how this linear
notation is related to its diagrammatic representation. The relation graphs
of this treatise can be understood as a formal, diagrammatic system for representing PAL by means of graphs (to be more precise: The relation graphs
cover PAL, but as it will turn out in the next section, not every relation graph
has a corresponding PAL-term).

Peirce’s understanding of relations is still disputed among Peirce experts.
Nowadays, relations are understood in a purely extensional manner as sets
of tuples. Burch argues that this view does not suﬃce for Peirce’s conception of relations, and he develops an extensional and intensional semantics for
relations. Zeman acknowledges in [Zem95] very much this intensional semantics, but he advocates that Peirce had the extensional view on relations as
well. Indeed, there are several places in Peirce’s writings where he describes

282

25 Relation Graphs

dyadic relations as classes of pairs. But Peirce’s view cannot be nailed down
to this understanding: In other places, Peirce provides diﬀerent descriptions
for relations (see below). The formal relation graphs whill will be developed
in this chapter suite both the extensional and the intensional interpretation
of relations, as they are elaborated by Burch.

Besides the extensional view, Peirce often described a relation as a proposition
with free places called blanks. In 3.465, he writes (in this and the following
quotation, emphasis is done by Peirce).

In a complete proposition there are no blanks. It may be called a
medad, or medadic relative [. . .] A non-relative name with a substantive verb, as ”– is a man,” or ”man that is –” or ”–’s manhood” has
one blank; it is a monad, or monadic relative. An ordinary relative
with an active verb as ”– is a lover of –” or ”the loving by – of –” has
two blanks; it is a dyad, or dyadic relative. A higher relative similarly
treated has a plurality of blanks. It may be called a polyad.

Shortly after this, he concludes in 3.466:

A relative, then, may be deﬁned as the equivalent of a word or phrase
which, either as it is (when I term it a complete relative), or else when
the verb ”is” is attached to it (and if it wants such attachment, I
term it a nominal relative), becomes a sentence with some number of
proper names left blank.

We have already seen an example for this view on page 103, where the relations
”– kills – to gratify –” or ”John is –” are diagrammatically depicted. For sake
of convenience, Figure 4 of 3.471 is repeated:

In this example, it becomes clear that the blanks of a relation correspond to
the hooks in EGIs. In Peirce’s existential graphs, they have to be ﬁlled by
lines of identity, resp. in EGIs, vertices are attached to the hooks.

It is well known that the diagrams from chemistry for atoms and molecules
are a main inspiration for the diagrammatic form of existential graphs. For
example, in 3.421 Peirce writes that ‘A rhema is somewhat closely analogous
to a chemical atom or radicle with unsaturated bonds. ’, and in 3.460 we ﬁnd
‘A chemical atom is quite like a relative in having a deﬁnite number of loose
ends or ”unsaturated bonds,” corresponding to the blanks of the relative’. In
fact, in 4.471 he writes that Figure 4 ‘correspond to prussic acid as shown in
Figure 5.’ (see Fig. 25.1).

The similarity to chemistry is not only the diagrammatic representation of
relations. Atoms of molecules with free valences can be compound to new

to grativykillsJohn it is thatis identical withand withand with25 Relation Graphs

283

Fig. 25.1. Fig. 5 of 4.471

molecules. Similarly, relations can be joined (the join of relations is one of the
operations of PAL). This exempliﬁes Peirce in 3.421 as follows:

So, in chemistry, unsaturated bonds can only be saturated by joining
two of them, which will usually, though not necessarily, belong to
diﬀerent radicles. If two univalent radicles are united, the result is a
saturated compound. So, two non-relative rhemas being joined give a
complete proposition. Thus, to join ”– is mortal” and ”– is a man,”
we have ”X is mortal and X is a man,” or some man is mortal. So
likewise, a saturated compound may result from joining two bonds
of a bivalent radicle; and, in the same way, the two blanks of a dual
rhema may be joined to make a complete proposition. Thus, ”– loves
–” ”X loves X,” or something loves itself.

Similarly, the graph of Figure 4 of 4.471 is the result of appropriately joining
the relations “John it is that –”, “– is identical with – and with – and with –”,
and “– kill – to gratify –”. In joining relations, it is allowed that blanks are left,
i.e., the result does not need to be a proposition: It might be a relation again.
An example by Peirce can be found in 3.421 as well, where Peirce writes:
‘Thus, ”– gives – to –” and ”– takes – from –” give ”– gives – to somebody
who takes – from –,” a quadruple rhema.”’

In this chapter, EGIs are extended by a new syntactical element which is used
to denote the blanks (or loose ends, as Peirce also calls them) of (possibly
compound) relation. These new syntactical elements will be devices query
markers with an index i, i.e., devices ’?i’. For example, the relations ”– is
mortal”, ”– is a man,”, ”– loves –” ”– gives – to –” and ”– takes – from –”
can de (so far informally) depicted as follows:

So the results of joining these relations as described by Peirce (”X is mortal
and X is a man,” or some man is mortal; ”X loves X,” or something loves
itself; and ”– gives – to somebody who takes – from –,”) yield the following
graphs:

CNH?1is mortal?1is a man?1loves?2?1gives to?2?3?1?2takes from?3284

25 Relation Graphs

In this chapter, relation graphs will be formally elaborated. This will done
by means of relation graph instances, which are an extension of EGIs in
the understanding of Chpt. 23 ( i.e., EGIs over an extended alphabet A :=
(C, F, R, ar)). This is done by additionally allowing that edges to be labeled
with new names ’?i’. Adding these names to vertex-based EGIs (in the understanding of Chpt. 24), i.e. by allowing that vertices to be labeled with new
names ’?i’, could be done in a similar manner.

To provide a simple, so-far informal example, we consider the following EGI
with the query markers ?1 and ?2. This graph describes the 2-ary relation
is stepmother of.

These graphs will be called relation graph instances (RGIs).1 We will even
evaluate RGIs without query markers to relations, namely to one of the two
0-ary relations {} and {{}}. The 0-ary relation {} can be identiﬁed with the
truth-value tt, the 0-ary relation {{}} can be identiﬁed with the truth-value
ff. Thus this approach is not a change, but an extension of the semantics for
EGIs, i.e., relation graphs are not an substitute, but an extension of existential
graphs.

In the next two sections, two diﬀerent kinds of relation graphs are introduced.
In Sec. 25.1, a general form of relation graph instances called called semi
relation graph instances is deﬁned. Roughly speaking, they are EGIs were we
additionally allow edges to be labeled with the query markers ?i. These edges
correspond to the loose ends, i.e. blanks, of relations. It will be possible that
diﬀerent edges are labeled with the same query marker, and it is moreover
allowed that these edges are in the area of cuts. For Peirce, each loose end
of a relation graph corresponds to the unsaturated bond of a chemical atom
or radicle. So for him, a loose end may appear only once, and it must placed
on the sheet of assertion. For this reason, the following graphs are to general
to encompass Peirce’s notion of relation graphs. Due to this, they are called
semi relation graph instances. For semi RGIs, the syntax, semantics, and a
sound and complete calculus is provided.

In Sec. 25.2, the graphs are syntactically restricted such that a query marker
?i may only appear once, and this must be on the sheet of assertion. These

1 Please do not mistake relation graphs with the underlying structure of all graphs

we consider, i.e., relational graphs (with cuts).

is a manis mortalloves?1gives to?2?3takes from?4mother_offather_ofmarried_withmalefemale11111222?1?225.1 Semi Relation Graph Instances

285

graphs are much closer to Peirce’s notion of relation graphs then the general
form of the ﬁrst section. The restriction does not yield a loss of expressiveness,
and it is shown that the calculus for semi RGIs remains complete.

Other authors already worked on graphs describing relations too. For example,
for their framework of Relational Logic and inspired by the work of Burch,
Pollandt and Wille invented and investigated such graphs as well (see [Pol01,
Pol02, Wil01]). Their graphs are termed relation graphs as well, and similar
to the graphs in this treatise, they are graph-based formalizations of Peirce’s
graphs. Similar to Pollandt and Wille, Hereth-Correia and P¨oschel in [HCP04,
HCP06] and Hereth-Correia and myself in [DHC06] investigated such graphs.
But I want to stress that that in these works, diﬀerent formalizations (than
in this treatise) for the graphs are introduced.

All the these works mainly focus on the expressiveness of the graphs and on
operations on the graphs. That is, they investigate the algebra of relations and
graphs. Some of them extend and prove Peirce’s famous reduction thesis, as
it is elaborated by Burch in [Bur91a]. In this chapter, we will focus on the
logic of relation graphs. The next chapter will turn to the algebra of relation
graphs, and using the result of [HCP06], a relation graph version of Peirce’s
reduction thesis, which strictly extends the result of Burch, will be provided.

25.1 Semi Relation Graph Instances

In this section, the syntax, semantics, and calculus for semi relation graph
instances are introduced. The basic idea is to extend the alphabet by additional signs ?1, ?2, . . . as free variables. Syntactically, we will treat these signs
sometimes like object names, sometimes like free variables. They are ﬁrst incorporated into an alphabet, then semi relation graph instances are deﬁned.

Let A := (C, F, R, ar)
Deﬁnition 25.1 (Extension of Alphabets).
.
∪ {?1, ?2, . . . | n ∈ N}
be an alphabet. Let A? := (C?, F, R, ar) with C? := C
(we assume C ∩ {?1, ?2, . . . | n ∈ N} = ∅). We call A? the query-markerextension of A.

Let A be an al-

Deﬁnition 25.2 (Semi Relation Graph Instances).
phabet and A? its query-marker-extension.
For an EGI G over A?, we set FV(G) := {?i | ∃e ∈ E : κ(e) =?i}. Let
E? := {e ∈ E | κ(e) =?i for an i ∈ N}. Each edge e ∈ E? is called pending
edge.
A semi relation graph instance (semi RGI) over A is an EGI G over
A? such that there is an n with FV(G) = {?1, ?2, . . . , ?n}. We set n := ar(G)
and call n the arity of G.

For an edge e with ar(e) = 1, let ve be the vertex incident with e.

286

25 Relation Graphs

If we have an alphabet A and its query marker extension A?, the query markers have a double syntactical meaning:

• We can consider EGIs over A?. Then the query markers are object names.

• We can consider semi RGIs over A. Then the query markers are treated
as new syntactical names –besides the names for constants, relations, or
functions– denoting free valences of an semi RGI.

In the following, the intended understanding will be clear from the context.

There are several ways to deﬁne n-tuples, and hence relations, over a ground
set U . For the following deﬁnitions of the semantics of relation graphs, and
particularly for the next chapter, it is useful to provide a precise deﬁnition of
tuples. Moreover, for the deﬁnition of the semantics it is helpful to consider
relations, where the tuples are not ﬁnite, but inﬁnite sequences.

Deﬁnition 25.3 (Relation). An I-ary relation over U is a set % ⊆ U I ,
i. e. a set of mappings from I to U .
If we have I = {1, . . . , n}, we write % ⊆ U n instead, and n := ar(%) is now
called the arity of %.
Each relation over a set I = {1, . . . , n} with n ∈ N is called finitary relation. The set of all ﬁnitary relations over a set U is denoted by Rel(U ).

In the following, we will use the letters % and σ to denote ﬁnitary relations.
Moreover, we will usually consider only ﬁnitary relations, i.e., the attribute
’ﬁnitary’ is often omitted. When we have to distinguish between ﬁnitary and
non-ﬁnitary relations, this will be explicitely mentioned.
The models for A? are the models for A, where we additionally assign objects
to the query markers. This is ﬁxed by the following deﬁnition.

Deﬁnition 25.4 (Extension of Models). Let M := (U, I) be a model for
A. An assignment for the query markers is a mapping f : {?1, ?2, . . . |
n ∈ N} → U .
Then let M[f ] := (U, I f ) be the model for A? with:

I f := (I f

C , IF , IR) , where I f

C (c) :=

(cid:26) IC(c) for c ∈ C

f (c) for c =?i , i ∈ N

M[f ] is called an query-marker-extension of M, and M is called the
query-marker-restriction of M[f ].

If M is a model for A and f : {?1, ?2, . . . | n ∈ N} → U , then M[f ] is obviously
an model for A?. Moreover, each model for A? is the query-marker-extension
of a model for A.

Based on the notation of extension of models, we can now easily deﬁne the
semantics of semi RGIs.

25.1 Semi Relation Graph Instances

287

Deﬁnition 25.5 (Semantics for Semi Relation Graph Instances). Let
G be a semi RGI over A. We set:

RM,G := {f : N → U | M[f ] |= G}

Now let H ∪ {G} be a set of semi RGIs. We set

H |=? G :⇐⇒ for all models M we have

\

G0∈H

RM,G0 ⊆ RM,G

In this deﬁnition, for the case H = ∅, we use the convention T ∅ := U N.
Particularly, we write M |=? G if we have RM,G = U N.

In this deﬁnition, we used sets of query marker assignments, i.e., N-ary relations, instead of ﬁnitary relations for a mere matter of convenience. But for a
single graph G, the relation RM,G can be understood to be a ﬁnitary relation
with arity ar(G). We have the following property: If G is an EGI over A?
with n := ar(G), if M is a model for A and if f, g are two query marker
assignments with f (cid:12)

(cid:12){1,...,n}, then we have

(cid:12){1,...,n} = g(cid:12)

M[f ] |= G ⇐⇒ M[g] |= G

So for % := {f (cid:12)
ar(G) such that

(cid:12){1,...,n} | f ∈ RM,G}, we obtain a ﬁnitary relation % with arity

RM,G = {f : N → U | f (cid:12)

(cid:12){1,...,n} ∈ %}

So we can have the following alternative deﬁnition for RM,G:
RM,G = {(u1, . . . , un) | M[f ] |= G for all f with (u1, . . . , un) ∈ f (cid:12)

(cid:12){1,...,n}}

= {f (cid:12)

(cid:12){1,...,n} | M[f ] |= G}

In the following, we will implicitly identify the inﬁnitary relation RM,G and
the n-ary relation %. i.e., RM,G will refer to both the ﬁnitary and inﬁnitary
relation described by G. It will be clear from the context which meaning is
intended. But note that the relation T
G0∈H RM,G0 of Def. 25.5 is usually not
a ﬁnitary relation.
If we have an EGI G over an extended alphabet A?, there are two possible
ways to evaluate it in a model: We can understand it as EGI over A?, thus
using the entailment-relation |=, or we understand it as semi RGI over A, thus
using the entailment-relation |=?. Of course, there is an intimate relationship
between these two evaluations, which is made precise through the following
lemma.

Theorem 25.6 (Semantical Entailment is Preserved for Semi Relation Graphs Instances). Let H∪{G} be a set of semi RGIs over an alphabet
A. Then we have:

(semi RGIs over A)

H |=? G ⇐⇒ H |= G

(EGIs over A?)

288

25 Relation Graphs

Proof: H |=? G (semi RGIs over A )

⇐⇒ for all models M := (U, I) over A : T
⇐⇒ for all models M := (U, I) over A, for all f : N → U :

G0∈H RM,G0 ⊆ RM,G

(∀G0 ∈ H : f ∈ RM,G0 ) ⇒ f ∈ RM,G

⇐⇒ for all models M := (U, I) over A, for all f : N → U :

(∀G0 ∈ H : M[f ] |= G0) ⇒ M[f ] |= G

⇐⇒ for all models M? over A? :

(∀G0 ∈ H : M |= G0) ⇒ M |= G

⇐⇒ for all models M? over A? :

M |= H ⇒ M |= G

⇐⇒ H |= G (EGIs over A?)

2

In the syntax, and in the semantic as well, query markers are basically handled
like new object names. If we carry over this idea to the transformation rules,
we obtain an adequate calculus. First of all, the calculus is deﬁned as follows:

Deﬁnition 25.7 (Calculus for Semi Relation Graph Instances). The
calculus for semi RGIs over A consists of the rules for EGIs over A?, where

• the query markers ?i are treated exactly like object names, and
• a rule may only be applied to a semi RGI G over A, if the result G0 is
again a well-formed semi RGI over A, i.e., if there is an n with FV(G0) =
{?1, ?2, . . . , ?n}.

We will use the sign ’‘?’ to refer to this calculus.

Let two semi RGIs Ga, Gb over an alphabet A with Ga |=? Gb be given. Each
proof for Ga ‘? Gb is a sequence of semi RGIs over A, so it is a proof for Ga ‘
Gb in the system of EGIs over A? as well. On the other hand, in a proof for
Ga ‘ Gb in the system of EGIs over A?, there might be EGIs over A? which are
no semi RGIs over A, as they violate the condition FV(G) = {?1, ?2, . . . , ?n}.
Nonetheless, by augmenting the graphs in the proof with some query vertices,
we can easily obtain a proof in the system of semi RGIs over A. This idea will
be used in the next theorem.

Theorem 25.8 (Soundness and Completeness of ‘?). Let an alphabet
A := (C, F, R, ar) be given. Then we have:

• The calculus ‘? is adequate for the system of all semi RGIs over A.
• Given a ﬁxed number n, the calculus ‘? is adequate for the system of all

semi RGIs G over A with ar(G) = n.

25.2 Relation Graph Instances

289

Proof: Let ﬁrst be two semi RGIs Ga, Gb be given with Ga ‘? Gb. Seen as
EGIs over A?, we have Ga ‘ Gb. As ‘ is sound, we obtain Ga |= Gb, thus
Lem. 25.6 yields Ga |=? Gb. That is, ‘i is sound.
Now let H ∪ {G} be a set of semi RGIs over an alphabet A with H |=? G.
Then there are G1, . . . , Gn ∈ H with GH ‘ G. where GH is the juxtaposition
of G1, . . . , Gn. Let F V := FV(G) ∪ FV(GH). Considered as EGIs over the
alphabet A?, we have a proof

(GH := G1, G2, . . . Gn := G)

for GH ‘ G with FV(Gk) ⊆ F V for each k = 1, . . . , n. Now for i = 1, . . . n, let
i be the graph obtained from G0 by adding for each i with ?i ∈ F V a device
G0
n) is again a proof, and

to the sheet of assertion. Then (G0

1, G2, . . . G0

,

, . . .,

to the sheet of assertion.

.
∪ {?l, ?(l + 1), . . . , ?m}, we can
1 from G1 with the existence of constants rule by adding successively

we have FV(Gk) = F V for each k = 1, . . . , n.
If we have FV(GH) ( F V , e.g. F V = FV(GH)
derive G0
the devices
If we have FV(G) ( F V , e.g. F V = FV(G)
can derive Gn from G0
removing successively the devices
sheet of assertion.
So we have a proof for GH ‘ G0
1, for G0
n ‘ G, thus for
GH ‘ G. Each graph Gi in this proof is an RGI over A. Moreover, due to the
construction of the proof, for FV(GH) = FV(G) = F V , we have FV(Gi) = F V
for each graph Gi. This proves both completeness claims of the theorem. 2

.
∪ {?l, ?(l + 1), . . . , ?m}, we
n with the existence of constants rule the devices by
from the

n, and for G0

1 ‘ G0

, . . .,

,

25.2 Relation Graph Instances

Semi RGIs evaluate to relations. For Peirce, to each blank of the relation,
we have exactly one pending edge, and this edge is placed on the sheet of
assertion. In the following, we restrict the system of RGIs in order to get a
class of graphs which corresponds more closely to Peirce’s understanding.

Deﬁnition 25.9 (Relation Graph Instances). Let A be an alphabet. A
relation graph instance (RGI) G := (V, E, ν, >, Cut, area, κ) over A is
a semi RGI over A which satisﬁes ctx(e) = > for each e ∈ E? and |{e ∈ E? |
κ(e) =?i}| = 1 for each ?i ∈ FVG).

RGIs can be understood as semi RGIs in some normal form. In order to emphasize that a graph is an RGI, not only a semi RGI, we will call it sometimes
normed. Now we assign to each semi RGI G a normed RGI norm(G), the
normalization of G. The normalization is ﬁrst described as a procedure using

?i?l?l+1?m?m?m−1?m290

25 Relation Graphs

the rules of the calculus, and it is exempliﬁed with one graph. Then the formal
deﬁnition is given.

1. Our example is the graph

In the diagram, for unary edges, we omit to label the edge-line with 1.

2. For each ?i ∈ FV(G), we add a new vertex v?i and a new edge e?i with
ν(e?i) = (v?i) and κ(e?i) =?i to the sheet of assertion. Within the calculus,
this is done with the existence of constants rule.

3. For each edge e with κ(e) =?i and e 6= e?i for a ?i ∈ FV(G), we use the
rule ’adding a vertex to a ligature’ to add a new vertex we to ctx(e). The
new identity edge between v(e) (the vertex incident with e in G) and we
will be denoted id1
e.

4. For each edge e with κ(e) =?i and e 6= e?i for a ?i ∈ FV(G), an identity
e between v?i and we is added to ctx(e) with the constant identity

link id2
rule.

5. Finally, each edge e with κ(e) =?i for a ?i ∈ FV(G) and e 6= e?i is removed.
Within the calculus, this can be done as follows: First, an new vertex w0
e
and a new identity-link id0
e between we and w0
e is added to to ctx(e) with
the rule ’adding a vertex to a ligature’. Then the subgraph consisting of
e and w0
e is
removed as well.

e is deiterated, and in this deiteration, the identity-link id0

1S2?111?211R2?111?2P1S2?111?21?111R2?11?211?2P1?11?21?2P11?12R11S2?11?211?11?21?2P11?12R11S2?11?211?11?21S22R1P125.2 Relation Graph Instances

291

Now the formal deﬁnition of the normalization of a semi RGI is provided.

Deﬁnition 25.10 (norm(G)). Let G := (V, E, ν, >, Cut, area, κ) be a semi
RGI.

• For each ?i ∈ FV(G), let v?i be a fresh vertex and e?i be a fresh edge.
• For each ?i ∈ FV(G) and e ∈ E?i, let let we be a fresh vertex and id1

be fresh edges. We set Wn := {we | e ∈ E?}, F 1
n := {id2
F 2

e | e ∈ E?}.

n := {id1

e, id2
e
e | e ∈ E?} and

Now we deﬁne norm(G) := (Vn, En, νn, >n, Cutn, arean, κn) as follows (note
that v(e) in the deﬁnition of νn is the vertex incident with e in G):

.
∪ F 2
n

.
.
∪ {v?i |?i ∈ FV(G)}
∪ Wn
.
.
∪ F 1
∪ {e?i |?i ∈ FV(G)}
n
.
∪ {(we, v(e)), (we, v?i) | e ∈ E?}

• Vn := V
• En := E\E?
• νn := ν(cid:12)
• >n := >,
• Cutn := Cut,
• arean is deﬁned as follows: For c ∈ Cut we set

(cid:12)E\E?

arean(c) := area(c)\(E? ∩ area(c))
arean(>) := area(>)\(E? ∩ area(>))
.
∪ {v?i, e?i |?i ∈ FV(G)}

.
∪ {we, id1

e, id2

e | e ∈ E? ∩ area(c)}, and
e | e ∈ E? ∩ area(>)}

e, id2

.
∪ {we, id1

• κn := κ(cid:12)

(cid:12)E\E?

.
∪ {(id1

e, .=) | id1

e ∈ F 1
n}

.
∪ {(id2

e, .=) | id2

e ∈ F 2
n}

norm(G) is called the normalization of G.

As we have seen, in the transformation of G to its normalization we used only
rules of the calculus which can be carried out in both directions. Thus we
immediately obtain the following lemma:

Lemma 25.11 (G and norm(G) are Equivalent). Let G be a semi RGI.
Then norm(G) is an RGI which is syntactically equivalent to G.

Without proof

Due to Lemma 25.11, the full system of semi RGIs is semantically equivalent
to the restricted system of RGIs. Moreover, it is clear that the calculus is still
sound, if consider the restricted system of RGIs. But if we apply one of the
rules iteration/deiteration, erasure/insertion, or the constant identity rule to
a normed RGI, we might obtain an semi RGI which is not normed. Thus it
is not clear that the calculus is still complete. The next theorem shows that
that we do not loose the completeness of the calculus.

292

25 Relation Graphs

Theorem 25.12 (Completeness of ‘? for RGIs). Let G, G0 be two semi
RGIs such that G0 is derived from G by applying one of the rules of the
calculus ‘?. Then we have norm(Ga) ‘? norm(Gb), where the proof contains
only RGIs. That is, the calculus ‘? is complete for RGIs.

Proof: First of all, if r is one of the rules ’isomorphism’, ’changing the orientation of an identity edge’, ’adding a vertex to a ligature’ and ’removing a vertex
from a ligature’, ’double cuts’, ’erasing a vertex’ and ’inserting a vertex’, ’functional property rule’, ’total function rule’, and the ’constant identity rule’,2
and if we have G ‘r
? norm(G0)
as well.

? G0, it is easy to see that we have norm(G) ‘r

It remains to consider the rules ’erasure’ and ’insertion’, ’iteration’ and ’deiteration’, and the existence of constants rule. First of all, we use the notation
of Def. 25.10. Moreover, in the ongoing proof, we will split and merge vertices
(see Def. 16.6). In Lemma 16.7, we have shown that splitting or merging vertices transforms a graph in a syntactically equivalent graph by providing a
formal proof for the transformation. It can easily be checked that if we start
with a normed graph, all graphs in this proof are normed as well. So we are
allowed to apply Lemma 16.7 in the ongoing proof.

e, then id2

We start with the pair ’erasure’ and ’insertion’. Due to the symmetry of the
calculus, it is suﬃcient to prove this theorem only for the erasure rule.
Let ﬁrst G0 be obtained from G by erasing the edge e. If e /∈ E?, we have
norm(G) ‘? norm(G0) as well. So let e be an edge with κ(e) =?i. In norm(G),
we ﬁrst erase id1
e, and then we. If e is the only edge in G with κ(e) =
?i, we furthermore erase the (now closed) subgraph consisting of v?i and e?i.
The resulting graph is norm(G), thus we again have norm(G) ‘? norm(G0).
Now let G0 be obtained from G by erasing the closed subgraph edge Gs :=
(V s, Es, νs, >s, Cuts, areas, κs) (particularly, >s is the context of Gs). We
provide a formal proof for norm(G) ‘? norm(G0), which will be illustrated
by an example.

Our example is given below. The subgraph is indicated by a dotted subgraphline.

2 Recall that constants are treated like 1-ary functions, and the constant identity
rule and the existence of constants rule are the counterparts of the functional
property rule and the total function rule. So one might think that if we have
norm(G) ‘r
? norm(G) for the rules for functions, this should hold trivially for
the rules for constants as well. But on the other hand, as query vertices are
exactly treated like constant vertices, and as query vertices are aﬀected by the
normalization of graphs, we have to take care for the constant rules. And in fact,
it turns out that the existence of constants rule has to be treated separately.

25.2 Relation Graph Instances

293

era.
‘?

Thus for the normalizations of these graphs, we have to show

era.
‘?

First, for each ?i ∈ FV(Gs), we split v?i. The new vertex w?i is placed in >s
(thus we have a new identity edge id?i in >s between v?i and w?i as well). It
shall be incident with all vertices we ∈ E? ∩ Es.
For our example, this yields:

Let us denote this intermediate graph by Gi. The sets

.
∪ {w?i |?i ∈ FV(Gs)}

.
∪ {we | e ∈ E? ∩ Es} of vertices,

.
∪ {id?i |?i ∈ FV(Gs)}

.
∪ {id1

e, id2

e | e ∈ E? ∩ Es} of edges,

s := Vs
s := Es\E?

• V i
• Ei
• Cuti

s := Cuts of cuts

give rise to a subgraph Gi
so-to-speak corresponds to the subgraph Gs of G.
Now, for each ?i ∈ FV(Gs), we erase id?i.

s := (V i

s , Ei

s, >i

s, νi

s, Cuti

s, areai

s, κi

s) of Gi which

SR?11Q?2?1P?12S?1PSPR21?1Q?2SP?1?1SP?2R21Q?1SP?2R21Q294

25 Relation Graphs

We erased only edges of Gi
be erased.

s. The remaining subgraph is now closed and can

Finally, for each ?i ∈ Gs with {e ∈ E|κ(e) =?i} ⊆ Es, the subgraph with the
vertex v?i and the edge e?i is closed and can erased.

We obtain norm(G0), thus we are done.

After proving the theorem for the rule ’erasure’, thus for ’insertion’ as well, we
consider next the iteration and deiteration rule. Again due to the symmetry
of the calculus, we prove this theorem only for the iteration rule.
Again we provide a formal proof for norm(G) ‘? norm(G0) and an example.
The subgraph Gs iterated into d.
Our example is given below. The subgraph is indicated by a dotted subgraphline. In the application of the iteration rule, we add one new identity link.

it.
‘?

Thus for the normalizations of these graphs, we have to show

era.
‘?

First, for each ?i ∈ FV(Gs), we split v?i exactly like in the proof of the erasure
rule. Again, we obtain an intermediate graph by Gi with a subgraph Gi
s.

S?2P?1SP?1?1R2?11S1?1P?1R2?11S?1R2?11?1PSR21P?1P?1SR21R21SPR21?125.2 Relation Graph Instances

295

Now the subgraph Gi
s is iterated into d similar to the iteration of Gs (particularly, if in iteration of Gs an identity edge it added between a vertex v ∈ Vs
and its copy v0, we do the same in the iteration of Gi
s). Moreover, for each
vertex w?i for an ?i ∈ FV(Gs), we add an identity-link id0
?i between w?i and
its copy w0

?i.

For each ?i ∈ FV(Gs), we merge w0

?i into w?i.

For each ?i ∈ FV(Gs), we merge w?i into v?i.

We obtain norm(G0), thus we are done.

After proving the theorem for the iteration and deiteration rule, we ﬁnally
prove this theorem for the existence of constants rule. We prove the theorem
for adding a fresh vertex v and an fresh unary edge e with ν(e) = (v) and
κ(e) = C to a context c, where C is a constant name. We distinguish three
cases.

• C ∈ C (i.e., C is no query marker). Then we have norm(G) ‘? norm(G0)

as well.

• C =?i for an i ∈ N, and ?i /∈ FV(G). We obtain norm(G0) from norm(G)
as follows: First, we add with the existence of constants rule. a new vertex
v?i and a new edge e?i with ν(e?i) = (v?i) and κ(e?i) =?i to the sheet of
assertion. Then v?i is iterated into c. The copy of v?i shall be denoted we.
During the iteration, an identity edge id2
e is added between v?i and we.
Finally, we is iterated into c. The copy of we shall be denoted v. During
the iteration, an identity edge id1
e is added between we and v. The graph
we obtain is norm(G0).

P?1R21SR21P?1R21SR21P?1SR21R21296

25 Relation Graphs

An example for this rule is given below. On the left side, we have G ‘? G0,
on the right side, we have norm(G) ‘? norm(G0).

‘?

, thus

‘?

• C =?i for an i ∈ N, and ?i ∈ FV(G). This case is handled like the last

case, except that the ﬁrst step of adding v?i and e?i is omitted.

As we have ﬁnally shown that each rule with G ‘r
norm(G0), we are done.

? G0 implies norm(G) ‘?
2

R?1RRR?126

Peirce’s Reduction Thesis

26.1 Introduction

Now I call your attention to a remarkable theorem. Every polyad higher than a triad can be analyzed into triads,
though not every triad can be analyzed into dyads.

Peirce, Detached Ideas Continued, 18981

In a footnote at the beginning of Sec. 3.2, we already shorty mentioned Peirce’s
three fundamental categories called ﬁrstness, secondness, and thirdness. For
him, these three categories form a complete metaphysical scheme. Moreover,
for Peirce, the basic constituting element of human reasoning are relations.
The above given quotation can be understood as the application of Peirce’s
categories to relations (’polyads’, as Peirce calls them in this place). So, to
put in into contemporary terminology, each relation of arity higher then three
can be constructed from ternary relations, but not every ternary relation can
be constructed from dyadic relations only. But, of course, this claim needs
an examination what Peirce means by ‘being analyzed’, i.e., it has to be
investigated which operations on relations have to be taken into account.

A ﬁrst approach to a mathematical elaboration of Peirce’s reduction thesis has
been provided by Herzberger in [Her81]. In this work, no Cartesian product of
relations is allowed. This approach has been extended by Burch in [Bur91a],
where he allows to use the Cartesian product of relations as last or secondlast operation in the construction of relations. Inspired by [Bur91a], Hereth
Correia and P¨oschel in turn have extended Burch’s result in [HCP06], as they
allow to use the Cartesian product in arbitrary steps in the construction of
relations.

In the following sections, we will use the result of Hereth Correia and P¨oschel
and adopt it for relation graphs. In all sections, we will only consider alphabets
A := (R, ar), i.e., we will not take constant or function names into account. In

298

26 Peirce’s Reduction Thesis

Sec. 26.2, the operations on relations, as they have been used in [HCP06], are
provided. Then, in Sec. 26.3, we will deﬁne corresponding operations on the
graphs. It will turn out that (nearly) all relation graphs can be constructed
with these operations. Then, in Sec. 26.4, we elaborate a version of Peirce’s
reduction thesis which suits the relation graphs of this treatise. In this section,
we ﬁrst show the ﬁrst part of Peirce’s thesis. The given result is more precise
than Peirce’s claim in the given quotation, as we will see that each relation can
be constructed from dyadic relations and the teridentity. Similarly, Peirce’s
claim that ‘not every triad can be analyzed into dyads’will be made precise
through the result of [HCP06], where it is shown that the teridentity IdU
3 on
a given universe of discourse cannot be constructed out of dyadic relations.
Finally, in Sec. 26.5, we will discuss more deeply the diﬀerences between the
approaches of Herzberger, Burch, and Hereth Correia and P¨oschel.

26.2 Peircean Algebraic Logic

The following two deﬁnitions, which are adopted from [HCP06], ﬁx the operations of the Peircean Algebraic Logic. This deﬁnition of PAL is a strict
extension of the version of PAL which Burch provided in [Bur91a].

Deﬁnition 26.1 (PAL-Operations).
set of all ﬁnitary relations on U , we deﬁne the following operations:

Let U be an arbitrary set. On the

PAL1 (Product): If % is an m-ary relation and S is an n-ary relation, then

% × σ := {(r1, . . . , rm, s1, . . . , sn) | (r1, . . . , rm) ∈ % ∧ (s1, . . . , sn) ∈ σ}

is the product of % and σ.

PAL2 (Join): If % is an n-ary relation and 1 ≤ i < j ≤ n, then

δi,j(%) := {(r1, . . . , ri−1, ri+1, . . . , rj−1, rj+1, . . . , rn) |

∃u ∈ U : (r1, . . . , ri−1, u, ri+1, . . . , rj−1, u, rj+1, . . . , rn) ∈ %}

is the join of the i-th and j-th blank (or place) of %.

PAL3 (Complement): If % is an n-ary relation, then

¬% := An\% = {(u1, . . . , un) ∈ U n | (u1, . . . , un) /∈ %}

is the complement of %.

PAL4 (Permutation): If % is an n-ary relation and if α is a permutation

on {1, . . . , n}, then

πα(%) := {(r1, . . . , rn) | (rα(1), . . . , rα(n)) ∈ %}

is the α-permutation of %.

26.3 Graphs for Peircean Algebraic Logic

299

Let U be a set and Σ ⊆ Rel(U )
Deﬁnition 26.2 (Closure resp. PAL).
be a set of ﬁnitary relations on U . Then let hΣiPAL−
=3 be the smallest set
which contains Σ and which is closed under the PAL-operations of Def. 26.1.
Similarly, let hΣiPAL be the smallest set which contains Σ ∪ { .=3} and which
is closed under the PAL-operations.

.

Let M := (U, I) be a model over an alphabet A := (R, ar). Then we set

hMiPAL−

.

=3 := h{I(%) | % ∈ R}iPAL\{ .=3}

hMiPAL := h{I(%) | % ∈ R}iPAL

Recall that for a given set U , we deﬁned IdU
3 := {(u, u, u) | u ∈ U } (see
page 183). In [HCP06], Hereth Correia and P¨oschel have proven the following
algebraic version of the second part of Peirce’s reduction thesis. This is the
main result we will use in this chapter.

Theorem 26.3 (An Algebraic Version of Peirce’s Reduction Thesis
(Hereth Correia and P¨oschel 2006) ). Let |U | ≥ 2 and let Σ be the set
of all 1- and 2-ary relations over U . Then we have

IdU

3 /∈ hΣiPAL−

.
=3

, thus

hΣiPAL−

.
=3

( hΣiPAL

26.3 Graphs for Peircean Algebraic Logic

In the last section, the operations of PAL, which act on relations, had been
deﬁned, and an algebraized version of the Peircean Reduction Thesis had been
provided. In this section, we transfer this result to relation graphs.

We start our scrutiny by transferring the (algebraic) PAL-operations of
Def. 26.1 to (syntactical) operations on RGIs.

Deﬁnition 26.4 (PAL Operations on Graphs).
over an alphabet A, we deﬁne the following atomar graphs and operations:

On the set of all RGIs

1. Atomar graphs: Let R be an n-ary relation name. The graph

GR := ({v1, . . . , vn}, {e1, . . . , en, eR},

{(e1, (v1)), . . . , (en, (vn)), (eR, (v1, . . . , vn))},
>, ∅, ∅, {(e1, ?1), . . . , (en, ?n), (eR, R)})

is the atomar RGI corresponding to R. Moreover, the graph

G?1 := ({v}, {e {(e, (v))}, >, ∅, ∅, {(e, ?1)})

is an atomar graph.

300

26 Peirce’s Reduction Thesis

2. Product: Let two RGIs G1 := (V1, E1, ν1, >1, Cut1, area1, κ1), G2 :=
(V2, E2, ν2, >2, Cut2, area2, κ2) with m = ar(G1) and n = ar(G2) be
given. Let G := (V, E, ν, >, Cut, area, κ) be the juxtaposition of G1 and
G1, where the labeling mapping κ is changes as follows: For e ∈ E1, we
set κ(e) := κ1(e), and for e ∈ E2, we set

κ(e) :=

(cid:26)

κ2(e) if e /∈ (E2)?
?(i + m) if κ2(e) =?i

Then G is called the product of G1 and G2 and denoted by G1 × G2.
3. Join: Let G := (V, E, ν, >, Cut, area, κ) be an n-ary RGI, and let 1 ≤
i < j ≤ n. Let vi, vj be the edges with κ(ei) =?i and κ(ej) =?j, resp., and
let vi and vj be the vertices incident with ei and ej, resp. Let v be a fresh
vertex. Let G0 be the following graph:
• V 0 := V \{vi, vj}
• E0 := E\{ei, ej},
• We deﬁne ν0 as follows: For ν(e) = (w1, . . . , wm), let ν0(e) = (w0

.
∪ {v},

1, . . . , w0

m)

with w0

k :=

(cid:26) wk for wk /∈ {vi, vj}
v for wk ∈ {vi, vj}

.

• >0 := >
• Cut0 := Cut
• area0(c) := area(c) for each c 6= >0, and
area0(>0) := area(>0)\{vi, vj, ei, ej}

.
∪ {v},

• κ0(e) := κ(e) for each e /∈ E?, and

κ0(e) :=






?k for κ(e) =?k and k < i
?(k − 1) for κ(e) =?k and i < k < j
?(k − 2) for κ(e) =?k and j < k

We say that we obtain G0 from G by joining (the blanks) i and j.
Sometimes we will say ’by joining ?i and ?j’ as well. G0 denoted by δi,j(G).

4. Complement: Let G := (V, E, ν, >, Cut, area, κ) be an n-ary RGI. Let
c be a fresh cut (i.e., c /∈ E ∪ V ∪ Cut ∪ {>}). Let V ? be the set of
all vertices which are incident with an e ∈ E?. Now let ¬G be the RGI
(V, E, ν, >, Cut0, area0, κ) with Cut0 := Cut ∪ {c}, where area0 is deﬁned
as follows:

area0(d) :=






E? ∪ V ? for d = >
area(c)\(E? ∪ V ?) for d = c

area(c) else

This graph is an n-ary RGI. Then G0 is called the negation of G and
denoted by ¬G.

26.3 Graphs for Peircean Algebraic Logic

301

5. Permutation: Let G := (V, E, ν, >, Cut, area, κ) be an n-ary RGI, let α
be a permutation of {1, . . . , n}. Let G0 := (V, E, ν, >, Cut, area, κ0) be the
RGI with

(cid:26) κ(e) for e /∈ E?

κ0(e) :=

?α(i) for e ∈ E? with κ(e) =?i

This graph is an n-ary RGI. Then G0 is called the α-permutation of
G and denoted by πα(G).

Before we proceed, ﬁrst some simple examples for this deﬁnition are provided.

1. Atomar graphs: Below, the graph GR for a relation name R with ar(R) =
4, as well G?1, is depicted. Moreover, as the teridentity will play a crucial
role in the deﬁnition of PAL-graphs, the graph G .=3 is depicted as well.

2. Product: Example: From

and

we obtain

3. Join: For example, with joining 3 and 5, from

we obtain

.

2R134?1?4?2?3?13?1?2?3123RT1122?1?2?3?4?1?2?3?4S1122RRT1122?1?2?3?4?5?6?7?8S1122R?5?6?7?8S1122RRT1122?1?2?3?4S1122RRT1122?1?2?3?4(cid:9)(cid:9)?5?6302

26 Peirce’s Reduction Thesis

4. Complement: For example, from

we obtain

.

Def. 26.4 is the syntactical counterpart of Def. 26.1 for RGIs. After Def. 26.1,
we deﬁned in Def. 26.2 the closure of sets of relations which respect to the PALoperations. As the teridentity plays the central role in the formal elaboration
of Peirce’s reduction thesis, we deﬁned two closures where in one case, besides
the given relations, the teridentity is included in the closure process.

The next deﬁnition is the syntactical counterpart of of Def. 26.2, i.e., we deﬁne
classes of graphs which are closed under the syntactical operations of Def. 26.4.
Again with respect to teridentity, we will deﬁne PAL− .=3-graph instances and
PAL-graph instances.

Recall that in Chpt. 16, where the method of separating ligatures at branching
points has been introduced, we augmented a given alphabet A by new names
.=k for the k-ary identity. The resulting alphabet has been denoted A=. For
the purpose we have now in mind, we will augment A only with the name .=3
.=3. As we then have
for the teridentity. The resulting alphabet is denoted A
.=3 ∈ R, the atomar graph G .=3 can be used in the construction of the graph
instances. That is, similar as the teridentity served to distinguish between the
=3 and hΣiPAL in Def. 26.2, now G .=3 will serve to distinguish
closures hΣiPAL−
between PAL− .=3-graph instances and PAL-graph instances.

.

Deﬁnition 26.5 (PAL Graph Instances). Let A := (R, ar) be a given
alphabet. We set:

• A PAL− .=3-graph instance over A is deﬁned to be an RGI which can be
obtained from ﬁnitely many atomar graphs GR with R ∈ R by ﬁnitely many
applications of the operations product, join, complement, and permutation,
and

• a PAL-graph instance over A is deﬁned to be a PAL− .=3-graph in-

stance over A

.=3.

As usual, PAL− .=3-graph instances and PAL-graph instances are abbreviated
by PAL-GIs and PAL-GIs.

RTA1122?1?2?5SR1122?3?4SRRTA11112222?1?2?3?4?526.3 Graphs for Peircean Algebraic Logic

303

Recall that we deﬁned branching points as vertices which are attached to more
than two hooks (see Def. 12.9). Up to some minor syntactical restrictions, the
PAL− .=3-GIs over A are the RGIs over A without branching points. This is
the subject of the next lemma.

Lemma 26.6 (The PAL-graphs are the normed RGIs without branching points). A graph G is a PAL− .=3-GI over A if and only if it is an normed
RGI over A such that

1. G has no branching points,

2. G has no isolated vertices, and
3. G has no vertices which are incident with two diﬀerent edges e, f ∈ E?.

Proof: Let us call the normed RGIs which satisfy the three conditions of the
lemma PAL∗-graph instance instances. That is, we have to show that
each RGI G is a PAL− .=3-GI if and only if it is and PAL∗-graph instance.
It can easily shown by induction over the construction of PAL− .=3-GIs that
each PAL− .=3-GI is a PAL∗-graph instance. So it remains to prove the opposite
direction.
Let G := (V, E, ν, >, Cut, area, κ) be a PAL∗-graph instance. Then each vertex v ∈ V satisﬁes exactly one of the following conditions:

• v is attached to two diﬀerent hooks (e, i) and (f, j) (e = f is possible)

with e, f /∈ E?. The class of these vertices shall be denoted T1(V ).

• v is attached to exactly one hook (e, i) with e /∈ E?. The class of these

vertices shall be denoted T2(V ).

• v is attached to two diﬀerent hooks (e, i) and (f, j) with e ∈ E? and

f /∈ E?. The class of these vertices shall be denoted T3(V ).

• v is attached to exactly one hook (e, i) with e ∈ E?. The class of these

vertices shall be denoted T4(V ).

.
∪ T2(V )

.
.
∪ T4(V ). Now we assign to G its
∪ T3(V )
Thus we have V = T1(V )
PAL-complexity palc(G) := 3 · |T1(V )| + |T2(V )| + |Cut|. The lemma is now
proven over the PAL-complexity of PAL∗-graph instances, i.e., by induction
over palc(G). In the proof, we set n := ar(G).
We ﬁrst consider an PAL∗-graph instance G := (V, E, ν, >, Cut, area, κ) with
palc(G) = 0. Then G has no cuts, and each vertex is either attached to two
diﬀerent hooks (e, i) and (f, j) with e ∈ E? and f /∈ E?, or to exactly one hook
(e, i) with einE?. That is, G is the juxtaposition of graphs of the following
form (where R ∈ R):

and

.

i2i1Riar(R)12???iar(R)?i304

26 Peirce’s Reduction Thesis

Then G can be obtained by the successive join of the corresponding atomar
PAL∗-graph instances

and

,

followed by an appropriate permutation.
Now let G := (V, E, ν, >, Cut, area, κ) be an PAL∗-graph instance with
palc(G) > 0.

Assume ﬁrst we have a vertex v ∈ T1(V ) with ctx(v) = >. Let v be attached
to the hooks (e1, i1) and (e2, i2). The graph G can be obtained from another
graph G0 by a join operation. The graph G0 is deﬁned as follows:

Let v?(n+1) ,v?(n+2) be fresh vertices and e?(n+1) ,e?(n+2) be fresh edges. Let
G0 := (V 0, E0, ν0, >0, Cut0, area0, κ0) be the following graph:

• V 0 := V \{v}

.
∪ {v?(n+1), v?(n+2)},

.
∪ {e?(n+1), e?(n+2)},

• E0 := E\
• We deﬁne ν0 as follows: For ν(f ) = (w1, . . . , wm), let ν0(f ) = (w0

1, . . . , w0

m)

with w0

k :=






v?(n+1)
v?(n+2)

for (f, k) = (e1, i1)
for (f, k) = (e2, i2)

.

wk else

• >0 := >
• Cut0 := Cut
• area0(c) := area(c) for each c 6= >0, and

area0(>0) := area(>0)\{v}

.
∪ {v?(n+1), v?(n+2), e?(n+1), e?(n+2)},

• κ0 := κ

.
∪ {(e?(n+1), ?n + 1), (e?(n+2), ?n + 2)}

Informally depicted, with R = κ(e1) and S = κ(e2),

is replaced by

resp. for e1 = e2 and κ(e) = R,

is replaced by

Ri?1ar(R)12?2ar(R)??1RijSRijSn+1??n+2Rji?n+2n+1?Rji26.3 Graphs for Peircean Algebraic Logic

305

Then we have G = δn+1,n+2(G0) and palc(G0) = palc(G) − 1, i.e. for this case,
the induction is done.

Next, we consider the case that we have a vertex v ∈ T2(V ) with ctx(v) = >.
This case is handled similarly to the last case. Let v be attached to the hook
(e, i). We deﬁne another graph G0 := (V 0, E0, ν0, >0, Cut0, area0, κ0) as follows:

• V 0 := V
• E0 := E

.
∪ {e?(n+1)},

.
∪ {(v, e?(n+1))}

• ν0 := ν
• >0 := >
• Cut0 := Cut
• area0(c) := area(c) for each c 6= >, and area0(>) := area(>)

.
∪ {e?(n+1)}

• κ0 := κ

.
∪ {(e?(n+1), ?(n + 1))}

Then we have G = δn+1,n+2(G0 × G?1) and palc(G0) = palc(G) − 1. Thus for
this case, the induction is done as well.

So we can now assume that we have T1(V ) ∩ area(>) = ∅ = T2(V ) ∩ area(>).
As we have palc(G) > 0, we have Cut 6= ∅. Let c ∈ area(>) ∩ Cut be a ﬁxed
cut. Let us consider an edge e which is enclosed by c, i.e., e < c. Note that
e /∈ E?. If e is incident with a vertex v which is not enclosed by c, this vertex
must be placed on > and satisﬁes v ∈ T1(V ). So if we deﬁne

:= {v ∈ V ∩ area(>) | v is incident with an edge e with e < c}

V +
c
c := {e ∈ E ∩ area(>) | e is incident with e vertex v ∈ V +
E+
c }

c , Ec := (≤[c] ∩ E) ∪ E+

the sets Vc := (≤[c] ∩ V ) ∪ V +
c , and Cutc := Cut give
rise to a closed subgraph Gc := (Vc, Ec, νc, >c, Cutc, areac, κc) of G, which
is placed on the sheet of assertion. As Gc is closed, the sets V−c := V \Vc,
E−c := E\Ec, and Cut−c := Cut\Cutc give rise to a closed subgraph G−c of
G as well (this graph may be empty). Now G is the juxtaposition of Gc and
G−c. By choosing appropriate permutations α, β, γ, we get

G = πα(πβ(Gc) × πγ(G−c))

c, ν0

c, ν0

c, >0

c , E0

c, Cut0

c , E0
c, area0
c) with Cut0 := Cut0
c(>) ∪ area0

Moreover, we have palc(G−c) < palc(G).
c). Now we set G0
c, κ0
Finally, let πβ(Gc) := (V 0
:=
c\{c}, area0(d) := area0
(V 0
c, >0, Cut0, area0, κ0
c(d)
for each d 6= >, and area0(>) = area0
c(c) (roughly speaking, G0
is obtained from πβ(Gc) by removing c). Then by deﬁnition of Gc, we have
β(Gc) = ¬G0, and we have palc(G0) = palc(πβ(Gc)) − 1 ≤ palc(G).
So for the last case where T1(V ) ∩ area(>) = ∅ = T2(V ) ∩ area(>), G can be
composed of PAL∗-graph instances with a lower PAL-complexity, too. This
2
ﬁnishes the proof.

306

26 Peirce’s Reduction Thesis

.=3
Please note that the lemma can be applied to PAL-ohne instances over A
as well, i.e, PAL− .=3-GIs are the RGIs over A which have no branching points,
as well as no isolated vertices, and no vertices which are incident with two
diﬀerent edges.
The second and third condition for PAL− .=3-GIs are of minor technical nature.
More importantly for is is that PAL− .=3-GIs have no branching points. But in
Chpt. 16, where the method of separating ligatures at branching points has
been discussed, it has been, roughly speaking, shown that instead of branching
points, it is (semantically) suﬃcient to have the relation name .=3 in our
alphabet. That is, we obtain the following lemma:

.

Lemma 26.7 (PAL−
out or with branching points).
have:

=3 - and PAL-GIs are equivalent to RGIs withLet A be a given alphabet. Then we

1. For each RGI G without branching points over A, there exists a corresponding PAL− .=3-GI G0 which expresses the same relation, i.e., we have
RM,G = RM,G0 for all models M.

2. For each RGI G over A, there exists a corresponding PAL-GI G0 which

expresses the same relation.

Proof:

1. Each RGI without branching points G can be easily transformed into a
syntactically equivalent, thus semantically equivalent, PAL− .=3-GI G0 as
follows:

a) With the iteration-rule, each isolated vertex • of G is replaced by

s

s= (compare this to Def. 19.2).

b) Now let v ∈ V be a vertex which is incident with two diﬀerent edges
e, f ∈ E?. With the rule ’adding a vertex to a ligature’, we add a
vertex v0 and a new identity link between v and v0, and on (e, 1), v is
replaced by v0.

The resulting graph has still no branching point, it is equivalent to G and
satisﬁes now the second and third condition of Lem. 26.6, too. That is, it
is a PAL− .=3-graph instance.

2. According to 1), we ﬁrst assume that G satisﬁes the second and third
condition of Lem. 26.6. We have shown in Lemma 16.3 that a branching
point with more than three branches can be converted into a ‘wheel’ or
a ’fork’ (see page 173), where only branching points with three branches
occur. Then, for each vertex v which is a branching point with three
branches, we separate a ligature at v (see page 184 ﬀ). That is, each
device

26.3 Graphs for Peircean Algebraic Logic

307

is ﬁrst is replaced by

or

and after that, each device

is replaced by

As both conversions respect the second and third condition of Lem. 26.6,
the resulting graph is a PAL-graph G0 which is syntactically, thus seman2
tically, equivalent to G.

So the class of all RGIs without branching points over A has the same expressiveness as the class of all PAL− .=3-GIs over A=, and the class of all RGIs,
where branching points are allowed, the same expressiveness as the class of
all PAL-GIs over A.

The operations of Def. 26.1 are semantical operations on relations, the operations of Def. 26.4 are syntactical operations on graphs. Thus before we use
Thm. 26.3 in the next section to prove the graph-version of Peirce’s reduction thesis, we still have to show that the syntactical operations of Def. 26.4
correspond semantically to the operations of Def. 26.1.

Lemma 26.8 (Inductive Semantics of PAL−
PAL− .=3-GIs and let M := (U, I) be a model. Then we have:

=3 -GIs). Let G, G1, G2 be

.

1. Atomar graphs: RM,GR = I(R) and RM,G?1 = U . Particularly we have

RM,G .
=3

= IdU
3 .

2. Product: RM,G1×G2 = RM,G1 × RM,G2
3. Join: RM,δi,j (G) = δi,j(RM,G)
4. Complement: RM,¬G = ¬RM,G
5. Permutation: RM,πα(G) = πα(RM,G)

Proof: The proof is carried out by induction over the construction of PAL− .=3GIs. The lemma is easily seen for atomar graphs, and the operations product,
join, and permutation. It remains to show RM,¬G = ¬RM,G.
Let Gc be the graph obtained from G by completely enclosing it with the fresh
.
cut c. That is, Gc := (V, E, ν, c, Cut
∪ {>}, areac, κ with areac(c) := {>} and
areac(d) := area(d) for each d ∈ Cut∪{>} (note that for FV(G) 6= ∅, the RGI

1234n234n11234n3123308

26 Peirce’s Reduction Thesis

Gc is not normed, particularly not a PAL− .=3-GI). We have RM,Gc = ¬RM,G.
Now we show that Gc and ¬G are syntactically, thus semantically, equivalent,
by providing a proof for Gc ‘? ¬G which uses only rules which can be carried
out in both directions. The transformation is similar (but not identical) to
the normalization of an RGIs (see Def. 25.9).

1. Our example is the graph

G :=

, thus Gc =

For each ?i ∈ FV(Gc), the edge of Gc labeled with ?i is denoted e?i, and
the vertex incident with e?i is denoted v?i.
For the following steps, please note that as G is a PAL− .=3-GI, each vertex
v?i of V ? belongs either to T3(V c) or to T4(V c) (we use the notation of
the proof of Lem. 26.6).

2. For each ?i ∈ FV(Gc), we add a new vertex w?i and a new edge f?i with
ν(f?i) = (v?i) and κ(f?i) =?i to the sheet of assertion. Within the calculus,
this is done with the existence of constants rule.

3. For each vertex v?i with v?i ∈ T4(V c), we erase the subgraph consisting

of v?i and e?i from > (recall that > is a cut in Gc).

4. For each vertex v?i with v?i ∈ T3(V c), we add an new identity edge id?i

between w?i and v?i to >.

5. Similarly to the ﬁfth step in the normalization of a graph, for each ?i with

v?i ∈ T3(V c), the edge e?i is deiterated from >.

6. Finally, for each ?i with v?i ∈ T3(V c), the identity edge id?i and the vertex

v?i is erased with the rule ’removing a vertex from a ligature’.

The last graph is (isomorphic to) ¬G, thus we are done.

2

2?1?3R1?22?1?3R1?22?1?1?3R1?2?3?22?1?3R1?2?2?32?1?3R1?2?2?3?12R1?2?3?12R1?3?226.4 Peirce’s Reduction Thesis for Relation Graphs

309

Please note that the last step of the proof relies of G being a PAL− .=3-GI. To
see this, consider the following graphs:

Let G :=

, thus ¬G =

and Gc =

.

Then we have RM,G = {(u, v) ∈ U 2 | u = v} (= I( .=)), RM,¬G = ∅, and
RM,Gc = {(u, v) ∈ U 2 | u 6= v}. So, even for the normed RGI G, we have
RM,Gc 6= RM,¬G.
Comment: On page 64, it was argued why we deﬁned graphs not inductively, but
in one step. For PAL−
=3 -GIs, their inductive deﬁnition is canonical. If we had so
far no semantics for these graphs, the ﬁve propositions of Lem. 26.8 could serve as
=3 -GIs do not have an unique
an inductive deﬁnition of their semantics. But PAL−
derivational history. For example, the constructions

.

.

δ2,3(δ4,5((GR × GS) × GT ))

and

π(1,2)(δ1,4(δ2,3(GS × GT ) × GR))

both yield the same graph

G :=

.

Thus for a model (U, I), an inductively semantics would assign (at least) the two
relations δ2,3(δ4,5((I(R) × I(S)) × I(T ))) and π(1,2)(δ1,4(δ2,3(I(S) × I(T )) × I(R)))
to G. So the semantics is not well-deﬁned unless it is proven that these terms yield
indeed the same relation.

Lem. 26.8 can now be understood to provide such a proof, as it shows that an
=3 -graphs yields simply the same
inductive deﬁnition of the semantics for PAL−
semantics as deﬁned in Def. 25.5. Particularly, it is well-deﬁned.

.

26.4 Peirce’s Reduction Thesis for Relation Graphs

After providing the algebraic version of Peirce’s reduction thesis in Sec. 26.2,
and the counterparts for RGIs of the algebraic operations in Sec. 26.3, we can
now elaborate the full account the graph-version of Peirce’s reduction thesis.

Before we do so, we will shortly discuss branching points in PAL-GIs. Strictly
speaking, in the understanding that branching points are vertices which are
attached to more than three hooks, PAL-GIs do not have branching points.
But of course, as we have it already used in the proof of Lem. 26.7, edges
which are labeled with the name .=3 for the teridentity can be understood as
branching points. When we ﬁrst introduced the names .=k on page 184 ﬀ, this
was done in the context to separate ligatures into single object ligatures. For
this purpose, it was reasonable that in the graphical representation of formal
EGs, we really used the signs .=k in their graphical representations (see for
example the formal EGs in Figs. 16.5 and 16.3).
Now, formal PAL− .=3-graphs and formal PAL-graphs are deﬁned in the usual
manner, i.e. by factorizing the class of all PAL− .=3-GIs and formal PAL-GIs

?1?2?1?2?1?2?1R12S12T12?2310

26 Peirce’s Reduction Thesis

by means of the transformation rules for ligatures. Moreover, we agree that
changing the order of the hooks of an edge labeled with .=3 is a further allowed
transformation rule for ligatures. For example, the PAL-GIs

and

are in the class of the same formal PAL-graph.

For the graphical representation of PAL-GIs, we now agree that an edge labeled with .=3 is represented as a branch of three heavily drawn lines, without
using the sign .=3. I.e., we agree that the formal formal PAL-graph generated
by either one of the just given PAL-GIs is depicted as follows:

In the following, we ﬁrst show that each relation of arity higher than two can
be expressed with PAL-GIs by means of relations of arity one and two. To
make this more precise: If M := (U, I) is a model such that

• for each relation % of arity one or two, there exists a corresponding relation

name R with I(R) = %, and

• we have a name .=3 for the teridentity (i.e., ( .=3) = IdU

3 ),

then for each relation % there exists a PAL-graph G, where –besides .=3– only
relation names of arity one or two occur, and which satisﬁes RM,G = %.
We have to distinguish two cases. Let us ﬁrst consider the case where U is
inﬁnite. Let % ⊆ U n be a relation with n ≥ 3. Using an index set I for
enumerating the pairs in %, we have:

% = {(u1,i, u2,i, . . . , un,i) | i ∈ I}

As U is inﬁnite, we have |%| ≤ |U n| = |U |. So w.l.o.g. we can assume I ⊆ U .
Now for k = 1, . . . , n, let %k := {(uk,i, i) | i ∈ I}, and let Rk be a relation
name with I(Rk) = %k. Then the RGI

evaluates in M to %. The given graph is not a PAL-GI, as it has n − 2
branching points. By separating the ligatures at these vertices, this graph can

3123PST1113PST11113211ST1PR2121R?2221RR21R21?nn?n−1n−1?11?33............26.4 Peirce’s Reduction Thesis for Relation Graphs

311

can be transformed into a semantically equivalent PAL-GI. This PAL-GI, and
moreover the corresponding formal PAL graph, is provided in Fig. 26.1.

Fig. 26.1. A PAL-GI and the corresponding PAL-graph which evaluate to %

Comment: For the algebraic version of PAL, as it was developed in Sec. 26.2, there
exists a corresponding term which evaluates to %. If we use ◦ as the usual notation
for the composition of the unary functions δi,j, J for an indexed representation of
this composition, and N for an indexed representation of the product of relations,
the PAL-expression is as follows:

% =

 "n−3
K

i=0

δ2+5i,4+5i ◦ δ4+5i,6+5i

◦ δ2+5(n−2),4+5(n−2)

%1 ×

#

!

!

%i+1× .=3

n−3
O

i=0

For example, for ar(%) = 4; we have

% = δ2,4(δ4,6(δ7,9(δ9,11(δ12,14(δ14,16(δ17,19(R1 × R2× .=3 ×R3× .=3 R4)))))))

This shows that although they have the same expressiveness, the PAL-graphs are
much easier to read than the corresponding terms of the algebraic version of PAL.

If U is ﬁnite, we might have |%| > |U |. Thus the ’technical trick’ to use some
elements of U to refer to the tuples of % does only work if the universe U is
inﬁnite. So for us, a diﬀerent approach is needed.

Now let U be ﬁnite and % be an n-ary relation with k elements, i.e.,

% = {(u1,i, . . . , un,i) | i = 1, . . . , k}

In contrast to Herzberger or Burch, we can express ﬁnite unions of relations
within the system of PAL-graphs. This will be used to ﬁnd a PAL-graph G
with RM,G = %. First, for j = 1, . . . , n and i := 1, . . . , k, we set %j,i := {(uj,i)}.
For i = 1, . . . , k, the product %1,i × %2,i × . . . × %n,i yields the n-ary relation
which contains exactly the ith tuple of % as element. So % is the union of these
relations, and we see that the semi RGI

321R?33?2221R33?11R21R21?1?3...?2?n−1?n13......R21221Rn−1nR21R2121R..................?n−1n−1?nnR211,k,nk2,k?2?n?1?1?2?n,nk−1R2,k−1R1,k−1R,22R,12Rn2,R,21Rn1,R,11R...?1?2?n............RRR......?1?2?n......312

26 Peirce’s Reduction Thesis

evaluates in M to %. This graph is not an RGI, but we can consider its (semantically equivalent) normalization instead. This graph is, after we reduced
the set of vertices with the rule ’removing a vertex from a ligature’:

Similar to the last case, in Fig. 26.2 a semantically equivalent PAL-GI and
the corresponding formal PAL-graph are depicted.

Fig. 26.2. A PAL-GI and the corresponding PAL-graph which evaluate to %

Comment: For this construction, it is even more tedious to write down the corresponding PAL-term. Instead of the general term, we provide only the term for case
ar(%) = 3 and |%| = 4. It is:

?2?n...?1,11,21n1,,12,22n2,1,k2,k,nk,nk−1R2,k−1R1,k−1R...............RRRRRR......RRR...,11,21n1,,12,22n2,...RRR31,k−1R2,k−1R,nk−1R1,k2,k,nk...RRR33333?2?n...?1333...RRR...............,11,21n1,1,k2,k,nk...RRR1,k−1R2,k−1R,nk−1R......?2?n...?1,12,22n2,...RRRRRR............26.4 Peirce’s Reduction Thesis for Relation Graphs

313

% = `δ1,2 ◦ δ2,5 ◦ δ3,8 ◦ δ4,12 ◦ δ5,13 ◦ δ6,15 ◦ δ7,17 ◦ δ8,19 ◦ δ9,21 ◦

δ10,21 ◦ δ11,24 ◦ δ12,27 ◦ δ14,20 ◦ δ17,23 ◦ δ20,26 ◦ δ24,29 ◦ δ27,33 ◦ δ30,37´
“
¬ˆ¬(R1,1 × R2,1 × R3,1) × ¬(R1,2 × R2,2 × R3,2)
×¬(R1,3 × R2,3 × R3,3) × ¬(R1,4 × R2,4 × R3,4)˜
× .=3 × .=3 × .=3 × .=3 × .=3 × .=3 × .=3 × .=3 × .=3

”

We have shown that with PAL-graphs and relations of arity 1 and 2, each
relation can be expressed. But in these graphs, the teridentity, i.e. a ternary
relation, is needed as well. The essence of Thm. 26.3 is that, using the PAL− .=3operations on relations, the teridentity cannot be expressed with unary and
dyadic relations only. On the side of the graphs, if we consider PAL− .=3graphs over relations of arity 1 or 2, we cannot express the teridentity. This
is the subject of the next theorem which is the graph-based counterpart of
Thm. 26.3.

Theorem 26.9 (Peirce’s Reduction Thesis for Relation Graph Instances). Let an alphabet A := (R, ar) be given with ar(R) ∈ {1, 2} for each
R ∈ R. Let G be an normed RGI without branching points over A and let
M := (U, I) be a model over A with |U | ≥ 2. Then we have

RM,G ∈ hMiPAL−

.
=3

, particularly

RM,G 6= IdU
3

Proof: Due to Lem. 26.7, we can w.l.o.g. assume that G is a PAL− .=3-GI. Let
Σ be the set of all 1- and 2-ary relations over U . Lem. 26.8 immediately yields
3 . 2
RM,G ∈ hMiPAL−
As relation graphs are classes of RGIs, we immediately obtain the following
corollary.

=3 . Now Thm. 26.3 yields RM,G 6= IdU

=3 ⊆ hΣiPAL−

.

.

Corollary 26.10 (Peirce’s Reduction Thesis for Relation Graphs).
Let an alphabet A := (R, ar) be given with ar(R) ∈ {1, 2} for each R ∈ R.
Let G be an normed relation graph without branching points over A and let
M := (U, I) be a model over A with |U | ≥ 2. Then we have

RM,G ∈ hMiPAL−

.
=3

, particularly

RM,G 6= IdU
3

Please note that it is mandatory to consider normed relation graphs. The
following semi relation graph has no branching points and trivially evaluates
to the teridentity in each model.

?1?2?2?3314

26 Peirce’s Reduction Thesis

26.5 The Contributions of Herzberger and Burch

We have used the result of Hereth Correia and P¨oschel in [HCP06] to provide
a graph version of Peirce’s reduction thesis. Their version of the reduction
thesis strictly extends the results of Herzberger [Her81] and Burch [Bur91a].
The diﬀerences between these three works shall be discussed in this section.
We start with the negative part of the reduction thesis, i.e., that not every
ternary relation can be constructed from unary and binary relations only.

To the best of my knowledge, Herzberger was the ﬁrst to provide mathematical
elaboration of Peirce’s reduction thesis. Roughly speaking, in Herzberger’s
approach, the Cartesian product of relations is not considered as an operation
on relations. That is, On the side of the graphs, the juxtaposition of graphs
is not allowed.

At the beginning of the last chapter, it was already discussed that relations can
are joined. According to Herzberger, this was for Peirce the most fundamental
operation on relations. So Herzberger ﬁrst considers a ‘miniature setting’ (this
term is used by Herzberger) where only the join of relations is allowed. To be
more precisely: Herzberger uses two join operations: One is taking one relation
as argument and joins two blanks of this relation, the second is taking two
relation as arguments and joins one blank of the ﬁrst relation and one blank of
the second relation. In both cases, the join of two relations of arity ≤ 2 yields
again a relation of arity ≤ 2. Thus it is easy to see that no ternary relation can
be constructed by means of unary or binary relations. So the negative part
of Peirce’s reduction thesis trivially holds in this setting. Herzberger then
extends the miniature setting by considering permutations and complements
of relations as well. But as these relations do not change the arity of a graph,
the negative part of Peirce’s reduction thesis still holds for the same simple
arity argument.

Burch extends in [Bur91a] the approach of Herzberger by considering the
product of relations as well. But in contrast to Hereth Correia and P¨oschel,
he allows to build the product of relations only as last step or before last
step (when the last step is building the complement of the relation) in the
construction of relations. Thus, in Burch’s setting, again using the arity argument, each ternary relation is the Cartesian product of three unary relations
or of an unary and a binary relation, or it is the complement of such an Cartesian product. It can easily be seen that in models with more than one element,
the teridentity cannot be of this form, so the negative part of the reduction
thesis still holds in this setting.

Hereth Correia and P¨oschel ﬁnally allow to build the product of relations in
arbitrary steps in the construction of a relation. The simple arity argument

26.5 The Contributions of Herzberger and Burch

315

of Herzberger and Burch cannot be applied in this setting anymore, and the
proof of the reduction thesis in contrast becomes exceedingly diﬃcult.2

It is hard to decide which approach is closest to Peirce’s thinking. Herzberger
gives good reasons that Peirce did not want to consider operations on relations which violate the arity argument. In fact, Peirce himself argues in some
places for the reduction thesis only with this argument (for example in 1.346).
Herzberger introduces the notion of ’valency-regular operations’, and argues
that Peirce aimed to show that valency-irregular operations are dispensable.
The Cartesian product of relations is such a valency-irregular operation, so
by introducing this operation, Burch departs from Herzberger’s point of view.
An argument Burch gives is that his approach is closer to Peirce’s existential
graphs. Nonetheless, as it will be shortly discussed, not all existential graphs
can be obtained from Burch’s operations.

To clarify matters, let us introduce Herzberger and Burch graphs. Similar to
the approach in this chapter, we could introduce operations on RGIs according
to the Herzberger’s and Burch’s operations on relations. Let us call an RGI a
Herzberger-RGI resp. a Burch-RGI, if it can be constructed from atomar
graphs with Herzberger’s or Burch’s operations. Obviously, we can lift this
deﬁnition to RGs by saying that an RG is a Herzberger graph resp. a
Burch graph, if the the underlying RGIs are Herzberger-RGI resp. a
Burch-RGI. Finally, let us call a RGI (V, E, ν, >, Cut, area, κ) connected
iﬀ (V, E, ν) is connected, and a relation graph is called connected if the
underlying RGIs are connected. It can be easily proven that all Herzberger
graphs are connected. Similarly, each Burch graph is the juxtaposition of
connected RGs, or the negation of such a juxtaposition.

Not all graphs Peirce provided in his writings are of this form. In the following, some examples from Peirce are given. In a comment on page 115, we
investigated how Peirce discusses in 4.449 how heavy lines crossing a cut are
understood. Below, you ﬁnd another graph of this discussion Peirce provides.
Another example can be found on page 22 of [PS00], where Peirce exempliﬁes
the iteration rule (we already used this example on page 153). Two further
examples are taken from 4.502, where Peirce provides a total of 25 graphs
to explain the transformation rules. Here Figs. 169 and 177 of these graphs
are provided (I slightly changed the diagram of Fig. 169: In the diagram in
[HB35], the right ligature which is attached to ‘respects’ and ‘knows’ ends
on the cut, instead of crossing it. This is a degenerate cut. But as Points on
a cut are considered outside the cut, I extended the ligature outwardly. See
Sec. 11.4). All these graphs are given in Fig. 26.3. None of these graphs is a
Herzberger graph or a Burch graph, but they can both be constructed with
the operations we provided in Def. 26.4. This shows that neither Herzberger’s

2 In total, it took Hereth Correia nearly three years to ﬁnd the proof (personal

communication).

316

26 Peirce’s Reduction Thesis

nor Burch’s approach captures all existential or relation graphs Peirce had in
mind.3

Fig. 26.3. Fig. 84 of 4.449 and a graph of page 22 of [PS00]

Let us now come to the positive part of the reduction thesis, namely that an
arbitrary relation % of arity ≥ 4 can be constructed from unary, binary and
ternary relations.

In the last section, we have proven the positive part of the reduction thesis
by providing two PAL-graphs: The graph of Fig. 26.1 was used for inﬁnite
universes, the graph of Fig. 26.2 was used for ﬁnite universes. But as the just
provided discussion shows, the graph of Fig. 26.2 is not a Herzberger or Burch
graph. Both Herzberger and Burch use the graph of Fig. 26.1 to represent a
ﬁnite relation % as well. Recall that the underlying idea in this graph was to
enumerate all tuples of varrho by means of elements of the universe. That is,
we can represent a relation with the graph of Fig. 26.1 only if the universe U
contains at least as many elements as the number of tuples in the relation. For
this reason, Herzberger ﬁrst proves in theorem 4 a restricted version of the
positive part, where a relation of arity ≥ 4 can be reduced within suﬃciently
large universes, i.e., for universes U with |U | ≥ |%| (particularly, for inﬁnite
universes). Nonetheless, even for the case |U | < |%| both Herzberger and
Burch use the graph of Fig. 26.1 to represent %. To enumerate the elements of
%, they augment (by means of Peirce’s hypostatic abstraction) the universe U

3 Moreover, the PAL-system provided in this treatise is closer to the system of
relational algebra: The equivalence of the PAL-system and relational algebra has
been shown in [HCP04].

Existsis a salamanderlives in fire(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:0)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)(cid:1)PMMSis oldrespectsknowsis wiseis a kingrespectsknowsis wiseis a kingis old26.5 The Contributions of Herzberger and Burch

317

with new elements to denote the tuples of %, i.e., they extend the universe U
to a larger universe U +. In fact, Peirce argues similarly for the positive part
of his reduction thesis (see for example 1.363). With the herein considered
PAL-graphs, this ‘trick’ is dispensable, as we have shown that for each model
M = (U, I) and each relation % ⊆ U n (with n ≥ 3), there exists a PAL-graph
G with RM,G = %. That is, we can express % within M, i.e., without extending
U .

318

26 Peirce’s Reduction Thesis

Appendix

Referenced Authors

Barwise, 2, 51
Burch, 3, 99, 108, 158, 244, 281, 282,

285, 297–298, 314–316

Chein, 109, 187

Dipert, 26

Etchemendy, 2

Frege, 1, 2, 7, 37

Haack, 37
Hammer, 22
Hereth Correia, 109, 187, 297–299, 314
Herzberger, 297–298, 314–316
Hookway, 26
Howse, 46

Keeler, 6, 25, 26

Mugnier, 109, 187

P¨oschel, 109, 187, 244, 285, 297–299,

314
Pape, 26
Pietarinen, 8
Pollandt, 109, 187, 285
Putnam, 2

Roberts, 3, 7, 32, 39, 41, 42, 55, 56, 99,

105, 118
Russell, 3, 34

Shimojima, 21
Shin, 3, 7, 22, 33, 39–42, 46, 55–58, 64,

186

Sowa, 3, 34, 39, 92, 105

Tennant, 1

Whitehead, 3, 34
Wille, 285

Zeman, 3, 8, 39, 55–57, 64, 108, 157,

281

Symbols

(U, I), 141, 246
(V, Eid), 127, 269
<, 64, 65, 125
E, 124
E?, 285
EC, 263
Eid, 126
Enonid, 126
Ev, 124
I, 141
I f , 286
I f
C , 286
IC, 246
IF , 246
IR, 141, 246
T1(V ), 303
T2(V ), 303
T3(V ), 303
T4(V ), 303
U , 141
V , 63, 124
V ∗, 206
V Var, 206
Ve, 124
[G]∼, 139, 148
ff, 284
(V, >, Cut, area, κ), 63
C, 245, 285
F , 245, 285
R, 126, 198, 245, 285
A, 126, 245, 285
A=, 183
A?, 285

.

=3 , 302
A
Cut, 63, 124
EGI, 126, 246
(V, E, ν, >, Cut, area, κ, ρ), 206, 260
VEGI, 260
VEGI sp,A, 264
∼=, 210
FV, 197, 285
.
G[c, ref
∪ val], 213
G[c, ref ], 142, 143
G[c], 75
G1 × G2, 299
G[v7→α], 213
IdU
k , 183
M, 141, 246, 286
M[f ], 286
Negf , 200
Negf ∪ {>f }, 200
(V, E, ν, >, Cut, area), 124
Rel(U ), 286
RM,G, 287
>, 63, 124
area, 63, 124
≤[c], 65, 66, 67, 125
(cid:12)[c], 65, 66, 67, 125
ctx, 63, 67, 124
.=, 126, 142, 212, 245, 262
.=k, 104, 117, 183, 184–187
|=class, 142
|=endo, 143, 213
Φ, 209, 212, 215, 227
Φα, 93
Π, 254

322

Symbols

Ψ , 206, 213, 215, 226, 227, 253
ΨV , 255
Ψα, 92
Ψ∀, 218, 218
Ψext, 255
tt, 284
Θ, 163, 265, 269
Θ∗, 269
(cid:13)v, 267
Ξ, 262, 263
αempty, 209
β, 65, 125
δi,j(G), 299
δi,j(%), 298
ref , 142, 143, 213
κ, 63, 126, 246, 260, 285
hMiPAL, 299
hMi
PAL−
hΣiPAL, 299
hΣi
=3 , 299
PAL−
≤, 65, 67, 125, 125, 200
(cid:12), 65, 125
|=, 75
|=?, 287
|=endo, 143
|=val, 201
¬G, 299
¬%, 298
ν, 124

=3 , 299

.

.

area, 231
πα(G), 299
πα(%), 298
?i, 283, 285
ρ, 206, 260
σ, 286
∼, 139, 148, 271
v, 232
%, 286
% × σ, 298
‘, 79, 167, 202
‘?, 288
‘e, 267
‘r
e, 267
‘v, 267
‘r
v, 267
ar, 126, 245
ar(F DGraph), 285
ar(%), 286
f [xj/xi], 199
norm(G), 291
palc(G), 303
ref , 142, 142, 143, 212, 213, 262
.
ref
∪ val, 213
ve, 124, 249, 285
val, 142, 212, 213, 262
ff, 75
tt, 75

Index

α-Conversion, 199

Abduction, 31
adequate, 259
Alpha, 2, 8–11
Alpha Graphs (Shin’s Deﬁnition), 40
Alphabet, 49, 126, 245, 285

Query-Marker-Extension, 285

Area, 9, 10
Area-Space, 128–133
Arity

of a Function, 245
of a Relation, 286
of a Semi Relation Graph Instance,

285

Begriﬀsschrift, 1, 7, 37
Beta, 2, 8, 11–14
Beta Graphs (Shin’s Deﬁnition), 40
Blank, 103, 282
Blank Form, 108
Branch, 128
Branching Point, 12, 41, 98, 100, 101,

101–103, 128, 173, 174, 183, 303,
306, 309–310

Calculus, 157
Moving, 157, 169, 175
Moving across Cuts, 158–159

Broken Cut, 15
Burch Graph, 315

Calculus, 10, 33

Alpha, 10, 76–77
Beta, 13

Equivalence Rules, 150
Existential Graph Instance, 163
First Order Logic, 203, 202–203
Formal Alpha Graphs, 78
Formal Existential Graphs, 167
Generalization Rules, 150
Graphical, 235–237
Peirce’s Understanding, 33
Semi Relation Graph Instances, 288
Shin’s Version, 57
Vertex-Based Existential Graph

Instance, 270

Vertex-Based Existential Graph

Instances, 267–268

Calculus Ratiocinator, 33
Categories, 18, 297
Classical Evaluation, see Evaluation
Classiﬁcation of Sciences, 29
Close, 9
Closed Subgraph, 134, 134–135
Collected Papers, 6
Colligation, 33
Comment, 6
Community, 31, 32
Completeness

Existential Graph Instance, 228
extended Existential Graph Instance,

253

First Order Logic, 203
Formal Alpha Graphs, 88, 86–89
Relation Graph Instances, 292
Semi Relation Graph Instances, 288

324

Index

Vertex-Based Existential Graph

Formal Existential Graph, 132–133,

Instances, 272

Conclusion, 14
Conjunction, 9, 10, 12, 206
Connect, 127
Connected, 127
Consistent, 86
Constant Name, 102, 245, 285

Rules, 252

Constant Vertex, 260
Context, 66, 67, 125, 150

Existential Graph Instance, 124
Formal Alpha Graphs, 63
Negative, 72, 125, 150
Ordering, 65, 125
Positive, 72, 125, 150
Convention No. Zero, 44
Cut, 8, 36

Alpha, 62
Existential Graph Instance, 124
Formal Alpha Graphs, 63

Cut Condition, 191

Classical Evaluation, 142
Endoporeutic Evaluation, 143
Existential Graph Instance with

Variables, 213

Formal Alpha Graphs, 75
Isomorphism, 136

Cut-And-Paste-Theorem, 80
Cut-Line, 128, 128–133
Cuts, 111–121
Cycle, 127

Deduction, 31
Deduction Theorem, 80
Degenerated Graph, 117, 120, 121
Deiterating Constant Labels, 275
Delta, 8
Derive

Existential Graph Instance, 167
First Order Logic, 202
Formal Alpha Graphs, 79
Diagram, 17–18, 21, 35, 39–53
Barwise and Etchemendy, 2
Chemistry, 282
Existential Graph Instances, 128–133,

229–240

Vertex-Based Existential Graph

Instance, 260–261

Diagrammatic Reasoning, 1, 2, 17, 25
Directly Enclosed, 134

Alpha, 65
Existential Graph Instance, 125

Dominating Nodes, 125, 143
Double Cut, 10, 13, 159–161

Edge, 109–110

Existential Graph Instance, 124
Pending, 285

Edge Condition, 191

Classical Evaluation, 142
Endoporeutic Evaluation, 143
Existential Graph Instance with

Variables, 213
Isomorphism, 136
Edge-Line, 129, 128–133
Enclosed, 128, 134, 231

Alpha, 62, 65
Directly, 134
Evenly, 10, 72, 125, 134
Existential Graph Instance, 125, 125
Oddly, 10, 72, 125, 134

Endoporeutic Evaluation, 143, 213
Endoporeutic Method, 9, 142, 143, 213
Erasure, 33
Euclidean Plane, 45, 46
Euler Circles, 1
Evaluation, 143, 213

Classical, 142
Equivalence, 144
First Order Logic, 201
Formal Alpha Graphs, 75
Propositional Logic, 92

Evenly Enclosed, see Enclosed
Existential Graph, 210
Existential Graph Instance, 126,

126–133

Representation, 128–133

Existential Graph Instance (extended),

229–240

246

Formal Alpha graphs, 61–62, 68,

Existential Graph Instance with

67–70

Variables, 206

First Order Logic, 2, 8, 49, 142,

197–203, 210
Firstness, 18, 297
Forest, 127
Formal Existential Graph, 139
Formula

Structure, 200

Formulas, 49

Equivalence Relation, 210
First Order Logic, 197
Propositional Logic, 91
Subformula Occurrences, 199
Universal Closure, 218

Free Ride, 21
Fresh, 138
Function Name, 245, 285

Rules, 249

Gamma, 2, 8, 14–16
Generalizing Labels of Vertices, 275
Generic Marker, 206
Generic Vertex, 206, 260
Grapheus, 37
Graphist, 37

Heavily Drawn Line, 97, 105
Crossing a Cut, 111–121

Heavily Marked Point, 98, 99, 107,

161–162
On a Cut, 112

Herzberger Graph, 315
Hook, 108, 108, 128
Attached to, 128
Replaced on, 128, 169

Hypostatic Abstraction, 15, 316
Hypothetical Universe, 28, 29, 34, 37

Icon, 18, 19, 20
Identity, 97–100, 104, 109, 111–117,

126, 179, 183, 203, 245, 285

Identity Spot, 99, 100, 106, 107

On a Cut, 112

Identity-Edge, 126, 129
Implication, 28, 36
Index, 18, 19
Induction, 30
Inductive Deﬁnition, 63, 309
Informal Deﬁnition, 6
Interpretant, 19, 20

Index

325

Interpretation, 141
Isomorphism, 68, 135

Except Cuts, 71, 136, 145
Partial, 71, 136, 145

Iterating Constant Labels, 275
Iteration, 33

Join of Relatives, see Relatives
Judgement, 8
Juxtaposition, 9, 35, 81, 206

Existential Graph Instance, 136
Formal Alpha Graphs, 73

Knowledge, 27

Leaf, 127
Ligature, 12, 98–107, 127, 169–187, 269

Calculus, 153, 155, 150–159
Crossing a Cut, 111–121
Extending or Restricting, 172, 277
Generic, 269
Idiotic, 100
Joining, 184
Rearranging, 174, 277
Retracting, 173, 174, 181, 277
Separating, 183–187
Single-Object, 179, 180, 181, 184–187
Vertex-Based Existential Graph

Instances, 274–279

Ligature-Graph, 127, 269
Line of Identity, 11, 35, 98–107
’Crossing a Cut’, 111–121

Logic, 26
Loop, 127
Loose End, 103, 155, 282

Mathematical Reasoning, 1, 2, 17, 27,

29, 32

Medad, 8
Merging two Vertices, 175, 176
Meta-Level Proposition, 15
Modal Logic, 3, 15
Model, 28

Beta, 201
Existential Graph Instance, 141
extended Existential Graph Instance,

246

Formal Alpha Graphs, 75
Relational, 141, 246
Modus Ponens, 10, 218

326

Index

Necessary Reasoning, 27–29, 32, 36
Negation, 9, 10, 12
Negative Context, see Context
Nesting, 9

Alpha, 64

Non-Degenerated Graph, 117, 120, 121,

230

Normalization, 289, 291

Object Vertex, 260
Oddly Enclosed, 10, 134, see Enclosed

PAL, 244, 281

Complexity, 303
Operations on Graphs, 299
Operations on Relations, 298
PAL Graph Instance, 302, 303, 306

Inductive Semantics, 307

.

PAL−{

=3} Graph Instance, 302, 306

Peirce and Mitchell, 2

Query Marker

Assignment, 286
Calculus, 288
Extension of a Model, 286
Extension of an Alphabet, 285
Restriction of a Model, 286

Rational Communication, 31
Reasoning, 1, 2, 25, 27–30, 32, 33, 37

Patterns, 33
Self-Correcting, 30, 31

Relation, 107–110, 282–283, 286

Arity, 286, 314
Complement, 298
Finitary, 286
Join, 282–283, 298, 314
Permutation, 298
Product, 298

Inductive Semantics, 307

Relation Graph Instance, 284, 289, 306

Partial Isomorphism, see Isomorphism
Partial Valuation, see Valuation
Path, 127
Peirce’s Reduction Thesis, 101, 103, 285

Algebraic Version, 299
for Relation Graph Instances, 313
for Relation Graphs, 313

Peircean Algebraic Logic, see PAL
Positive Context, see Context
Pragmatism, 25
Predicate, 11, 107–110
Predicate Spot, 108
Principia Mathematica, 3, 34
Proof

Existential Graph Instance, 167
First Order Logic, 202
Formal Alpha Graphs, 79

Proposition, 8, 10, 35, 108
Propositional Logic, 2, 10, 91, 91–95
Propositional Variables, 61, 62, 91

Occurences, 62
Provably Equivalent

Existential Graph Instance, 167
First Order Logic, 202
Formal Alpha Graphs, 79

Psychologism, 37

Quantiﬁcation, 12, 102, 142, 198, 203,

218

Atomar Graph, 299
Complement, 299
Join, 299
Normed, 289, 303
Permutation, 299
Product, 299

Relation Name, 126, 198, 245, 285
Relational Graph with Cuts, 246, 260
Relational Graphs with Cuts, 124,

123–125

Relational Structure, see Model
Relations, 107, 243–244, 281

Product, 297

Relatives, 103, 104, 107, 243–244,

281–283

Replica, 23, 39, 44, 41–45, 230
Representation Problem, 45, 49–51
Reversion Theorem, 80
Rule of Deformation, 44

Scribing, 8
Scroll, 10, 36, 41, 208
Secondness, 18, 297
Semantics

Existential Graph Instance, 142, 143
Existential Graph Instance with

Variables, 213
First Order Logic, 201
Formal Alpha Graphs, 75

Formal Existential Graphs, 148

Formal Alpha Graphs, 79

Index

327

Semi Relation Graph Instance, 284, 285
Semiotics, 17–23, 26
Sep, 8, 44
Separated Constant Vertices

seeVertex, 317

Sheet of Assertion, 8, 10, 34, 124

Existential Graph Instance, 124
Formal Alpha Graphs, 63

Sign, 23, 17–23, 27
Single-Object Ligature, 179, 180, 181,

184–187

Soundness

Constant Vertex Rule, 266
Existential Graph Instance, 196,

189–196

First Order Logic, 203
Formal Alpha Graphs, 85, 83–85
Function Rule, 250
Main Lemma for Alpha, 83
Main Lemma for Beta, 145, 147
Relation Graph Instances, 291
Semi Relation Graph Instances, 288
Transformation Rules for Ligatures,

147

Vertex-Based Existential Graph

Instances, 272

Specializing Labels of Vertices, 275
Splitting a Vertex, 175, 176
Standard-Form, 208, 227
Standardization, 208
Star, 183
Subformulas

First Order Logic, 197

Subgraph, 42, 127, 134, 134–135

Alpha, 70, 70–71
Beta, 134, 134–135
Calculus, 151–152
Closed, 134
Existential Graph Instance, 134
Representation, 230–235
Subgraph-Line, 232, 233, 234
Substitutions, 199
Syllogism, 13, 29
Symbol, 7, 18, 19, 27
Symbolic Logic, 1, 2, 7, 48–51
Syntactical Entailment, 218, 226

Existential Graph Instance, 167
First Order Logic, 202

Teridentity, 99, 101–103, 117, 157, 174,

184, 299, 309–310

Terms, 197, 253–258
Thirdness, 18, 297
Tinctures, 15
Token, 23, 45
Token-Structure, 45
Total Valuation, see Valuation
Transformation Rules, 32, 33
Transformation Rules for Ligatures,

138, 147

Translation, 263
Translations, 91–95, 205–215

Meaning-Preserving, 94, 212, 213,

215, 264
Truth Values, 28, 75
Type, 23, 45
Type-Equivalence, 46
Type-Structure, 45
Type-Token Issue, 23

Universal Language, 37
Universe of Discourse, 16, 34, 141

Valid, 75, 92, 201
Valuation

Extended Partial, 142, 212, 262
First Order Logic, 201
Partial, 75, 142, 145, 212, 262
Total, 75, 142, 212, 262

Variable Vertex, 206
Variables, 197, 201, 205, 206

Bound, 197
Free, 197

Venn Diagrams, 1
Vertex, 109

Existential Graph Instance, 124
Formal Alpha Graphs, 63
Generic, 206, 271
Separated Constant, 264
Variable, 206
Vertex Condition

Formal Alpha Graphs Graphs, 75

Vertex-Based Existential Graph
Instances, 259, 260

with Separated Constant Vertices,

264

Vertex-Spot, 128, 128–133

References

[AB96] G. Allwein and J. Barwise, editors. Logical Reasoning With Diagrams. Ox-

ford University Press, 1996.

[ACH00] Michael Anderson, Peter Cheng, and Volker Haarslev, editors. Theory and
Application of Diagrams: First International Conference, Diagrams 2000,
volume 1889 of Lecture Notes in Computer Science. Springer, Berlin – Heidelberg – New York, 2000.

[Arn01] Markus Arnold. Einf¨uhrung in die kontextuelle relationenlogik. Master’s

thesis, Darmstadt University of Technology, 2001.

[Bar93] John Barwise. Heterogenous reasoning. In Mineau et al. [MMS93], pages

64–74.

[BE98] J. Barwise and J. Etchemendy. Computers, visualization, and the nature of
reasoning. In Terrell Ward Bynum, Don D. Roberts, and James H. Moor, editors, The Digital Phoenix: How Computers are Changing Philosophy, pages
93–116. Blackwell, London, 1998.

[BF97] Jacqueline Brunning and Paul Forster, editors. The Rule of Reason: The

Philosophy of Charles Sanders Peirce. University of Toronto Press, 1997.

[BMS04] Alan Blackwell, Kim Marriott, and Atsushi Shimojima, editors. Diagrammatic Representation and Inference: Third International Conference, Diagrams 2004, volume 2980 of LNAI. Springer, Berlin – Heidelberg – New
York, 2004.

[Bra01] R. B. Brandom. Begr¨unden und Begreifen. Eine Einf¨uhrung in den Infer-

entialismus. Suhrkamp, Frankfurt, 2001.

[Bru76] W. Brugger. Philosophisches W¨orterbuch. Herder Verlag, Freiburg, 1976.

14. Auﬂage.

[Bur91a] Robert W. Burch. A Peircean Reduction Thesis: The Foundation of Topo-

logical Logic. Texas Tech. University Press, Texas, Lubbock, 1991.

[Bur91b] Robert W. Burch. Valency, adicity, and adity in peirce’s ms 482. Trans-

actions of the Charles S. Peirce Society, 27(2):237–244, 1991.

[Bur92] Robert W. Burch. Valental aspects of peircean algebraic logic. Computers

and Mathematics with Applications, 23(6–9):665–677, 1992.

[Bur94a] Robert W. Burch. Die Logischen Operationen in Peirce’ ’Beschreibung
einer Notation fuer die Logik der Relative’, pages 77–113. Suhrkamp, Frankfurt, 1994.

330

References

[Bur94b] Robert W. Burch. Game theoretical semantics for peirce’s existential

graphs. Synthese, 99:361–375, 1994.

[Bur97a] Robert W. Burch. Peirce on the application of relations to relations. In

Houser et al. [HRE97].

[Bur97b] Robert W. Burch. Peirce’s reduction thesis. In Houser et al. [HRE97].
[Bur97c] Robert W. Burch. A tarski-style semantics for peirce’s beta graphs. In

Brunning and Forster [BF97].

[CM92] M. Chein and M.-L. Mugnier. Conceptual graphs: Fundamental notions.

Revue d’Intelligence Artiﬁciell, 6:365–406, 1992.

[CM95] M. Chein and M.-L. Mugnier. Conceptual graphs are also graphs. Technical report, LIRMM, Universit´e Montpellier II, 1995. Rapport de Recherche
95003.

[Dau03a] Frithjof Dau. Concept graphs without negations: Standardmodels and
standardgraphs. In de Moor et al. [dMLG03], pages 243–256. This paper is
a part of [Dau03b] as well.

[Dau03b] Frithjof Dau. The Logic System of Concept Graphs with Negations and
its Relationship to Predicate Logic, volume 2892 of LNAI. Springer, Berlin –
Heidelberg – New York, November 2003.

[Dau04a] Frithjof Dau. Background knowledge in concept graphs.

In Eklund

[Ekl04], pages 156–171.

[Dau04b] Frithjof Dau. Query graphs with cuts: Mathematical foundations.

In

Blackwell et al. [BMS04], pages 32–50.

[Dau04c] Frithjof Dau. Types and tokens for logic with diagrams: A mathematical
approach. In Karl Erich Wolﬀ, Heather D. Pfeiﬀer, and Harry S. Delugach,
editors, Conceptual Structures at Work: 12th International Conference on
Conceptual Structures, volume 3127 of Lecture Notes in Computer Science,
pages 62–93. Springer, Berlin – Heidelberg – New York, 2004.

[Dau06a] Frithjof Dau. Fixing shin’s reading algorithm for peirce’s existential
graphs. In Dave Barker-Plummer, Richard Cox, and Nik Swoboda, editors,
Diagrams, volume 4045 of LNAI, pages 88–92. Springer, Berlin – Heidelberg
– New York, 2006.

[Dau06b] Frithjof Dau. The role of existential graphs in peirce’s philosophy.

In
Peter Øhrstrøm, Henrik Sch¨arfe, and Pascal Hitzler, editors, ICCS, pages
28–41. Aalborg University Press, 2006.

[Dau06c] Frithjof Dau. Some notes on proofs with alpha graphs. In Øhrstrøm et al.

[ØSH06], pages 172–188.

[Dev91] K. Devlin. Logic and Information. Cambridge University Press, Cambridge,

1991.

[DHC03] Frithjof Dau and Joachim Hereth Correia. Nested concept graphs: Mathematical foundations and applications for databases. In Ganter and de Moor
[GdM03], pages 125–142.

[DHC06] Frithjof Dau and Joachim Hereth Correia. Two instances of peirce’s reduction thesis. In Rokia Missaoui and J¨urg Schmid, editors, ICFCA, volume
3874 of Lecture Notes in Computer Science, pages 105–118. Springer, 2006.
[Dip04] Randall Dipert. Peirce’s deductive logic: Its development, inﬂuence, and
philosphical signiﬁcance. In Cheryl L. Misak, editor, The Cambridge Companion to Peirce, pages 287–324. Cambridge University Press, Cambridge,
2004.

References

331

[DK03] Frithjof Dau and J. Klinger. From formal concept analysis to contextual
logic. In Bernhard Ganter, Gerd Stumme, and Rudolf Wille, editors, Formal
Concept Analysis: The State of the Art, volume 3626 of Lecture Notes in
Computer Science. Springer, Berlin – Heidelberg – New York, 2003.
[dMLG03] Aldo de Moor, Wilfried Lex, and Berhard Ganter, editors. Conceptual Structures for Knowledge Creation and Communication, volume 2746
of LNAI. Springer, Berlin – Heidelberg – New York, 2003.

[DS01] Harry S Delugach and Gerd Stumme, editors. Conceptual Structures: Broadening the Base, volume 2120 of LNAI, Stanford, USA, July,, 2001. Springer,
Berlin – Heidelberg – New York.

[EEM96] P. W. Eklund, G. Ellis, and G. Mann, editors. Conceptual Structures:
Knowledge Representation as Interlingua, volume 1115 of LNAI. Springer,
Berlin – Heidelberg – New York, 1996.

[Eis76] C. Eisele, editor. Charles Sanders Peirce: The new Elements of Mathematics.
Hague: Mouton Publishers; Atlantic Highlands, N.J.: Humanities Press, 1976.
[Ekl04] Peter W. Eklund, editor. Concept Lattices, Second International Conference
on Formal Concept Analysis, ICFCA 2004, Sydney, Australia, February 2326, 2004, Proceedings, volume 2961 of Lecture Notes in Computer Science.
Springer, Berlin – Heidelberg – New York, 2004.

[ELRS95] G. Ellis, R. Levinson, W. Rich, and J. F. Sowa, editors. Conceptual
Structures: Applications, Implementation, and Theory, volume 954 of LNAI.
Springer, Berlin – Heidelberg – New York, 1995.

[Fri92] U. Friedrichsdorf. Einf¨uhrung in die klassische und intensionale Logik.

Vieweg, 1992.

[GdM03] Bernhard Ganter and Aldo de Moor, editors. Using Conceptual Structures:
Contributions to ICCS 2003, Borovets, Bulgaria, July, 15–19, 2003. Shaker
Verlag, Aachen.

[GM00] Bernhard Ganter and Guy W. Mineau, editors. Conceptual Structures: Logical, Linguistic and Computational Issues, volume 1867 of LNAI, Darmstadt,
Germany, 2000. Springer, Berlin – Heidelberg – New York.

[GM01] B. Ganter and G. Mineau, editors. Conceptual Structures: Extracting and

Representing Semantics. Manuscript Stanford, 2001.

[GW99] Bernhard Ganter and Rudolf Wille. Contextual attribute logic. In Tepfen-

hart and Cyre [TC99], pages 377–388.

[Haa78] Susan Haack. Philosophy of Logics. Cambridge University Press, 1978.
[Ham95] Eric M. Hammer. Logic and Visual Information. CSLI Publications, Stan-

ford, California, 1995.

[Ham98] E. M. Hammer. Semantics for existential graphs. Journal Philosophical

Logic, 27:489–503, 1998.

[Haw94] Derik Hawley. Logic in pictures: An examination of diagrammatic representations, graph theory and logic. Master’s thesis, Waterloo, Canada, 1994.
Available at: http://etd.uwaterloo.ca/etd/dhawley1994.pdf.

[HB35] Weiss Hartshorne and Burks, editors. Collected Papers of Charles Sanders

Peirce, Cambridge, Massachusetts, 1931–1935. Harvard University Press.

[HCP04] Joachim Hereth Correia and Reinhard P¨oschel. The power of peircean

algebraic logic (pal). In Eklund [Ekl04], pages 337–351.

[HCP06] Joachim Hereth Correia and Reinhard P¨oschel. The teridentity and

peircean algebraic logic. In Øhrstrøm et al. [ØSH06].

332

References

[Her81] Hans G. Herzberger. Peirces remarkable theorem. In F. Wilson L. W. Sumner, J. G. Slater, editor, Pragmatism and Purpose: Essays Presented to
Thomas A. Goudge. University of Toronto Press, Toronto, 1981.

[Hin85] J. Hintikka. The Game of Language: Studies in Game-Theoretical Semantics

and its Applications. D. Reidel, Dordrecht, 1985.

[Hin97] J. Hintikka. The place of c. s. peirce in the history of logical theory. In

Brunning and Forster [BF97], pages 13–33.

[HMN02] Mary Hegarty, Bernd Meyer, and N. Hari Narayanan, editors. Diagrammatic Representation and Inference: Second International Conference, Diagrams 2002, Proceedings, volume 2317 of Lecture Notes in Computer Science.
Springer, Berlin – Heidelberg – New York, 2002.

[HMST02] J. Howse, F. Molina, Sun-Joo Shin, and J. Taylor. On diagram tokens

and types. In Hegarty et al. [HMN02], pages 146–160.

[Hoo85] Christopher Hookway. Peirce. London: Routledge and Kegan Paul, 1985.
[HRE97] Nathan Houser, Don D. Roberts, and James Van Evra, editors. Studies

in the Logic of Charles Sanders Peirce. Indiana University Press, 1997.

[Jec78] T. Jech. Set Theory. Academic Press, 1978.
[Kee] Mary Keeler. The philosophical context of peirce’s existential graphs. Avail-

able at:
http://www.dipf.de/projekte/Paed Sem HCI/Texte/Keeler context.htm.
[Ket90] Kenneth Laine Ketner. Elements of Logic: An Introduction to Peirce’s Existential Graphs. Texas Tech University Press, Lubbock, Texas, 1990.
[KGS90] L. Kreiser, S. Gottwald, and W. Stelzer. Nichtklassische Logik. Akademie–

Verlag Berlin, 1990.

[Kul94] Zenon Kulpa. Diagrammatic representation and reasoning. Machine Graph-

ics and Vision, 3(1/2):77–103, 1994.

[Lev79] A. Levy. Basic Set Theory. Springer, Berlin – Heidelberg – New York, 1979.
[Luk97] D. Lukose, editor. Conceptual Structures: Fulﬁlling Peirce’s Dream, volume

1257 of LNAI. Springer, Berlin – Heidelberg – New York, 1997.

[M¨97] Ralf M¨uller. Peirce’s existential graphs: First inquiries towards a proper
understanding. In Michael van Heerden Jaap van Brakel and, editor, C.S.
Peirce, categories to constantinople, proceedings of the international symposium of Peirce. Leuven University Press, 1997.

[Mat69] B. Mates. Elementare Logik. Vandenhoeck & Ruprecht, 1969.
[MC98] Marie-Laure Mugnier and Michel Chein, editors. Conceptual Structures:
Theory, Tools and Applications, 6th International Conference on Conceptual
Structures, ICCS ’98, Montpellier, France, August 10-12, 1998, Proceedings,
volume 1453 of LNAI. Springer, Berlin – Heidelberg – New York, 1998.

[Men64] E. Mendelson. Introduction to Mathematical Logic. D. Van Nostrand Com-

pany, Princeton, 1964.

[ML] Robert Marty and Bern Lang. 76 deﬁnitions of the sign by c. s. peirce.

Available at:
http://members.door.net/arisbe/menu/library/rsources/76defs/76defs.htm.

[MMS93] Guy Mineau, Bernard Moulin, and John F. Sowa, editors. Conceptual
Graphs for Knowledge Representation, volume 699 of LNAI, Quebec City,
Canada, August 1993. Springer, Berlin – Heidelberg – New York.

[Mon69] J. D. Monk. Introduction to Set Theory. McGraw–Hill, 1969.
[Nor04] Jesse Norman. The iconic logic of peirce’s graphs. Mind, 113(452):783–787

(5), 2004.

References

333

[ØBD99] Peter Øhrstrøm, Torben Br¨auner, and Claus Donner. A software system
for learning peircean graphs. In Tepfenhart and Cyre [TC99], pages 184–197.

[Oeh93] K. Oehler. Charles Sanders Peirce. Beck’sche Reihe, 1993.
[Øh95] Peter Øhrstrøm. Logic and existential graphs. Topics in Cognitive Science

and HCI, 6:137–154, 1995.

[Øh96] Peter Øhrstrøm. Existential graphs and tense logic.

In Eklund et al.

[EEM96].

[Øh97] Peter Øhrstrøm. C. s. peirce and the quest for gamma graphs. In Lukose

[Luk97], pages 357–370. Available at:
http://www.hum.auc.dk/ poe/ARTIKLER/GammaHTML/GammaGraphs.html.

[ØSH06] Peter Øhrstrøm, Henrik Sch¨arfe, and Pascal Hitzler, editors. Conceptual
Structures: Inspiration and Application, volume 4068 of Lecture Notes in
Computer Science. Springer, Berlin – Heidelberg – New York, 2006.
[ØSvdB94] Peter Øhrstrøm, Jan Schmidt, and Harmen van den Berg. Some peircean
In Tepfenhart et al.

problems regarding graphs for time and modality.
[TDS94], pages 78–92.

[Pap83] Helmut Pape. Charles S. Peirce: Ph¨anomen und Logik der Zeichen.
Suhrkamp Verlag Wissenschaft, Frankfurt am Main, Germany, 1983. German
translation of Peirce’s Syllabus of Certain Topics of Logic.

[PCA02] Uta Priss, Dan Corbett, and Galia Angelova, editors. Conceptual Structures: Integration and Interfaces, volume 2393 of LNAI, Borovets, Bulgaria,
July, 15–19, 2002. Springer, Berlin – Heidelberg – New York.

[Pei35] Charles Sanders Peirce. MS 478: Existential Graphs. Harvard University
Press, 1931–1935. Partly published in of [HB35] (4.394-417). Complete german translation in [Pap83].

[Pei92] Charles Sanders Peirce. Reasoning and the logic of things. In K. L. Kremer and H. Putnam, editors, The Cambridge Conferences Lectures of 1898.
Harvard Univ. Press, Cambridge, 1992.

[Pie04] Ahti-Veikoo Pietarinen. Peirce’s diagrammatic logic in if perspecive.

In

Blackwell et al. [BMS04], pages 97–111.

[Pie06] Ahti-Veikoo Pietarinen. The endoporeutic method. Published on ’the digital

Peirce’. Available at:
http://www.digitalpeirce.fee.unicamp.br/endo.htm., 2006.

[Pol01] Silke Pollandt. Relational constructions on semiconcept graphs. In Ganter

and Mineau [GM01].

[Pol02] Silke Pollandt. Relation graphs: A structure for representing relations in

contextual logic of relations. In Priss et al. [PCA02], pages 24–48.

[Pre98] Susanne Prediger. Kontextuelle Urteilslogik mit Begriﬀsgraphen – Ein
Beitrag zur Restrukturierung der Mathematischen Logik. Shaker Verlag,
Aachen, 1998. Dissertation, Darmstadt University of Technology.

[Pre00] Susanne Prediger. Mathematische logik in der wissensverarbeitung:
Historisch-philosophische gr¨unde f¨ur eine kontextuelle logik. Mathe.
Semesterberichte, 47, 2000.

[PS00] Charles Sanders Peirce and John F. Sowa. Existential Graphs: MS 514 by
Charles Sanders Peirce with commentary by John Sowa, 1908, 2000. Available at: http://www.jfsowa.com/peirce/ms514.htm.

[Put82] Hilary Putnam. Peirce the logician. Historia Mathematica, 9:290–301, 1982.
[Rau96] W. Rautenberg. Einf¨uhrung in die mathematische Logik. Vieweg Lehrbuch

Mathematik, 1996.

334

References

[Rob73] Don D. Roberts. The Existential Graphs of Charles S. Peirce. Mouton,

The Hague, Paris, 1973.

[Rob92] Don D. Roberts. The existential graphs. Computers Math. Appl.., 23(6–

[Shi]

9):639–63, 1992.
Sun-Joo Shin. Diagrams and a theory of seeing. Available at:
http://www.cs.tcd.ie/Tim.Fernando/B/shin.pdf.

[Shi94] Sun-Joo Shin. The Logical Status of Diagrams. Cambridge University Press,

1994.

[Shi96] Atsushi Shimojima. On the Eﬃcacy of Representation. PhD thesis,
The Department of Philosophy, Indiana University, 1996. Available at:
http://www.jaist.ac.jp/ ashimoji/e-papers.html.

[Shi99] Sun-Joo Shin. Reconstituting beta graphs into an eﬃcacious system. Journal

of Logic, Language and Information, 8(3), 1999.
[Shi00] Sun-Joo Shin. Reviving the iconicity of beta graphs.

In Anderson et al.

[ACH00].

[Shi02a] Sun-Joo Shin. The Iconic Logic of Peirce’s Graphs. Bradford Book, Mas-

sachusetts, 2002.

[Shi02b] Sun-Joo Shin. Multiple readings in peirce’s alpha graphs.

In Michael
Anderson, Bernd Meyer, and Patrick Olivier, editors, Diagrammatic Representation and Reasoning. Springer, Berlin – Heidelberg – New York, 2002.

[Sho67] J. R. Shoenﬁeld. Mathematical Logic. Addison–Wesley, 1967.
Semantic
[Sow] John F. Sowa.
is a revised merger of

This pacontexts.
foundations of
[Sow95] and [Sow97b]. Available at:

per
http://www.jfsowa.com/ontology/contexts.htm.

[Sow84] John F. Sowa. Conceptual structures: information processing in mind and

machine. Addison-Wesley, Reading, Mass., 1984.

[Sow92] John F. Sowa. Conceptual graphs summary. In T. E. Nagle, J. A. Nagle,
L. L. Gerholz, and P. W. Eklund, editors, Conceptual Structures: current
research and practice, pages 3–51. Ellis Horwood, 1992.

[Sow95] John F. Sowa. Syntax, semantics, and pragmatics of contexts. In Ellis et al.

[ELRS95], pages 1–15. See also [Sow].

[Sow97a] John F. Sowa. Logic: Graphical and algebraic. manuscript, Croton-on-

Hudson, 1997.

[Sow97b] John F. Sowa. Peircean foundation for a theory of context. In Lukose

[Luk97], pages 41–64. See also [Sow].

[Sow00] John F. Sowa. Knowledge Representation: Logical, Philosophical, and Com-

putational Foundations. Brooks Cole, Paciﬁc Grove, CA, 2000.

[SPØ02] Henrik Sch¨arfe, Ulrik Petersen, and Peter Øhrstrøm. On teaching concep-

tual graphs. In Priss et al. [PCA02], pages 285–298.

[Ste96] John Stewart. Theorem proving using existential graphs. Master’s thesis,

University of California at Santa Cruz, 1996. advisor: Robert Levinson.

[Stu00] Gerd Stumme, editor. Working with Conceptual Structures. Contributions

to ICCS 2000. Shaker Verlag, Aachen, 2000.

[SW00] G. Stumme and R. Wille, editors. Begriﬄiche Wissensverarbeitung: Meth-

oden und Anwendungen. Springer, Berlin – Heidelberg – New York, 2000.

[Tar41] A. Tarski. On the calculus of relations. Journal of Symbolic Logic, 6(3):73–

89, 1941.

[TC99] Wiliam Tepfenhart and W. Cyre, editors. Conceptual Structures: Standards
and Practices, volume 1640 of LNAI. Springer, Berlin – Heidelberg – New
York, 1999.

References

335

[TDS94] William M. Tepfenhart, Judith P. Dick, and John F. Sowa, editors. Conceptual Structures: Current Practices, volume 835 of LNAI, College Park,
USA, August 1994. Springer, Berlin – Heidelberg – New York.

[TW94] H. P. Tuschik and H. Wolter. Mathematische Logik – kurzgefasst. BI Wis-

senschaftsverlag, Mannheim–Leipzig–Wien–Z¨urich, 1994.

[vD96] D. van Dalen. Logic and Structure. Springer, Berlin – Heidelberg – New

York, 1996.

[VP98] Adam Vile and Simon Polovina. Possibilites in peirce’s existential graphs

for logic education. available from the authors, 1998.

[Wer95] M. Wermelinger. Conceptual graphs and ﬁrst-order logic. In Ellis et al.

[ELRS95], pages 323–337.

[Wil94] Rudolf Wille. Pl¨adoyer f¨ur eine philosophische grundlegung der begrifﬂichen wissensverarbeitung. In R. Wille and M. Zickwolﬀ, editors, Begrifﬂiche Wissensverarbeitung: Grundfragen und Aufgaben, pages 11–25. B.I.–
Wissenschaftsverlag, Mannheim, 1994.

[Wil96] Rudolf Wille. Restructuring mathematical logic: An approach based on
peirce’s pragmatism. In A. Ursini and P. Agliano, editors, Logic and Algebra,
pages 267–281. Marcel Dekker, New York, 1996.

[Wil97] Rudolf Wille. Conceptual graphs and formal concept analysis. In Lukose

[Luk97], pages 290–303.

[Wil99] Rudolf Wille. Conceptual landscapes of knowledge: a pragmatic paradigm
for knowledge processing. In W. Gaul and H Locarek-Junge, editors, Classiﬁcation in the Information Age, pages 344–356. Springer, Berlin – Heidelberg
– New York, 1999.

[Wil00] Rudolf Wille. Contextual logic summary. In Stumme [Stu00], pages 265–

276.

[Wil01] Rudolf Wille. Lecture notes on contextual logic of relations. Fb4-preprint,

Darmstadt University of Technology, 2001.

[Zem64] Jay J Zeman. The Graphical Logic of C. S. Peirce. PhD thesis, University
of Chicago, 1964. Available at: http://www.clas.ufl.edu/users/jzeman/.
[Zem86] Jay J Zeman. Peirce’s philosophy of logic. Transactions of the Charles S.

Peirce Society, 22:1–22, 1986.

[Zem95] Jay J Zeman. Existential graphs and thirdness. Semiotica, 105:311–19,

1995.

[Zem97] Jay J Zeman. Peirce and philo. In Houser et al. [HRE97]. Available at:
http://web.clas.ufl.edu/users/jzeman/peirce and philo.htm.

